[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Adaptation Notes",
    "section": "",
    "text": "Preface\nThese are lecture notes to accompany my class, Adaptation.\nI first developed this class when I moved from the Anthropology department to the Department of Earth System Science. There was a new masters program in sustainability and the director of this program wanted a class that taught complexity and socioecological systems. I took up the challenge. Of course, after developing the class, I was told that the program had gone in a different direction and my class wouldn’t be a core class for the program after all, but by then it had taken on a life of its own.\nMy initial thought was to analyze the different ways that the term “adaptation” was used across cognate disciplines. When I first moved into the School of Earth, I became aware that the people focused on climate change and related issues clearly meant something different by “adaptation” than I did.\nThis seemed like an interesting approach for a class on adaptation. The only problem was that as I read work on adaptation in the climate-change sense, I was struck by two things: (1) how the valence accorded the term adaptation is fundamentally different in the climate-change literature than it is in the evolutionary sciences, and (2) in how bereft of theory the field of climate-change adaptation is.\nWhen an evolutionary biologist talks about adaptation, it is typically done so with a strongly positive valence. An adaptation means that the organism has overcome some persistent environmental challenge and improved itself. It has ascended the fitness landscape toward a more optimal phenotype. It has come up with a clever solution.\nWhen a climate scientist or policy-maker talks about adaptation, there is resignation. Adaptation is synonymous with resignation or settling. There is an underlying Freirean pessimism that somehow by adapting people are not liberated, but are coping.\nThere seems to be more than just a little status quo bias in this framing.\nWhat I decided to try instead was to explore how evolutionary and ecological theory of adaptation could be applied to understanding the current human predicament. We wrote a paper on this topic laying out some of our early thinking (Jones, Ready, and Pisor 2020).\nNow, just because an evolutionary perspective on adaptation has positive valance doesn’t mean everything is roses and we can adapt our way out of any predicament. Natural selection is the only evolutionary mechanism that can produce adaptation and, of course, natural selection has a dark side. Ernst Mayr, an architect of the Modern Evolutionary Synthesis, characterized natural selection as “nonrandom elimination.”\nNaturalistic fallacy, etc. Don’t be a little bitch and confuse an is for an ought.\nYes, we should mitigate the future effects of climate change, but mitigation in the absence of adaptation is just more status quo. A real Freirean dialogue can come about when mitigation and adaptation work in concert. We should prevent bad things that we know are likely to happen, but we should also work toward better solutions.\nThe structure of the notes follows the structure of the class. What follows are ten chapters:\n1  Models\n2  Evolutionary Foundations\n3  Population Ecology\n4  Does Culture Evolve?\n5  Risk, Uncertainty, and Decision-Making\n6  Complexity\n7  Emergence and Governing the Commons\n8  Dynamic Optimization and Adaptive Management\n9  Efficiency Is the Enemy\n10  The Structure of Successful Problem-Solving",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#evolution-is-a-snap",
    "href": "index.html#evolution-is-a-snap",
    "title": "Adaptation Notes",
    "section": "Evolution is a Snap",
    "text": "Evolution is a Snap\n\n\n\nAdaptation is a snap. A meme created by and then presented in class by a former student class (Keona Banks), in which I was repeatedly assured by the assembled class that I was a “good Thanos.”",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#the-great-nothings-of-adaptation",
    "href": "index.html#the-great-nothings-of-adaptation",
    "title": "Adaptation Notes",
    "section": "The Great Nothings of Adaptation",
    "text": "The Great Nothings of Adaptation\nThese notes are organized around what I call “The Two Great Nothings of Adaptation”:\nNothing in biology makes sense except in light of evolution (Theodosius Dobzhansky)\nThere is nothing more practical than a good theory (Kurt Lewin). But must keep in mind the Bendor Corollary: “There is nothing more impractical than a bad theory.”\nThese notes primarily deal with the scientific theory underlying adaptation in complex socio-ecological systems. Scientific Theory is an explanation of some aspect of the world. Good scientific theories have been tested and corroborated repeatedly by established research methods. Scientific Theory goes beyond facts or observations by providing a structure for investigation and providing answers to how questions. To be useful, a scientific theory must make testable predictions. These should distinguish it from competing theories.\nWhy is theory so important? As suggested by three greats of ecology (Roughgarden, May, and Levin 1989), “More importantly, perhaps, theory can imagine and explore a wider range of worlds than the unique one we inhabit, and by so doing can lead to fresh perceptions and new questions about why our actual world came to be as it is.”\nTheory allows us to make statements about states of the universe that we have not yet seen. This is especially important in the context of adaptation and sustainability. Sustainability is ultimately about the future, and the future is, by definition, a world we have not yet experienced. This means that theory is particularly important for the pressing problems of sustainability.\nIn a stationary environment, where the mean and variance stay the same despite short-term variability, optimizing your decision-making based on your prior experience with the environment is a sound policy. However, in nonstationary environments, doing so can be a disaster. Nonstationary environments create what the psychologist Robin Hogarth called a wicked learning environment. In such environments, lessons that we learn from the past do not help us perform better. The economists John Kay & Mervin King note that when the learning environment is wicked “the application of the mathematics of probability is questionable and the results ambiguous.” In other words, in uncertain, wicked learning environments, maximization of something like expected utility, the primary tool of decision theory, economics, and planning won’t do us much good.\nWe live in a time of nonstationary change. When we optimize, we are adapting to the past.\nThe Stanford Doerr School of Sustainability’s own Bill Barnett has noted how bad we are at identifying transformative technologies before they do their transforming. Optimization and consensus approaches may get you incremental improvement, but they will not produce transformation.\nSome themes we will weave together in these notes:\n\nEcology, not Mechanics\nAdaptation is Evolutionary\nOptimality is for Small Worlds, not Real Ones\nResilience, not Stability\nAdaptability and Robustness Trade-Off\nUncertainty Changes Everything\nAdaptation Requires Diversity\nNeed to Jettison the (Standard) Narratives of Progress\n\nI’ll conclude with a nod toward another obsession of mine: the utility of climate fiction for helping us to imagine adaptive societies. In her acceptance speech at the 2014 National Book Awards’ Medal for Distinguished Contribution to American Letters, Ursula Le Guin noted:\n\nI think hard times are coming, when we will be wanting the voices of writers who can see alternatives to how we live now, and can see through our fear-stricken society and its obsessive technologies, to other ways of being. And even imagine some real grounds for hope. We will need writers who can remember freedom: poets, visionaries—the realists of a larger reality.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#fair-warning",
    "href": "index.html#fair-warning",
    "title": "Adaptation Notes",
    "section": "Fair Warning",
    "text": "Fair Warning\nThese notes are a work in progress and, as such, are necessarily incomplete. They are, in places, quite telegraphic. Some chapters are far more complete; others are more like the presenter notes from lecture slides (because that’s what they are!).\n\n\n\n\nJones, J. H., E. Ready, and A. C. Pisor. 2020. “Want Climate-Change Adaptation? Evolutionary Theory Can Help.” American Journal of Human Biology 33 (4): e23539. https://doi.org/10.1002/ajhb.23539.\n\n\nRoughgarden, J., R. M. May, and S. A. Levin. 1989. Perspectives in Ecological Theory. Princeton: Princeton University Press.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "models.html",
    "href": "models.html",
    "title": "1  Models",
    "section": "",
    "text": "1.1 The Great Nothings\nNothing in Biology Makes Sense Except in Light of Evolution (Theodosius Dobzhansky) and There is Nothing More Practical Than a Good Theory (Kurt Lewin).\nScientific theory is an explanation of some aspect of the world. Good scientific theories have been tested and corroborated repeatedly by established research methods. Scientific Theory goes beyond facts or observations by providing a structure for investigation and providing answers to how questions. To be useful, a scientific theory must make testable predictions. These should distinguish it from competing theories. Some examples of scientific theories include the germ theory of disease, heliocentric solar system, plate tectonics, and of course, the theory of evolution by natural selection.\nTheory allows us to make rigorous statements about things we have not yet observed. It is therefore particularly important for a branch of science focused on the future. As noted by Roughgarden, May, and Levin (1989), “More importantly, perhaps, theory can imagine and explore a wider range of worlds than the unique one we inhabit, and by so doing can lead to fresh perceptions and new questions about why our actual world came to be as it is.”\nMy colleague, the political scientist Jon Bendor, once quipped that while there is nothing more practical than a good theory, “there is nothing more impractical than a bad theory.” Obviously, we need rigorous mechanisms to adjudicate the good theory and weed out the bad.\nThe physicist-turned-philosopher-of-science, Karl Popper, promoted a model of scientific reasoning that seems to be largely the default for many practicing scientists. Popper’s model of science is known as the Hypothetico-Deductive model. I won’t belabor it, but I will say that I am generally not big on prescriptive approaches to science — as long as the science can eventually be placed into something like a formal framework (to avoid ambiguity, etc.).\nLehman (1986) “Those who embrace constraints crafted by others in the form of Popperian or hypothetico-deductive straight jackets may have divined a means to restrict their imagination, but there is no evidence in my view that those constraints encourage breakthroughs in the biological sciences”",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Models</span>"
    ]
  },
  {
    "objectID": "models.html#models-are-dumb",
    "href": "models.html#models-are-dumb",
    "title": "1  Models",
    "section": "1.2 Models Are Dumb",
    "text": "1.2 Models Are Dumb\nWith complex explanatory frameworks for complex real-world phenomena, our intuition often fails us. P. E. Smaldino (2017) argues for the fundamental importance of formal models in science (especially in areas, such as psychology and anthropology where they are not typically employed). A formal model requires us to delineate parts of a system, and then specify the relationships between those parts. The model helps us develop intuition for problems. It allows us to examine the logical conclusions of assumptions and to examine appropriateness of assumptions. Gunawardena (2014) noted that “a mathematical model is a logical machine for converting assumptions into conclusions”\nHilborn and Mangel (1997) suggest that formal models serve four purposes:\n\nThey are tools for evaluating scientific hypotheses.\nThey are a means of formalizing a verbal description.\nThey are a means of identifying important features of a system.\nThey are a means of refining investigation and guiding future experimental or observational work.\n\nIn addition to these features, formalizing verbal models allows us to avoid strategic ambiguity, a term coined by Eisenberg (1984). He meant it in a positive sense. P. E. Smaldino (2017) re-purposes the term with a decidedly less positive implication. From Eisenberg’s perspective of organizational communication, strategic ambiguity is a tool for organization that promotes “unified diversity”, facilitates organizational change, and preserves the power structure of institutions. From a scientific perspective, the strategic ambiguity of verbal models gives the illusion of understanding while undermining actual understanding.\nRelated to The Motte-and-Bailey Fallacy, where a speaker initially advances an indefensible claim (“the bailey”) and, when challenged, retreats to a more modest claim (“the motte”) that shares some similarities with the indefensible claim. This is a common tactic employed by racist pseudoscientists.\nTwo specific modes of strategic ambiguity include Theory stretching and Post-Hoc precision. Theory stretching: interpretation of an ambiguous claim more expansively to absorb data outside the scope of the original claim. Post-hoc precision: interpretation of an ambiguous theoretical claim narrowly so that it appears more precisely aligned with the data\nIn a tweet on 8 December 2021 the psychologist Julia Rohrer suggested that “[i]t is the curse of transparency that the more you disclose about your research process, the more there is to criticize.”\nW. Frankenhuis, Panchanathan, and Smaldino (2022): “Clarity can have the perverse effect of making it easier for evaluators to identify flaws that might have remained hidden in a more ambiguous description.”\nAmbiguous theories promote confirmation bias. Natural selection for bad science (Paul E. Smaldino and McElreath 2016). Ambiguous theories are often given a pass by reviewers, editors, and the general public, while precise theories are seen as narrow and uninteresting. In a tweet (RIP) on 30 November 2020, Paul Smaldino coined the name RAPPing (Rewarding Ambiguity and Penalizing Precision) for this phenomenon (W. Frankenhuis, Panchanathan, and Smaldino 2022).\nW. Frankenhuis, Panchanathan, and Smaldino (2022) identify six questions that you can ask to avoid RAPPing:\n\nIs each term defined?\nAre all the relations between terms specified?\nAre all the assumptions stated explicitly?\nHas the theory been formalized?\nIs the scope of the theory well-specified?\nIs the theory consistent across papers?\n\nModels may be dumb, but they are also democratic. Muthukrishna and Henrich (2019) note that “[b]y formally defining assumptions, logic, and predictions, anyone can challenge the theory by either testing the predictions or by challenging or modifying the assumptions or logic and showing how the predictions would change.”\nIn the spirit of moving beyond the existing empirical evidence, “[r]igorous formal theory may also be a way to evaluate the existing literature for plausibility based on connections to well-established theories and data.”\nThompson et al. (2022), cited in W. Frankenhuis, Panchanathan, and Smaldino (2022), used machine learning, trained on evaluations of work for the UK Research Excellence Framework, to show that harder-to-understand abstracts rated more highly than than easier-to-understand abstracts!\nThink about the language of the contemporary humanities, especially cultural anthropology…\n\n1.2.1 Three Ambiguous Models in the Study of Adaptation\nResilience: started out as serious population biology, but has become overrun by woo.\nThe Availability Heuristic. See Chapter 5\nAdaptation itself!\n\n\n1.2.2 Types of Models\nHolling (1966) made a distinction between strategic and tactical models. Strategic Models typically have a small number of parameters and are “uncluttered with extraneous details,” and are important for developing general theory. Tactical models, on the other hand, are more detailed, possibly fit to empirical data. The aim of a tactical model is making more precise predictions or to provide refinements of general theory.\nLevins (1966) suggested that models inherently entail trade-offs. In particular, he suggested that a model cannot simultaneously maximize generality, precision, and realism. In the framework of Holling (1966), we can say that strategic models are more general, while tactical models are more realistic & precise.\nOrzack and Sober (1994) don’t like it one bit. Like I’m a little worried that Steve Orzack is going to come for me because I actually cited Levins unironically. Evans et al. (2013) suggest that complex models can be general and that theoretical progress depends on combining simple and complex models. I agree with that in principle.\nSchelling (1960) similarly praises simple models. Similarly, so does Western (2001), who notes notes that they are easy to refute because their prior probability mass is more highly concentrated.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Models</span>"
    ]
  },
  {
    "objectID": "models.html#the-power-of-false-models",
    "href": "models.html#the-power-of-false-models",
    "title": "1  Models",
    "section": "1.3 The Power of False Models",
    "text": "1.3 The Power of False Models\nWimsatt (1987) provides a comprehensive list of the benefits of",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Models</span>"
    ]
  },
  {
    "objectID": "models.html#the-power-of-simple-models-optimality-in-human-behavioral-ecology",
    "href": "models.html#the-power-of-simple-models-optimality-in-human-behavioral-ecology",
    "title": "1  Models",
    "section": "1.4 The Power of Simple Models: Optimality in Human Behavioral Ecology",
    "text": "1.4 The Power of Simple Models: Optimality in Human Behavioral Ecology\nWe can illustrate the power of simple (false) models by examining an old debate in human ecology. To do this, we first need to spend a little time introducing optimality models.\n\n1.4.1 Optimality Models\nOptimality models are generally relatively simple, tactical explanation for behavior. The foundational approach for human behavioral ecology (HBE) Eric Alden Smith (1992b)\nDifferent authors break up the requirements for optimality models in different ways. I like the approach of E. A. Smith and Winterhalder (1992) best. In this formulation, optimality models require the specification of four things”\n\nActor: A definition of the unit of analysis. Who or what is doing the optimizing?\nObjective Function: What is it that people seek to optimize?\nStrategy Set: What are the possible alternative actions from which the best choice is being made?\nConstraints What is possible?\n\nThe use of simple optimality models provides a coherent framework for structuring research.\nOptimality models tend to be simple. As such, they frequently fail to fully explain human decisions. What then is the point? As we discuss in more detail elsewhere (e.g., Chapter 5), simple models allow us to make very general qualitative statements. When people fail to conform to the predictions of optimality models, what is happening? Importantly, people may simply not be optimizing. However, we can make far more out of the result. Have we mis-specified the objective function or the currencey? Did we fail to properly enumerate the possible alternative strategies? Is there a constraint on indivudals’ choice that we failed to account for?\nLevins, in his classic (1966) paper, noted that models can fufill three goals: generality, realism, and precision. He further suggests that a single model can not maximize all three of these features simultaneously (Levins 1966). A highly realistic model will not typically apply to a broad range of cases because it will include a great deal of information specific to the situation.\nHolling (1964) and Holling (1966) has proposed a similar typology of models, noting particularly the distinction between tactical and strategic models.\nSchelling (1960) similarly praises simple models.\n\n\n1.4.2 Optimal Foraging Theory\nHowever, the optimality approach has drawn criticism from other ecological anthropologists and may continue to create a barrier to fruitful integration of different traditions of human ecology. Vayda (1995a) and Vayda (1995b) has been particularly critical of HBE and other functionalist approaches to human ecology. The strong criticism that comes out of Vayda’s work (Driscoll and Stich 2008) is that the fit between functional predictions and observed human behavior frequently can not rule out alternative explanations. The formal methods of evaluating multiple hypotheses that I present below addresses this criticism and are consistent with Vayda’s emphasis on event-driven explanatory models (Vayda and Walters 1999). In general, I am sympathetic to many of Vayda’s criticisms of both behavioral and political ecology, though there are shortcomings in his criticism of HBE.\nArguing from a Pragmatic perspective, Vayda criticizes both HBE and political ecology, suggesting that they are shackled in their ability to explain human action by their respective theoretical perspectives. While Vayda clearly sees both traditions as blinded by their strong theoretical perspectives, he specifically levels criticism against HBE (what he initially called “Darwinian Ecological Anthropology” or DEA (though later identified DEA as HBE) based on its nomological-deductive approach to explanation. In the place of theoretically-committed research strategies, Vayda persuasively argues for an event-based causal/explanatory (CE) style of science. He suggests that the best research strategy is Chamberlin’s “multiple working hypothesis” approach: observe an event; reason backward through potential chains of causation; evaluate the empirical support for these various candidate explanations. Supporting this idea of multiple working hypotheses is Peirce’s concept of abductive reasoning. Abduction is essentially reasoning from effect to probable cause. Your colleague is uncharacteristically short with you one morning. You reason that he must be experiencing stress at home. Or perhaps he just had a paper rejected. Or he harbors resentment at the way you treated him at last Friday’s faculty meeting. Of course, there are an infinite number of possible causes for your colleague’s grumpiness, but the universe of probable causes is greatly reduced by that person’s attributes (e.g., age, gender, profession, martial status, etc.) and contextual factors (e.g., recent history, current political climate, the weather). Abduction is the reasoning from event back to cause. However, determining the correct cause(s) requires deductive and inductive inference. Theory helps too, as it is theory that allows us to reduce the infinite universe of possible explanation to something manageable.\nPeirce (CP, 5:189) defined abduction as a form of inference as follows: “The surprising fact, C, is observed; But if A were true, C would be a matter of course, Hence, there is reason to suspect that A is true.” However, the definition of abduction raises the fundamental question of what exactly makes C surprising in the first place? Peirce suggests that humans possess a special capacity for reasoning about nature, an intriguing idea, consistent with some threads in evolutionary psychology. In the context of science, there is the issue of Peirce’s “economy of science,” which combines notions of parsimony and generativity of scientific results as a means of ordering preferences for scientific explanations. A particular scientific hypothesis is better than competitors, all else being equal, if it generates more possible empirical tests and future scientific work.\nContrary to Vayda’s critique, I suggest that the logic of HBE research, and particularly the reliance of simple models based on law-like generalizations, provides a fertile environment for the generation of surprising facts, as much the raw material of abduction as mutations are the raw material for natural selection. However, just as mutations are not sufficient to explain complex adaptations, so are the violations of simple models not sufficient for explanation of complex natural phenomena. Abduction generates new ideas. However, we still need deduction to reduce the universe of possible cause and generate testable predictions from our new ideas and we still need induction to allow empirical confirmation. Indeed, this is exactly Peirce’s perspective on the practice of science.\nThe prey-choice or diet-breadth model of which Vayda is so critical serves as an excellent starting point for understanding how positing a simple model that generally fits observations can yield new insights that allow for more complete explanation of human behavior. Assume random, sequential encounters (i.e., no clumping). Encounters are with individual prey items and chosen items and handled one at a time. Foraging is not dangerous for the forager, but it is all-encompassing, in that while foraging, an individual can not engage in any other behaviors.\nLet \\(En\\) be the total net energy gain from foraging and \\(T\\) be the total time spent foraging. Individual items \\(i \\in 1,2, \\ldots, k\\) have energy \\(E_i\\) and require handling time \\(h_i\\). The expected number of encounters per unit of foraging time is \\(\\lambda_i\\) and the probability of attack conditional on encounter is \\(P_i\\). Of these variables, the only one under the forager’s control is \\(P_i\\).\nThe goal is to maximize \\(En/T\\):\n\\[\n\\frac{E n}{T}=\\frac{\\sum \\lambda_i E_i P_i}{1+\\sum \\lambda_i h_i P_i}\n\\]\nMacArthur and Pianka (1966) proved that the optimal diet can be found by ranking the items from most profitable to least profitable based on their measures of \\(E_i/h_i\\), the energy of the item per unit of handling time. The optimal diet includes all (and only) the items for which:\n\\[\n\\frac{E_i}{h_i} &gt; \\frac{En}{T}.\n\\] That is, include all items whose net energy gain is greater than the average for the environment and ignore everything else. This is sometimes known as the zero-one rule because if an item is included in the diet, it should always be pursued when encountered and if it is not, it should never be pursued (Stephens and Krebs 1986). Research on hunter-gatherers from a variety of localities shows that the of the prey-choice model predicts foragers’ diets remarkably well in general. People preferentially target items that yield high energy returns. There are nonetheless some systematic deviations from predictions. In particular, men typically avoid items that have high values of \\(E_i/h_i\\) but come in small packages, particularly if those things are plant-based, favoring instead large-package items like big game that carry high prestige. Hawkes, Hill, and O’connell (1982), for example, showed that Aché men regularly ignore high-return items like biaju fruit or palm fiber. When captured, big game provides large energy returns. However, its relative scarcity and the very high handling/transport costs associated with its consumption means that other, ignored items may actually be better from a strictly energetic standpoint.\nIt is this reasoning that led researchers such as Hawkes (1991) and R. B. Bird, Smith, and Bird (2001) to suggest that men are driven by alternative motives other than simply energy maximization in pursuing high-prestige food items (and, more importantly, forgoing high-return, low-prestige items). Rebecca Bliege Bird (1999), in particular, argues that by widely sharing desirable food items within social groups, men gain prestige within communities, forge political alliances with other households, and potentially increase reproductive opportunities for themselves. The ensuing debate in the HBE literature over the motivations for men’s foraging decisions, while at times intense, has been extremely productive and has led to important theoretical developments in our attempts to explain observed human behavioral patterns. Chief among these are the theory of embodied capital of Kaplan and colleagues Gurven and Hill (2009) and theories of costly signaling as laid out by R. B. Bird and Smith (2005). Moreover, this debate has done the most valuable thing that scientific theory can do for science, namely, it has motivated the collection of more highly detailed data on foraging, food sharing, cooperation, and has generated novel theoretical linkages between different threads of human evolutionary biology (Hawkes 1991; Marlowe 2003; Alvard and Gillespie 2004; Marlowe 2004; Tucker 2004; Zeanah 2004; Wood 2006; Bird, et al. 2009; Gurven and Hill 2009; Kramer and Ellison 2010; Marlowe 2010; Nolin 2010; Carmody, et al. 2011; Codding, et al. 2011; Winking and Gurven 2011; Nolin 2012; Jones, et al. 2013; Wood and Marlowe 2013). gotta deal with these, ugh\nThis line of work and the research program it has spawned would not have been possible were it not for the simple model (i.e., the prey-choice model) that conditioned our expectations and the observed anomalies generated by attempts at empirical evaluation of the its predictions. The results score very favorably in terms of Peirce’s economy of science because of this generativity. It seems quite reasonable to posit that the best case for scientific progress is for a generally well-fitting model to generate occasional surprising exceptions. This provides a rather strong incentive for the development of general models. Of course, it also requires that researchers be open to — and willing to accept — the failure of their models in pursuit of improved scientific explanation.\nVayda (1995b) dismissed cost-benefit analysis of foraging theory in Kaplan and Hill (1992) and related work as mere “economizing,” suggesting that the fact that hunters forego prey that are not sufficiently profitable is a commonsense result that holds no deep insight into evolutionary process. Of course, it begs the question of why people behave in an economical manner? There are plenty of domains of human activity in which economizing is, apparently, not the rule. Indeed, demonstrating the apparent economic irrationality of the human mind is something of a cottage industry in behavioral economics Thaler (2015). Why should economizing be commonsense in the realm of foraging decisions? The answer, of course, comes from the biologically integrated theory of preferences that lies at the heart of HBE. Foraging, and subsistence behavior more generally, fall into the category of human actions that are economized because success in these domains actually matters for survival, reproduction, political success, and offspring recruitment. This explanation is consistent with the exciting counter-narrative to the irrationality of behavioral economics that comes from examining the savvy economic decision-making of the very poor, for whom the stakes of “economizing” presumably matter most W. E. Frankenhuis and Nettle (2020).\nThe causal-mechanistic explanation that is advocated by Vayda can produce rich narratives to account for events. It can also lead to highly convoluted explanations when an event’s causes are complex. While description is seen as the epistemic ideal in some schools of anthropological investigation (Geertz 1973), scientific approaches generally favor explanation, which necessarily involves simplification and generalization. Models – particularly strategic models — simplify, facilitating general explanation Schelling (1978). Thus, the simple models favored by HBE, and of which Vayda is so critical, can actually work in a complementary manner to mechanistic accounts, serving as an important check to potential runaway complexity of mechanistic accounts. This strategy is supported in the masterful statements on the philosophy of model-building by Levins (1966) in the biological sciences and by Schelling (1978) in the social sciences.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Models</span>"
    ]
  },
  {
    "objectID": "models.html#whence-the-replication-crisis",
    "href": "models.html#whence-the-replication-crisis",
    "title": "1  Models",
    "section": "1.5 Whence the Replication Crisis?",
    "text": "1.5 Whence the Replication Crisis?\nMuthukrishna and Henrich (2019): “without a unifying theoretical framework, we don’t know whether we should expect the results to replicate with older individuals, poorer individuals, or individuals in other societies. And without such a framework, even after the onerous replication effort, doubt remains as to whether one of the infinite space of moderators explains the lack of replication. To understand the importance of theory to data and data to theory, it’s worth remembering the abductive challenge.”\nThe limited imaginations of homogeneous researchers:\n“Many creative hypotheses have been drawn from the imaginations of researchers from societies that are WEIRD, but there is a certain circularity to testing these WEIRD intuitions on WEIRD participants that can mislead us into believing we are drawing closer to a deeper and more general understanding of human behaviour.”",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Models</span>"
    ]
  },
  {
    "objectID": "models.html#weirdmyopics",
    "href": "models.html#weirdmyopics",
    "title": "1  Models",
    "section": "1.6 WEIRD/MYOPICS",
    "text": "1.6 WEIRD/MYOPICS\nHenrich, Heine, and Norenzayan (2010)\nIn a blog post reviewing Henrich, Heine, and Norenzayan (2010), the cultural anthropologist Greg Downey suggested that WEIRD, while a great advance, is a wee bit self-congratulatory: “rich,” “educated,” “democratic,” and all that. Somewhat jokingly, he presented an alternative typology that is a bit more mechanistic, namely, MYOPICS:\n\nMaterialist\nYoung\nself-Obsessed\nPleasure-seeking\nIsolated\nConsumerist\nSedentary",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Models</span>"
    ]
  },
  {
    "objectID": "models.html#do-big-data-obviate-the-need-for-theory",
    "href": "models.html#do-big-data-obviate-the-need-for-theory",
    "title": "1  Models",
    "section": "1.7 Do Big Data Obviate the Need for Theory?",
    "text": "1.7 Do Big Data Obviate the Need for Theory?\nNo.\nProponents of “Big Data” argue that we are moving beyond the need for theory. For example, in probably the strongest early articulation of this idea, WIRED Magazine’s editor, Chris Anderson suggested that “with enough data, the numbers speak for themselves” In a brief note for the annual big-question solicitation by the Edge, mathematician Steven Strogratz (2007) suggested that we are approaching “the end of insight.”\nHowever, Big Data is no panacea and actually creates its own problems. Meng’s Paradox is a notable example. Sampling theory is central to modern statistical practice. There is a general impression that with large enough collections of data, we don’t need to woryy about sampling designs, etc.\nMeng (2018) described his “Law of Large Populations” (LLP), which shows that the estimation error, relative to the benchmarking rate from normal theory, \\(1/\\sqrt{n}\\), increases with \\(\\sqrt{N}\\), where \\(n\\) is the sample size and \\(N\\) is the census size of the population from which the sample of size \\(n\\) is drawn. Using polling data for the 2016 US presidential election, he shows that because of LLP, the simple sample proportion of the self-reported voting preference for Trump from 1% of the US eligible voters (\\(n \\approx 2,300,000\\)) had the same MSE as the corresponding sample proportion from a genuine simple random sample of size \\(n \\approx 400\\). This represents a 99.98% reduction of sample size (and hence confidence) and helps explain why so many media outlets were blindsided by the Trump electoral victory. Bradley et al. (2021) showed that the same phenomenon led to massive over-estimation of COVID-19 vaccination uptake in the US.\nMeng shows that the relative error of an outcome of interest, \\(\\bar{G}\\) is given by\n\\[ Z_{n,N} =  \\rho_{R,G} \\sqrt{N-1},\\] where \\(N\\) is the total population size, \\(n\\) is the sample size, and \\(\\rho_{R,G}\\) is the correlation between the response rate and the outcome.\nObviously, if the correlation between response and outcome is zero, then the relative error is zero. This is the case of a probability sample, which eliminates the correlation by design. However, even a minuscule correlation can blow up the relative error when the study population is large. The larger the underlying population, the larger the error.\nMeng concludes, “population inferences with Big Data are subject to a Big Data Paradox: the more the data, the surer we fool ourselves.” (Meng 2018)\n“Although we often hear that data speak for themselves, their voices can be soft and sly.” (Mosteller 1983: 234) We might add that the data also generally speak a foreign language and their soft voices typically require the expertise of a translator. That translator, of course, is theory.\nSucci and Coveney (2019) note that complex systems are strongly correlated, hence they do not (generally) obey Gaussian statistics. No data are big enough for systems with strong sensitivity to data inaccuracies. Moreover, correlation does not imply causation, the link between the two becoming exponentially fainter at increasing data size. In a finite-capacity world, too much data is just as bad as no data.\nIt seems that theory might actually be more important than ever.\nThis has proved to be the case in genetics. The surfeit of genomic data means that theoretical population geneticists are required now more than ever to help formulate scientifically-interesting questions.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Models</span>"
    ]
  },
  {
    "objectID": "models.html#on-nuance-and-rigor",
    "href": "models.html#on-nuance-and-rigor",
    "title": "1  Models",
    "section": "1.8 On Nuance and Rigor",
    "text": "1.8 On Nuance and Rigor\nDo formal models capture every last detail of the human experience? No, of course not. They’re not meant to do that. In fact, the simplification of a model is very much a feature and not a bug. Nuance turns out not to be a desirable feature in theory (Healy 2017).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Models</span>"
    ]
  },
  {
    "objectID": "models.html#worldview-of-ecology-vs.-worldview-of-physics",
    "href": "models.html#worldview-of-ecology-vs.-worldview-of-physics",
    "title": "1  Models",
    "section": "1.9 Worldview of Ecology vs. Worldview of Physics",
    "text": "1.9 Worldview of Ecology vs. Worldview of Physics\nThe mechanistic model of the world does not work\nEconomics, social behavior, society, politics are not physical systems\nThis should be foregrounded. Maybe read Brian Arthur’s article:\nArthur (2021): “The economy becomes something not given and existing but constantly forming from a developing set of actions, strategies and beliefs — something not mechanistic, static, timeless and perfect but organic, always creating itself, alive and full of messy vitality.”\nAlso seen in the work of, e.g., May, Levin, and Sugihara (2008), May and Arinaminpathy (2010)\n\n\n\n\nAriely, D. 2008. Predictably Irrational: The Hidden Forces That Shape Our Decisions. New York: HarperCollins.\n\n\nArthur, W. Brian. 2021. “Foundations of Complexity Economics.” Nature Reviews Physics 3 (2): 136–45. https://doi.org/10.1038/s42254-020-00273-3.\n\n\nBird, R. B., and E. A. Smith. 2005. “Signaling Theory, Strategic Interaction, and Symbolic Capital.” Current Anthropology 46 (2): 221–48. https://doi.org/10.1086/427115.\n\n\nBird, R. B., E. A. Smith, and D. W. Bird. 2001. “The Hunting Handicap: Costly Signaling in Human Foraging Strategies.” Behavioral Ecology and Sociobiology 50 (1): 9–19. https://doi.org/10.1007/s002650100338.\n\n\nBird, Rebecca Bliege. 1999. “Cooperation and Conflict: The Behavioral Ecology of the Sexual Division of Labor.” Evolutionary Anthropology 8 (2): 65–75. https://doi.org/10.1002/(SICI)1520-6505(1999)8:2&lt;65::AID-EVAN5&gt;3.0.CO;2-3.\n\n\nBradley, Valerie C., Shiro Kuriwaki, Michael Isakov, Dino Sejdinovic, Xiao-Li Meng, and Seth Flaxman. 2021. “Unrepresentative Big Surveys Significantly Overestimated US Vaccine Uptake.” Nature 600 (7890): 695–700. https://doi.org/10.1038/s41586-021-04198-4.\n\n\nCollins, D., J. Morduch, S. Rutherford, and O. Ruthven. 2010. Portfolios of the Poor: How the World’s Poor Live on $2 a Day. Princeton: Princeton University Press. https://books.google.com/books?id=esDhcbEHOfkC.\n\n\nDriscoll, C., and S. Stich. 2008. “Vayda Blues: Explanation in Darwinian Ecological Anthropology.” In Against the Grain: The Vayda Tradition in Human Ecology and Ecological Anthropology, edited by B. Walters, B. McCay, P. West, and S. Lees, 175–91. Lanham, MD: AltaMira Press.\n\n\nEisenberg, Eric M. 1984. “Ambiguity as Strategy in Organizational Communication.” Communication Monographs 51 (3): 227–42. https://doi.org/10.1080/03637758409390197.\n\n\nEvans, Matthew R., Volker Grimm, Karin Johst, Tarja Knuuttila, Rogier de Langhe, Catherine M. Lessells, Martina Merz, et al. 2013. “Do Simple Models Lead to Generality in Ecology?” Trends in Ecology & Evolution 28 (10): 578–83. https://doi.org/10.1016/j.tree.2013.05.022.\n\n\nFrankenhuis, Willem E., and Daniel Nettle. 2020. “The Strengths of People in Poverty.” Current Directions in Psychological Science 29 (1): 16–21. https://doi.org/10.1177/0963721419881154.\n\n\nFrankenhuis, Willem, Karthik Panchanathan, and Paul E Smaldino. 2022. “Strategic Ambiguity in the Social Sciences.” MetaArXiv. https://doi.org/10.31222/osf.io/kep5b.\n\n\nGeertz, Clifford. 1973. The Interpretation of Cultures. New York: Basic Books.\n\n\nGunawardena, Jeremy. 2014. “Models in Biology: ‘Accurate Descriptions of Our Pathetic Thinking’.” BMC Biology 12 (1): 29. https://doi.org/10.1186/1741-7007-12-29.\n\n\nGurven, Michael, and Kim Hill. 2009. “Why Do Men Hunt? A Reevaluation of ‘Man the Hunter’ and the Sexual Division of Labor.” Current Anthropology 50 (1): 51–74. https://doi.org/10.1086/595620.\n\n\nHawkes, Kristen. 1991. “Showing Off: Tests of an Hypothesis about Men’s Foraging Goals.” Ethology and Sociobiology 12 (1): 29–54. https://doi.org/10.1016/0162-3095(91)90011-E.\n\n\nHawkes, Kristen, Kim Hill, and James F. O’connell. 1982. “Why Hunters Gather: Optimal Foraging and the Aché of Eastern Paraguay.” American Ethnologist 9 (2): 379–98. https://doi.org/10.1525/ae.1982.9.2.02a00100.\n\n\nHealy, Kieran. 2017. “Fuck Nuance.” Sociological Theory 35 (2): 118–27. https://doi.org/10.1177/0735275117709046.\n\n\nHenrich, Joseph, Steven J. Heine, and Ara Norenzayan. 2010. “The Weirdest People in the World?” Behavioral and Brain Sciences 33 (2-3): 61–135. https://doi.org/10.1017/s0140525x0999152x.\n\n\nHilborn, R., and M. Mangel. 1997. The Ecological Detective: Confronting Models with Data. Princeton: Princeton University Press.\n\n\nHolling, C. S. 1964. “The Analysis of Complex Population Processes.” The Canadian Entomologist 96 (1-2): 335–47. https://doi.org/10.4039/Ent96335-1.\n\n\n———. 1966. “The Strategy of Building Models of Complex Ecological Systems.” In Systems Analysis in Ecology, edited by Kenneth E. F. Watt, 195–214. Academic Press. https://doi.org/10.1016/B978-1-4832-3283-6.50014-5.\n\n\nKahneman, D. 2011. Thinking, Fast and Slow. New York: Farrar, Straus; Giroux.\n\n\nKaplan, H., and K. Hill. 1992. “The Evolutionary Ecology of Food Acquisition.” In Evolutionary Ecology and Human Behavior, edited by E. A. Smith and B. Winterhalder, 167–201. Hawthorne, NY: Aldine de Gruyter.\n\n\nKaplan, H., K. Hill, J. Lancaster, and A. M. Hurtado. 2000. “A Theory of Human Life History Evolution: Diet, Intelligence, and Longevity.” Evolutionary Anthropology 9 (4): 156–85. https://doi.org/10.1002/1520-6505(2000)9:4&lt;156::AID-EVAN5&gt;3.0.CO;2-7.\n\n\nLehman, John T. 1986. “The Goal of Understanding in Limnology.” Limnology and Oceanography 31 (5): 1160–66. https://doi.org/10.4319/lo.1986.31.5.1160.\n\n\nLevins, Richard. 1966. “The Strategy of Model Building in Population Biology.” American Scientist 54 (4): 421–31. http://www.jstor.org/stable/27836590.\n\n\nMacArthur, Robert H., and Eric R. Pianka. 1966. “On Optimal Use of a Patchy Environment.” The American Naturalist 100 (916): 603–9. http://www.jstor.org/stable/2459298.\n\n\nMay, R. M., and N. Arinaminpathy. 2010. “Systemic Risk: The Dynamics of Model Banking Systems.” Journal of The Royal Society Interface 7 (46): 823–38. https://doi.org/10.1098/rsif.2009.0359.\n\n\nMay, R. M., S. A. Levin, and G. Sugihara. 2008. “Complex Systems: Ecology for Bankers.” Nature 451 (7181): 893–95. https://doi.org/10.1038/451893a.\n\n\nMeng, Xiao-Li. 2018. “Statistical Paradises and Paradoxes in Big Data (I): Law of Large Populations, Big Data Paradox, and the 2016 US Presidential Election.” Annals of Applied Statistics 12 (2): 685–726. https://doi.org/10.1214/18-AOAS1161SF.\n\n\nMullainathan, S., and E. Shafir. 2013. Scarcity: Why Having Too Little Means so Much. New York: Henry Holt; Company. https://books.google.com/books?id=NTnjsTHrfj8C.\n\n\nMuthukrishna, Michael, and Joseph Henrich. 2019. “A Problem in Theory.” Nature Human Behaviour 3 (3): 221–29. https://doi.org/10.1038/s41562-018-0522-1.\n\n\nOrzack, Steven Hecht, and Elliott Sober. 1994. “Optimality Models and the Test of Adaptationism.” The American Naturalist 143 (3): 361–80. http://www.jstor.org/stable/2462735.\n\n\nRoughgarden, J., R. M. May, and S. A. Levin. 1989. Perspectives in Ecological Theory. Princeton: Princeton University Press.\n\n\nSchelling, T. C. 1960. Strategy of Conflict. Cambridge: Harvard University Press.\n\n\n———. 1978. Micromotives and Macrobehavior. New York: Norton.\n\n\nSmaldino, P. E. 2017. “Models Are Stupid, and We Need More of Them.” In Computational Social Psychology, edited by R. R. Vallacher, A . Nowak, and S. J. Read, 311–31. New York: Routledge.\n\n\nSmaldino, Paul E., and Richard McElreath. 2016. “The Natural Selection of Bad Science.” Royal Society Open Science 3 (9): 160384. https://doi.org/10.1098/rsos.160384.\n\n\nSmith, E. A., and B. Winterhalder. 1992. “Natural Selection and Decision Making: Some Fundamental Principles.” Book Section. In Evolutionary Ecology and Human Behavior, edited by E. A. Smith and B. Winterhalder, 25–60. New York: Aldine de Gruyter.\n\n\nSmith, Eric Alden. 1992a. “Human Behavioral Ecology: I.” Evolutionary Anthropology 1 (1): 20–25. https://doi.org/10.1002/evan.1360010107.\n\n\n———. 1992b. “Human Behavioral Ecology: II.” Evolutionary Anthropology 1 (2): 50–55. https://doi.org/10.1002/evan.1360010205.\n\n\nStephens, David W., and John R. Krebs. 1986. Foraging Theory. Princeton: Princeton University Press.\n\n\nSucci, Sauro, and Peter V. Coveney. 2019. “Big Data: The End of the Scientific Method?” Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences 377 (2142): 20180145. https://doi.org/10.1098/rsta.2018.0145.\n\n\nThaler, R. H. 2015. Misbehaving: The Making of Behavioral Economics. New York: W. W. Norton.\n\n\nVayda, Andrew P. 1995a. “Failures of Explanation in Darwinian Ecological Anthropology: Part I.” Philosophy of the Social Sciences 25 (2): 219–49. https://doi.org/10.1177/004839319502500205.\n\n\n———. 1995b. “Failures of Explanation in Darwinian Ecological Anthropology: Part II.” Philosophy of the Social Sciences 25 (3): 360–75. https://doi.org/10.1177/004839319502500305.\n\n\nVayda, Andrew P., and Bradley B. Walters. 1999. “Against Political Ecology.” Human Ecology 27 (1): 167–79. https://doi.org/10.1023/A:1018713502547.\n\n\nWestern, B. 2001. “Bayesian Thinking about Macrosociology.” American Journal of Sociology 107 (2): 353–78. https://doi.org/10.1086/323639.\n\n\nWimsatt, William C. 1987. “False Models as Means to Truer Theories.” In Neutral Models in Biology, edited by M. H. Nitecki and A. Hoffman, 23–55. New York: Oxford University Press.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Models</span>"
    ]
  },
  {
    "objectID": "evolution.html",
    "href": "evolution.html",
    "title": "2  Evolutionary Foundations",
    "section": "",
    "text": "2.1 Nothing In Biology Makes Sense\nExcept in light of evolution.\nEvolution is defined as change over time in inherited characteristics (Futuyma 2013). Mayr (1982) defined organic evolution as the change in allele frequencies over time. This is a bit old-fashioned because it doesn’t count certain important forms of evolutionary change.\nIt’s important to remember that not all change is evolutionary. For example, developmental change over the course of a single lifespan or the change in species composition over short time period (i.e., hundreds of years) are not evolutionary because they are not changes in inherited characteristics.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Evolutionary Foundations</span>"
    ]
  },
  {
    "objectID": "evolution.html#nothing-in-biology-makes-sense",
    "href": "evolution.html#nothing-in-biology-makes-sense",
    "title": "2  Evolutionary Foundations",
    "section": "",
    "text": "2.1.1 Mechanisms of Evolution\n\nMutation\n\nChanges to the underlying genetic sequence. By itself, mutation doesn’t have a big effect on changing allele frequencies, but it is the raw material of (organic) evolution.\n\nDrift\n\nRandom change in allele frequencies (or other heritable characteristics) due to sampling effects of finite populations.\n\nMigration\n\nMovement can change the frequencies of heritable characteristics across a landscape\n\nNatural Selection\n\nNatural selection is the only mechanism that can produce adaptation\n\n\nThere are three necessary and sufficient conditions for natural selection (3NS4NS)\n\nVariation in a phenotype\nHeritability of those phenotypes\nDifferential fitness based on this variation\n\nNote that natural selection is not equivalent to evolution. Natural Selection is just one mechanism by which organisms evolve. Now, it happens to be the most important mechanism from the standpoint of adaptation since adaptations can only arise from the action of natural selection.\nDrift is a mechanism that is systematically ignored by many evolution popularizers. The interactions of drift and natural selection can be powerful.\nWhat does natural selection explain? Two main phenomena: Diversity and Fitness. There have probably been more than 2 billion species (including extinct ones). where did they come from and why? The Darwinian solution is that “small heritable variations among individuals within a species become the basis of large differences between species” (Lewontin 1978). Second, as noted by Lewontin (1978), “Organisms fit remarkably well into the external world in which they live.”\n\n\n2.1.2 Modes of Selection\n\nx &lt;- seq(-3,3,length=1000)\nx0 &lt;- x[x&gt;1.5]\nx0 &lt;- c(x0[1], x0)\ndn &lt;- dnorm(x)\ndn1 &lt;- dn[x&gt;1.5]\nlength(dn1)\n\n[1] 250\n\n#[1] 250\ndn1 &lt;- c(dn1[250],dn1)\nplot(x,dnorm(x), type=\"l\", lwd=2, axes=FALSE, frame=TRUE, xlab=\"Phenotype\",\n     ylab=\"Probability Density\")\npolygon(x0,dn1,col=grey(0.65))\n\n\n\n\n\n\n\n\n\nx1 &lt;- x[x&lt; -1.5]\nx1 &lt;- c(x1[1], x1)\ndn2 &lt;- dn[x&lt; -1.5]\nlength(dn2)\n\n[1] 250\n\n#[1] 250\ndn2 &lt;- c(dn2,dn2[1])\nplot(x,dnorm(x), type=\"l\", lwd=2, axes=FALSE, frame=TRUE, xlab=\"Phenotype\",\n     ylab=\"Probability Density\")\npolygon(x0,dn1,col=grey(0.65))\npolygon(x1,dn2,col=grey(0.65))\n\n\n\n\n\n\n\n\n\nx2 &lt;- x[x&gt; -1 & x&lt;1]\nx2 &lt;- c(x2[1],x2)\ndn3 &lt;- dn[x&gt; -1 & x&lt;1]\nlength(dn3)\n\n[1] 332\n\n#[1] 332\ndn3 &lt;- dn3[-1]\ndn3 &lt;- c(0,dn3,0)\nplot(x,dnorm(x), type=\"l\", lwd=2, axes=FALSE, frame=TRUE, xlab=\"Phenotype\",\n     ylab=\"Probability Density\")\npolygon(x2,dn3,col=grey(0.65))\n\n\n\n\n\n\n\n\n\n\n2.1.3 Fitness\nWhat is fitness? Fitness is a demographic measure of proportional representation in a population Futuyma (2013): “average per capita rate of increase in numbers” (individual) “average per capita lifetime contribution of individuals of that genotype to the population after one or more generations” (genotype) Fitness combines survival and reproduction\nSteve Stearns has characterized fitness as a property “everyone understands; no one can define.”\nCritics of NS theory claim that fitness is tautological Dennett: “x is fitter than y if and only if x’s traits enable it to solve the”design problems” set by the environment more fully than y’s traits do.” Problem is that there are many design problems What counts as a ‘design problem’? A bit vague and metaphorical\nPropensity theory of fitness.\nRosenberg and Bouchard (2015) “there has been a wide consensus that the solution to problem of defining individual”fitness” is given by treating it as a probabilistic disposition.” propensity means that the fitter individual will not always succeed, therefore, “putting aside the tautology issue, there is also a scientific reason for favoring propensity approaches: since the theory of natural selection allows for drift, this qualification on its claims will be a welcome one.”\n\n\n2.1.4 What is Adaptation?\nAdaptation is a process by which organisms become better suited to their environments. Lasker (1969, 1481) provides a grand view of adaptation: “Adaptation is the change by which organisms surmount the challenges to life. In the broadest sense biological adaptation encompasses every necessary biological process.” Biological adaptation can only be achieved through natural selection We will refer to the adaptation that is produced by natural selection as “big-A Adaptation.”\nWriters within the human evolutionary sciences, such as Alland (1975), Bennett (1976), and Lasker (1969) noted that adaptation can be biological in the sense of the transgenerational change of phenotypes in response to regularities in the environment (what we would call “Big-A Adaptation”), but can also be physiological (Alland 1975), meaning a systemic adjustment to local conditions aimed at ensuring homeostasis within an individual’s lifetime. This is one variety of “Little-a adaptation.” The third variety noted by these authors is cultural adaptation that was the preoccupation of cultural ecologists. Bennett (1976) suggests that adaptation is one of the three primary subjects of study in cultural anthropology, along with thought and “interhuman activity.” Bennett (1976: 269) defines this form of adaptation as “The patterns and rules of social adjustment and change in behavior by individuals and groups in the course of realizing goals or simply maintaining the staus quo, and called by such terms as coping, adjustment, adaptation, adaptive dynamics, adaptive strategies, achievement, compromise, fulfillment.”\nGoodman (1963) noted that in adapting, biological systems simultaneous face in two directions: they must respond to the external environment such that they improve their chances of survival and reproduction. However, they must also adapt to the internal environment, which favors “the coherence and parsimony of the system as a system.” This idea that adaptation is simultaneously internal and external was also discussed by Godelier and other structural Marxists in the late 1960s and 1970s (Alland 1975).\nPhysiological constancy is called homeostasis and the desirability of homeostasis in physiological systems became a popular metaphor for adaptation more generally. For example, Rappaport (1971, 60) wrote “Adaptation here refers to the processes by which organisms or groups of organisms, through responsive changes in their own states, structures, or compositions, maintain homeostasis in and among themselves in the face of both short term environment fluctuations and long term changes in the composition or structure of their environments.”\nVayda and McCay (1975) likened adaptation to risk management, echoing the sentiments of pioneering development thinkers when talking about the economic preferences of the peasantry like Lipton (1968) (“Survival Algorithms”) and Scott (1977) (“Safety First”).\nThe modern view of adaptation is articulated by Lewontin (1978), namely, that the external world sets certain “problems” that organisms need to “solve”: “Adaptation is the process of evolutionary change by which the organism provides a better and better ‘solution’ to the ‘problem’ and the end result is the state of being adapted.” Naturally, we need to be careful with our intentional language. Intentional language in evolutionary biology is a shorthand for this more correct but cumbersome phrasing and its existence should necessarily not imply conscious choices, reasoning, or agency. Of course, things get complicated when talking about humans since these qualities often (though not always!) apply to human decision-making, as we will see in Chapter 4.\nOf course, engineering analysis has its own problems. Two sets of a priori decisions required: (1) Appropriate way to divide the organism, and (2) Describe what problem each part solves.\nThis amounts to creating descriptions of the organism and of the environment and then relating the descriptions by functional statements.\nThere are two ways to do this. First, start with the problems and try to infer which aspect of the organism is the solution, and second, start with the organism and then ascribe adaptive functions to each part. A basic assumption of all engineering analyses is ceteris paribus, that is all things being equal. How often do you think everything else is actually equal?\nStrongly adaptationist accounts focus on the engineering aspects of “organismal design” and tend to short-change the diversity that underlies all adaptation. Indeed, most contemporary approaches to to evolution and human behavior employ some element of what’s known as the phenotypic gambit. The basic idea of the phenotypic gambit is that we can ignore the genetic (and developmental) architecture of adaptation and focus simply on selection with the assumption that if selection is strong enough, phenotypes will respond. The problem is that selection is, in fact, constrained. It is constrained by the variability available for selection to work on. Moreover, it is constrained by correlations with other traits, as we will see in Section 2.2.\nWhen we actually manage to test it, the phenotypic gambit often fails (Hadfield et al. 2007).\n\n\n2.1.5 The Misunderstanding of Spencer, Morgan\n“This survival of the fittest, which I have here sought to express in mechanical terms, is that which Mr. Darwin has called ‘natural selection’, or the preservation of favoured races in the struggle for life.” (Spencer 1864: 444)\nSpencer and his followers clearly muddle the colloquial and technical meanings of “fitness” when they evoke this famous collocation. Fitness is a complex measure which, at the bare minimum, involves the product of survival and fertility. “Survival of the fittest,” therefore, is both tautological and incomplete. Those with higher fitness survive. What defines fitness? Survival. But, of course, it’s more than survival since fitness also depends on fertility. Individuals need to survive in order to reproduce.\nAlas this 19th century neckbeard is making a real resurgence in American culture.\nLewis Henry Morgan suggested that all societies passed through three stages of development. Savagery is characterized by acephalous social organization of bands of foragers. Barbarism is characterized by authoritarian leadership (“big man”), largely tribal social organization, food production and surpluses. Civilization is characterized by complex social organization and role differentiation.\nUnfortunately for the theories of Morgan and other unilineal social evolutionists, there is very little evidence for the type of lockstep, unilineal transformation envisioned by the Victorian cultural evolutionists. Ethnographically and archaeologically, we see frequent shifts from “more complex” to “simple” social organization, modes of production, and technology. A canonical example of this phenomenon of moving in and out of complex societies is the Kachin of Burma as described by Leach in his The Political Systems of Highland Burma.\nThe Kachin (Jingpo/Singpo) are native to Burma’s Kachin state and neighboring Dehong Dai and Jingpo Autonomous Prefecture in China, as well as Northeastern India’s Arunachal Pradesh and Assam. “Kachin” is probably British colonial name: Jinghpaw in their own (eponymous) language. Name derives from Kachin Hills of far-northern Burma/Myanmar. They were characterized as “barbarous” hill people, practicing animist religion (now mostly Christian). Kachin livelihoods are derived primarily from yam and upland-rice cultivation. Society was organized around clans with shifting alliances. Live in Lived in long houses.\nIn contrast, the Shan, native to Shan province immediately to the Southeast of Kachin province, were Theravāda Buddhists, occupying river valleys, who practiced lowland, wet-rice agriculture and had the associated “complex,” hierarchical social organization. They are the second largest ethnic group in Burma.\nAs documented by Leach, it turns out, they’re the same people! Leach writes that, rather than talking about different political systems in the north of Burma as independent entities, “they should clearly be thought of as part of a total system.”\nScott, Art of Not Being Governed, argues that the sort of social fluidity that Leach observed in the Burmese Highlands has actually been the rule for states historically. Indeed, Scott goes so far as to suggest that that the “barbarism” characteristic of the highland cultures of the Asian Massif are adaptations to prevent their societies from being incorporated into neighboring state actors! He doesn’t specifically use adaptationist language, but this is clearly the spirit of his argument.\nHistorian Richard Hofstader first coined the term Social Darwinism in 1944. In reference to philosophy of Progressive Era reformers that included Laissez-Faire capitalism, Eugenics, Imperialism. It relies on Spencer’s misunderstanding of “survival of the fittest”. So it’s not Darwinism at all, but Spencerism. Social Darwinsim has come to be associated with racist, nationalist philosophy of fascism and it is making a resurgence in the US among so-called “race scientists” and other self-appointed “rationalists.”\nTypological thinking is not how it works. Mayr: population thinking.\nAdaptation is the foil to typology and progressivism. Adaptation is local, environmentally specific and historically situated It is nonsensical to say that one species or population is ‘more evolved’ or ‘more advanced’ Statements about advancement are normative and should be understood as such\nAdaptation is dynamic and specific to local (and historically situated) environmental conditions Adaptations arise because certain phenotype variants have higher fitness in a particular environment Organisms do not necessarily become progressively more complex or better morphological complexity seems to be hard to lose once gained social complexity appears to move easily in either direction\n\n\n2.1.6 On Race\n“People are people so why should it be, you and I should get along so awfully?” Depeche Mode\nIn a pioneering study in 1972, Richard Lewontin capitalized on the explosion in molecular data on protein polymorphism to characterize the nature of human genetic diversity. Using standard statistical tools, he apportioned the total variation into three levels: individual, race, and subgroup within race. Lewontin used the standard five-race classification. He found that the great majority of the total genetic variation in the human species is contained at the level of the individual (87%). Race accounted for only 6% of the variation, with the rest held in subpopulations within race (Lewontin 1972).\nThis result has been replicated repeatedly. For example, Brown and Armelagos (2001) review studies in the approximately 30 years following Lewontin’s study. Every study showed the same qualitative pattern.\nBut what about the principal components plots that show clustering of human racial groups? Lewis et al. (2022) note that sampling of human populations for studies of diversity is circular. When samples are designed to maximize differences, it should not be surprising when differences (however small) appear.\nLewontin: “Human racial classification is of no social value and is positively destructive of social and human relations. Since such racial classification is now seen to be of virtually no genetic or taxonomic significance either, no justification can be offered for its continuance.”\nHumans are not very genetically diverse. Phylogenetic studies regularly show that the distances separating the most divergent humans from each other are much shorter than those separating the most-divergent apes (e.g., Gagneux et al. 1999). Overall, the much smaller popualtions of the other great apes have much more genetic diversity than the global human populations (Ruvolo 1997).\nFor example, chimpanzee populations on either bank of the Sanga River in Cameroon are about as different from each other as are different continental human populations (Bowden et al. 2012). As the Oxford geneticist Peter Donnelly noted, “that chimpanzees from habitats in the same country, separated only by a river, are more distinct than humans from different continents is really interesting. It speaks to the great genetic similarities between human populations, and to much more stability and less interbreeding over hundreds of thousands of years in the chimpanzee groups.”\nYou might hear the term “Lewontin’s Paradox” or “Lewontin’s Fallacy” thrown around by so-called “race scientists.” The paradox turns out not to be paradoxical at all, as shown by Roseman (2021), but arises from a misunderstanding of genetic diversity, phylogeny, and evolutionary process more generally. In brief, it is possible to assign people to ancestry groups based on shared derived genetic markers even when the great majority of overall genetic variation is contained at the individual level.\nThe biological insignificance of race is a highly unusual instance where the views of the population geneticsists like Lewontin and the evolutionary psychologists like John Tooby coincide. This is remarkable, as Tooby once commented to me that taking Dick Lewontin’s graduate seminar on population genetics was the biggest waste of time he had ever experienced! EPs maintain that psychological adaptations are complex and require a complex genetic (and ontogenetic) architecture to support. Complex adaptations tend to have low heritability, in the strict sense of the fraction of total phenotypic variance that is attributable to additive genetic variance. For EPs, psychological adaptations are like head number in humans: genetically controlled but essentially zero additive genetic variation underlying them.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Evolutionary Foundations</span>"
    ]
  },
  {
    "objectID": "evolution.html#sec-response",
    "href": "evolution.html#sec-response",
    "title": "2  Evolutionary Foundations",
    "section": "2.2 Response to Selection",
    "text": "2.2 Response to Selection\nMost of our understanding of the response of traits to selection comes from animal and plant breeding. Indeed, it was the artificial selection of breeders that inspired Darwin’s theory of natural selection.\nWhen selection acts on a trait, how will it respond? For a single trait, the response to selection depends on two things: (1) the strength of selection, and (2) the amount of variation in the trait.\nThe so-called Breeders’ Equation combines these elements. Consider the change in some phenotypic trait \\(z\\) under a single generation of selection. The predicted change is simply the product of the variability and the intensity of selection:\n\\[\n\\Delta z = h^2 S,\n\\] where \\(S\\) is the selection coefficient and \\(h^2\\) is a very particular measure of trait variability, called (narrow-sense) heritability. While the term “heritability” means colloquially how under genetic control a trait is, it means something quite specific in the breeders’ equation. In particular, heritability is the fraction of the total phenotypic variance that is attributable to additive genetic variance. Additive genetic variance is the variability contributed by independently-assorting loci and is the part of genetic variability that allows us to make predictions. There are other forms of genetic variability that are not accounted for by the breeders’ equation. For example, there is variability contributed by non-additive genetic effects like dominance. There is epistatic variance that arises from gene-gene interactions. There are non-genetic sources of total variance as well.\nNote that heritability is not squared. It’s just called \\(h^2\\) by convention to remind us that it’s a variance, which is conventionally \\(s^2\\).\nThe greater the variance, the greater the response. The greater the selection, the greater the response.\nWhen we consider more than one trait, we need to account for the possibility that different traits may covary. Lande (1979) generalized the breeders’ equation to multiple traits, known as the multivariate breeders’ equation. Rather than a single heritability value, the multivariate breeders’ equation uses a matrix which contains the additive genetic variances and covariances. Consider a simple \\(2 \\times 2\\) covariance matrix:\n\\[\n\\mathbf{G} = \\left( \\begin{array}{cc} V_1 & C_{12} \\\\ C_{21} & V_2 \\end{array} \\right)\n\\] On the diagonal of the matrix are the variances of the two traits (\\(V_1\\) and \\(V_2\\)). On the off-diagonals are the covariances between the traits. A covariance is essentially an unnormalized correlation. More technically, it is the expected value (average) of the product of the deviations of the two variables from their means:\n\\[\n\\operatorname{Cov}(X,Y) = E \\left[ (X-\\bar{X}) (Y - \\bar{Y}) \\right].\n\\] Because we work with the additive-genetic covariance matrix, rather than heritabilties, we change the selection coeficients somewhat to account for this. Rather than straight selection coefficients, the multivariate breeders’ equation typically uses a vector of selection coefficients divided by the phenotypic variance in each trait.\nPutting this all together, we get the change in the mean of a vector of \\(k\\) traits \\(\\mathbf{z} = (z_1,z_2, \\ldots, z_k)\\) as:\n\\[ \\Delta \\mathbf{\\bar{z}} = \\mathbf{G \\beta}, \\]\nwhere \\(\\Delta \\mathbf{\\bar{z}}\\) is the change in the mean fitness of a multivariate trait, \\(\\mathbf{G}\\) is the additive genetic variance-covariance matrix, and \\(\\beta\\) is the normalized selection gradient on \\(\\mathbf{\\bar{z}}\\).\nIn effect, \\(\\beta\\) is a vector pointing in the direction of the optimal change in the phenotype. The matrix \\(\\mathbf{G}\\) does two things to this gradient pushing \\(\\mathbf{\\bar{z}}\\) toward its optimum: (1) it scales the response depending on how much additive variance there is in each trait and (2) it rotates it as a function of the covariances between traits. I won’t get too much into matrix multiplication here (this is a very nice reference too). The key point is that \\(\\mathbf{G}\\) is a square \\(k \\times k\\) matrix (where \\(k\\) is the number of traits we’re looking at) the diagonal elements of which are variances and the off-diagonal elements of which, \\(g_{ij}\\) represent the covariances between traits \\(i\\) and \\(j\\). Selection requires variance. Without sufficient variance, even strong selection won’t change the phenotype much between generations. But variance isn’t all there is to it. When the covariances are positive, there will be substantial indirect selection, and when they are negative, you have genetic constraints at work. Selection may be pointing in a particular direction, but the structure of the trade-offs could very easily mean that you can’t actually get there.\nLet’s consider three quick (toy) examples. Say we have two traits, maybe “length” and “width” (this could be something less vague and insipid: Lande (1979) looks at brain mass and body mass in a serious two-trait example). We will assume that the selection gradient is \\(\\mathbf{\\beta} = \\{0.5, 0.25\\}'\\). That is, the force of selection is twice as high on length as it is on width, but it is pretty strong and positive on both. We’ll demonstrate the effect of variance and constraint in three ways: (1) more variance in the trait under weaker selection (\\(\\mathbf{G_1}\\)), (2) positive covariance between the two traits (\\(\\mathbf{G_2}\\)), and (3) negative covariance between the two traits (\\(\\mathbf{G_3}\\)).\n\\[ \\mathbf{G_1} = \\left( \\begin{array}{cc} 0.33 & 0.00 \\\\ 0.00 & 0.67 \\end{array} \\right) \\]\n\\[ \\mathbf{G_2} = \\left( \\begin{array}{cc} 0.33 & 0.33 \\\\ 0.33 & 0.67 \\end{array} \\right) \\]\n\\[ \\mathbf{G_3} = \\left( \\begin{array}{cc} 0.33 & -0.33 \\\\ -0.33 & 0.67 \\end{array} \\right) \\]\nThe figure below plots the response to selection in the three different types of genetic architecture. The direction of selection is indicated in the grey arrow. If the variances of the two traits were equal to 1 and there were zero covariances, this is where selection would move the phenotype pair (try it). We can see that the response to selection moves toward width (the trait under weaker selection) even when covariances are zero (black arrow). Why? Because there is more variance for width than there is for length (\\(0.67 \\times 0.25 &gt; 0.33 \\times 0.5\\)). This effect becomes more pronounced when there is positive covariance between the traits (blue arrow) – the selection toward width is \\(0.33 \\times 0.5 +0.67 \\times 0.25 = 0.3325\\). When the covariances are negative, we see something cool (red arrow). The response to selection is small and moves (almost) entirely in the direction of length. This is because the negative covariance between length and width, when acted on by the strong selection on length, all but cancels out the positive response to selection (\\(-0.33 \\times 0.5 + 0.67 \\times 0.25 = 0.0025\\)).\n\ns &lt;- c(0.5,0.25)\nG &lt;- matrix(0.5*c(1,0,0,1), nr=2,byrow=TRUE)\nG1 &lt;- matrix(c(0.33,0,0,0.67), nr=2,byrow=TRUE)\nG2 &lt;- matrix(c(0.33,0.33,0.33,0.67), nr=2,byrow=TRUE)\nG3 &lt;- matrix(c(0.33,-0.33,-0.33,0.67), nr=2,byrow=TRUE)\n#\n(Dw1 &lt;- G1%*%s)\n\n       [,1]\n[1,] 0.1650\n[2,] 0.1675\n\n(Dw2 &lt;- G2%*%s)\n\n       [,1]\n[1,] 0.2475\n[2,] 0.3325\n\n(Dw3 &lt;- G3%*%s)\n\n       [,1]\n[1,] 0.0825\n[2,] 0.0025\n\n## simple plotting function to demonstrate stretching and rotation of\n## the G matrix on the seleciton gradient G in two dimensions\nplot.vector &lt;- function(s,G=NULL,plot.both=TRUE,color=\"black\"){\n  x &lt;- seq(0,1,length=100)\n  plot(x,x, type=\"n\", xlab=\"Length\", ylab=\"Width\")\n  arrows(0,0,s[1],s[2], lwd=3, col=grey(0.85))\n  if(plot.both){\n    Dw &lt;- G%*%s\n    arrows(0,0,Dw[1],Dw[2], lwd=3, lty=1, col=color)\n  }\n}\n# independent\nplot.vector(s,G1)\ntitle(\"Independent\")\n\n\n\n\n\n\n\n# positive covariance\nplot.vector(s,G2, color=\"blue\")\ntitle(\"Positive Covariance\")\n\n\n\n\n\n\n\n# negative covariance\nplot.vector(s,G3, color=\"red\")\ntitle(\"Negative Covariance\")\n\n\n\n\n\n\n\n\nThis simple demonstration shows that the response to selection can be complex. Making an argument that some trait would be under selection is not sufficient to say that it actually evolved (or will evolve) that way. Entirely plausible arguments for the direction of selection are made all the time in evolutionary anthropology. Here is one from a very important paper in paleoanthropology (Lovejoy 1981: 344):\n\nAny behavioral change that increases reproductive rate, survivorship, or both, is under selection of maximum intensity. Higher primates rely on social behavioral mechanisms to promote survivorship during all phases of the life cycle, and one could cite numerous methods by which it theoretically could be increased. Avoidance of dietary toxins, use of more reliable food sources, and increased competence in arboreal locomotion are obvious examples. Yet these are among the many that have remained under stading selection throughout much of the course of primate evolution, and therefore unlikely that early hominid adaptation was a product of intensified selection for adaptations almost universal to anthropoid primates.\n\nArguing for selection without considering trade-offs can get you into trouble. Selection in the presence of quantitative genetic constraints (or even differential variance in the traits) can produce counter-intuitive results. In the case of Lovejoy’s argument, there are good reasons to think that survivorship and reproductive rate are, indeed, strongly negatively correlated. Moreover, Lovejoy’s quote seems to imply that behavioral changes that increase either reproductive rate (i.e., fertility) or survivorship are under equal selection (namely, maximum). Is this true? In general, the selection intensity tends to change quite systematically across different demographic traits (i.e., survival, fertility). For humans (or hominins more generally), which traits are under under stronger selection, fertility or survival? Which have more additive variance? How strong are the negative covariances?\nWhen we make selectionist or adaptationist arguments, we should always keep in the back of our minds the three questions:\n\nHow strong is the force of selection?\nHow much variance is there on which selection can act?\nHow is the trait constrained through negative correlations with other traits?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Evolutionary Foundations</span>"
    ]
  },
  {
    "objectID": "evolution.html#approaches-to-human-evolutionary-ecology-and-behavior",
    "href": "evolution.html#approaches-to-human-evolutionary-ecology-and-behavior",
    "title": "2  Evolutionary Foundations",
    "section": "2.3 Approaches to Human Evolutionary Ecology and Behavior",
    "text": "2.3 Approaches to Human Evolutionary Ecology and Behavior\nEvolutionary concepts have been systematically applied to the study of human behavior. Different schools of thought have emerged. Overall, there are three broadly recognized approaches: (1) evolutionary psychology, (2) human behavioral ecology, and (2) cultural evolution. These approaches certainly suffer from the narcissism of small differences, but there are also some important substantive differences\nEvolutionary psychology (EP) is an approach to studying human behavioral biology that largely developed out of the sociobiology tradition in the late 1980s and 1990s. Central to EP is the logic of natural selection leading to extensive adaptation, particularly in psychological mechanisms. As the name implies, the clear analytical focus of EP is psychological mechanisms. The ubiquity of adaptation in psychological mechanisms is related to the concept of modularity. The idea of cognitive modules is attributable to the work of Fodor (1983). According to Fodor, modules are reflex-like encapsulations of critical functions that are anatomically localized within the brain. The encapsulation of function suggests that modules are domain specific.\nBecause of the complexity of adaptive psychological mechanisms, there is also a very strong emphasis on human universality. For EP, complexity of design implies uniformity across individuals, as seen, for instance, in the argument of John Tooby and Cosmides (1990, 17), “complex adaptations necessarily require many genes to regulate their development, and (b) sexual recombination makes it improbable that all the necessary genes for a complex adaptation would be together at once in the same individual, if genes coding for complex adaptations varied substantially between individuals.”\nThe scientific process of EP is largely inductive. Relying heavily on the ubiquity of adaptation, regularities in human behavior are “reverse-engineered” to determine what adaptive problem they solve. Historically, there is less emphasis in understanding the building blocks of evolution. EP tends to focus on universals in human behavior with little interest in understanding the variability the underlies evolution by natural selection.\nA feature of EP that is particularly noteworthy in the context of human decision-making and ultimately understanding human health in the contemporary world is the emphasis on adaptive lag. This logic can be seen in a paraphrase of the title of Tooby & Cosmides’s foundational paper (J. Tooby and Cosmides 1990), the past explains the present. Adaptations arise as solutions to problems in particular environments. When the specific environmental, physiological, social, or information-processing problems remain relatively stable for long periods of time, we expect to see extensive, frequently complex, adaptations to these problems. When selective milieux change relatively abruptly, there is no expectation that adaptations will track these changes. The putative existence of such adaptive lags have proven central to the emerging field of Darwinian Medicine as we will see in several later chapters.\nFor much of its history, EP has been largely laboratory-based and experimental in its approach to hypothesis-testing. Increasingly, EP-associated anthropologists (and other scientists) have taken ideas from EP to the field in more traditional ethnographic contexts.\nIn the context of human decision-making, Evolutionary psychologists have shown that the framing of decision problems matters enormously. For example, Cosmides has shown that people are generally much better at the Wason Selection Test, a test of logical reasoning, when the test is framed as a social contract than when the test is presented as an abstract problem (as is more typical in psychological research).\nA research tradition at the intersection of Psychology and Economics, which Todd and Gigerenzer (2012) have called the Biases and Heuristics tradition (discussed further in section Chapter 5), has repeatedly demonstrated that people are not particularly good probabilists. For example, in probably the canonical paper on the subject, Kahneman and Tversky (1973, 237) write, “In making predictions and judgments under uncertainty, people do not appear to follow the calculus of chance or the statistical theory of prediction. Instead, they rely on a limited number of heuristics which sometimes yield reasonable judgments and sometimes lead to severe and systematic errors.” Gigerenzer (1991) and Cosmides and Tooby (1996) have shown that people are generally much better at reasoning about probabilities when they are presented as frequencies than as abstract probabilities. When presented with probabilistic reasoning tasks similar to those employed by Kahneman & Tvesrsky, these authors find that subjects’ decision-making under uncertainty improves substantially, coming much closer to the normative utilitarian predictions of classical decision theory. These authors argue that reasoning about frequencies is a much more ecological and evolutionarily salient activity than reasoning about one-off probabilities.\n\n2.3.1 Which humans behave adaptively and why does it matter?\nThere is a fundamental tension in the way that evolutionary anthropologists think about natural selection and adaptation of human populations. On the one hand, evolutionary psychologists emphasize environmental inertia and adaptive disequilibrium. This contrasts with the approach of human behavioral ecologists, who generally favor adaptation in the present, largely by means of behavioral plasticity. We first see these issues brought to the fore in the late 1980s and early 1990s, starting with a couple provocative papers by Donald Symons, an anthropologist at UCSB.\nSymons (1989) writes “adaptive design is usually manifested at the psychological rather than at the behavioral level, that measuring reproductive differentials is at best an inefficient and ambiguous way to illuminate adaptation, and that Darwin’s theory of natural selection sheds light on human affairs only insofar as it promotes understanding of the psychology that underpins these affairs.” In a classic study of Tibetan polyandry (an extremely rare marriage form in humans), Crook and Crook (1988) argue that the adoption of polyandry is, in fact, functional in an adaptive sense. Symons criticizes this position by suggesting that it could only be an adaptation if humans possessed a “polyandry gene.” Irons (1990) defends Crook and Crook, noting “in criticizing Crook and Crook (1988) for arguing that Tibetan polyandry is an expression of evolved mechanisms without postulating specific genes for polyandry. If human beings evolved to track a wide variety of different mating opportunities and arrangements, their psychological mechanisms might well lead some of them to form polyandrous unions not because of genes for polyandry but because of genes for tracking many possibilities.”\nA foundational work in the development of contemporary evolutionary psychology was written by John Tooby and Leda Cosmides in 1990 in part of the exchange surrounding the publication of Symons’s provocative paper. In it, they write: “an evolutionary functionalism that leapfrogs the characterization of adaptations and in its place simply catalogues correspondences between present behavior and present fitness is incomplete and is often guided by serious misinterpretations of Darwinism” (J. Tooby and Cosmides 1990: 377).\nCentral to the argument of Tooby, Cosmides, and other evolutionary psychologists is the idea of the Environment of Evolutionary Adaptedness (EEA). This idea was borrowed by Tooby from the developmental psychologist, John Bowlby, the father of attachment theory. Bowlby saw the environment of evolutionary adaptedness as the environment in which a behavior is adaptive. Tooby & Cosmides write that the second goal of EP analysis is: “An analysis of how these principles were manifested as a species-specific array of selection pressures, refracted through the specific ecological, social, genetic, phylogenetic, and informational circumstances experienced along a given species’ evolutionary history.” Together, these characterize the “ancestral conditions,” or “the environment of evolutionary adaptedness.” For Tooby & Cosmides, the task of evolutionary psychology is the “task analyses of what information processing problems an adaptation must solve.”\nThere is, unfortunately, a tendency for this interesting idea of an EEA to devolve into a caricature of the human hunter-gatherer Pleistocene. Anatomically modern Homo sapiens sapiens appears just over 50,000 years ago, with substantial discontinuities in behavior as indicated by the archaeological record (art, ritual, distinct local cultural variation). Foley (1995, 195–96) noted, “New chronologies for the evolution of Homo sapiens, which stress a break between archaic and modern humans and involve recent colonization (\\(&lt;60\\) Kyr) of most parts of the world, have removed the notion of ‘two million years of hunter-gathering,’ reduced the chronological disparity between agriculture and hunting and gathering, and highlighted major differences between continents.”\nIs 400 generations really such a short time? Particularly if selection is very strong?\nIrons, citing the work of Richard Alexander, suggests that most human psychological adaptations are to dealing with other human beings and that there is continuity in this over the Holocene. The Pleistocene was hardly constant.\nAlways ask yourself what are the testable, unique hypotheses being posited by a particular approach to human behavior? If there is no empirical jeopardy of the adaptive predictions, is it science?\nTo what extent do contemporary humans need to be in a state of adaptive disequilibrium for the past-explains-the-present type reasoning to still apply? Does evidence of extensive recent adaptation jeopardize the EP position?\nLife is full of trade-offs. If all cognitive mechanisms are specific to the particular domain, i.e., if they “carve the psyche more nearly to its joints” (Daly and Wilson 1999: 510), how does behavior arise when a decision affects two (or more) distinct domains? What mechanism adjudicates the trade-off between the two domain-specific information processing mechanisms? Presumably, this will be some general-purpose executive function. If such trade-offs are common, then does it not make more sense to focus on this executive function and the conditions in which one decision is favored over another?\nAs noted by Smith, Mulder, and Hill (2001, 131), “two decades of research on the psychological adaptations underlying mating preferences has generated a list of the sexual and parental cues men and women look for in mates, but almost no information on how these cues are contextually weighted, how they interact with one another, and how they are used in the real world of mating markets and biological clocks.”\nOn the EP emphasis on adaptive lag, Laland & Brown (2002: 144) write, “since no one really knows to what extent the past and present selective environments differe from that trait, itis entirely possible that most human adaptations could produce adaptive behaviour in the modern environment, and it would be premature to assume that most would not.”\nWe certainly need an evolutionary psychology. I’m not sure we need the evolutionary psychology as currently practiced. This said, there has been a great deal of scientific progress in the field by the best practitioners (and a great deal of regression toward some social bads such as race science and social Darwinism more generally) by the worst practitioners.\nI am hopeful for a better EP in the future that incorporates more insights from developmental and cognitive psychology in particular.\n\n\n2.3.2 Human Behavioral Ecology\nThere are a couple of common uses of the term adaptation in the literature on human ecology and behavior (Jones, Ready, and Pisor 2020). Acclimatization refers to the modulation of physiological parameters to adjust to local environmental changes such as temperature, altitude (i.e., pressure), drought or other physiological stresses. An “adaptation” in the physiological sense refers to an acclimatization that essentially becomes permanent within an individual’s lifetime. If the environmental changes that led to acclimatization and eventually adaptation become regular, then the organism might specifically change its phenotype in response to selection. There are efficiency gains to having the adapted phenotype more “hard-wired.” However, there is a potential cost in terms of reduced capacity to respond to further environmental change.\nAdaptive plasticity is clearly a major part of the human adaptive suite. This of course raises questions about what types of environments favor extensive adaptive plasticity?\nThe HBE approach to understanding human behavior relies heavily on the idea of adaptive plasticity. It assumes that people are generally able to make sensible decisions over important matters of evolutionary significance (e.g., food acquisition, reproductive decisions). It favors the specification of optimality solutions to problems, placing a premium on measuring costs and benefits associated with particular behavioral decisions.\nDavies & Krebs (1977) define behavioral ecology, noting principally its comparative approach to studying adaptation, which dates to the work of Crook and Lack (e.g., Crook 1964, Crook & Garland 1966; Lack 1948). The then-coalescing field of behavioral ecology combined this comparative approach to understanding adaptation with ethological work testing hypotheses about the “survival value” of behavior that emerged from Tinbergen’s work (Tinbergen et al. 1967) and the formal approach to ecology championed by Robert MacArthur.\nIn many respects Human Behavioral Ecology is a distinct field but with obvious linkages. HBE comes as much out of the cultural ecology of Julian Stewart as the behavioral ecology that that synthesized the approaches of Lack, Crook, Tinbergen, and MacArthur.\nThe key features of HBE include: (1) the underlying logic of natural selection, (2) a hypothetico-deductive approach, and (3) an emphasis on behavioral strategies, flexibility, and decision-rules, (4) a piecemeal approach.\nThe logic of natural selection drives behavioral ecology generally and HBE in particular. On the whole, actual fitness is rarely measured. As noted by Davies & Krebs (1977: 1) “although pure population genetics and ecology only rarely appear in explicit form they obviously lurk just beneath the surface.” HBE uses an approach to studying adaptation identified by Grafen (1984) as the phenotypic gambit. In practice, taking the phenotypic gambit means that the researcher believes that the details of mechanism (both cognitive and genetic) and phylogeny do not matter, at least to a first approximation, for understanding adaptive behavior. More technically, it means assuming that there is sufficient additive genetic variation and a permissive covariance structure to this variation and that cognitive or other proximate mechanisms exist for making appropriately adaptive decisions in the ecological context.\nThe logic of natural selection allows HBE to overcome some of the shortcomings of functionalism by greatly limiting the domains of functional response and the currencies with which we measure this response (Winterhalder and Smith 2000). Many applications of HBE focus on behavior that is proximate to fitness. In particular, two of the most popular domains include foraging and life history. Efficiency is emphasized in foraging since energy saved in foraging can be reinvested in other fitness-promoting activities (e.g., having more children, generating new immune cells, spending more time socializing with potential political allies), though as we will see in section Chapter 9, there are substantial limits to the utility of efficiency as a behavioral or evolutionary objective.\nIn contrast to much of the classical work in cultural ecology, HBE is largely guided by a principle of methodological indvidualism. The primary locus of adaptive response is the individual and not the community or culture. Adaptive response of culture are seen as emergent phenomena of individual adaptations. Once again, this has some weaknesses.\nThe hypothetico-deductive approach of HBE essentially boils down to a simple, idealized recipe for the practice of science. First, the researcher formulates a simple model. Second, using some formal mechanism (e.g., logic, mathematics, computation), she generates hypotheses that can be tested using empirically gathered data. Third, gather data relevant to test the hypothesis. Fourth, confront the model predictions with the empirical data. Fifth, modify the original model as a result of this confrontation and start the cycle all over again. This is obviously an idealized rendition of the way that research is actually performed and says little about why a researcher might formulate a particular model in the first place.\nBehavioral flexibility is essential to the approach of HBE. An emphasis is generally placed on decision-making and the use of conditional strategies. A conditional strategy takes the form “If condition \\(X_1\\), perform action \\(Y_1\\), else \\(Y_2\\).” For example, a forager encountering prey type \\(i\\) will choose to pursue that prey if the expected rate of energy return for that type exceeds the overall average for the environment (Kaplan & Hill 1992).\nHBE shares a strong committment with anthropology more generally of ethnography. This is the extended in situ observation, measurement, and recording of behavior as performed in its immediate social, cultural, and ecological context.\nClassical behavioral ecology is actually a heavily experimental discipline (e.g., see Krebs & Davies 1977, 1984, 1991, 1998). This is generally not true of HBE. One exception to this lies in the articulation between HBE and ethno-archaeology. Archaeological evidence indicated the Great Basin foragers in the early Holocene largely ignored grass seed but later foragers relied on it heavily. Simms (1984) experimentally measured return rates for edible seeds and found that the processing costs were generally prohbitive. He was then able to calculate the threshold prey density at which seed-processing would become economically viable.\nMore observational approaches to to HBE also abound in ethnoarchaeological research Bird et al. (2002) show that the general lack of key species (e.g., large tridacnid clams) in Holocene shell middens in the Torres Straits does not mean that Holocene foragers did not take these prey. They show that the lack of these species’ remains in middens is consistent with contemporary foraging behavior on Mer where ethnographic evidence shows they are heavily exploited but nonetheless do not leave residues in contemporary middens. This puzzle is solved by understanding the nature of foraging trade-offs, noting that simple models of central-place foraging predict that such resources should be field-processed because of the burden of transporting the heavy shells of these large mollusks.\nThe most commonly voiced criticism of HBE comes primarily from EP. In particular, fitness maximization is taken to be naïve in confusing proximate motivation and ultimate mechanism. Daly and Wilson (1999, 512), while complaining that the views of EP were being caricatured by human behavioral ecologists, reduce the optimality approach favored by HBE as “imagining that evolution imparts a magic ability to find the course of action that maximizes inclusive fitness even in the face of evolutionarily unforeseen challenges.” Daly and Wilson (1999, 513) incorrectly attribute the preponderance of studies in HBE happening in small-scale societies as the desire by behavioral ecologists to study populations similar to the EEA: “An irony is that those who deride the EEA concept include researchers who have taken the trouble to study people in nonstate, face-to-face societies, presumably believing that such studies can afford important insights into human nature that could not be attained by studying the citizens of modern mass society.” Indeed, human behavioral ecologists tend to focus on small-scale societies because these are where functional hypotheses about subsistence and reproduction are most salient. Real people making real decisions with regard to real-world trade-offs, uncluttered (at least conditionally) by the complexities of the state. Furthermore, the importance of the comparative approch for behavioral ecology and HBE in particular places a premium on studies of face-to-face societies since the vast majority of behavioral and social research is performed on people living in (and fully integrated with) modern nation-states and market economies. This said, human behavioral ecologists have increasingly made forays into the behavior of people integrated with states and market economies (Gibson and Lawson 2014)\nSymons (1989) and J. Tooby and Cosmides (1990) dismiss the measurement of present-day fitness consequences of behavior altogether. Laland and Brown (2002) importantly note that measuring fitness consequences in the present, while no panacea, is certainly an important part of the evolutionary biologist’s toolkit (e.g., Endler (1986)).\nTurke (1990) notes that observing the contexts in which a particular behavior is adaptive – and importantly those in which it is not – provides important information about the selective background of the trait.\nPerhaps the best scientific rejoinder to the criticisms leveled by EP is simply the ability of a particular approach to make empirically supported predictions about behavior. Optimality models that use some form of fitness maximization as an objective function have fared well when applied to both human and nonhuman animal decisions (e.g., Real 1991).\nBeyond the criticisms of EP, there are other more general criticisms of HBE. One criticism of hypothetico-deductive approach is the ease with which it can be divorced from actual problems in the world. However, the analyses of HBE do, in fact, stem from observations of the world and regularities therein. For example, anthropologists of the functionalist tradition have long noted the remarkable fit between many human behaviors and the environments in which they are embedded. For example, the small size and flexibility of social organization of dry country hunter-gatherers such as the Western Shoshone or Ju/’hoansi.\nOptimality models have been more broadly criticized for assuming that observed phenotypes are, in fact, optimal. In their famous critique of adaptationist perspectives in biology, Gould and Lewontin (1979) deride the assumption of optimality as being “Panglossian,” alluding to the character of Dr. Pangloss in Voltaire’s Candide, who suggested that all was for the best in every situation.\nMaynard Smith (1978) and Parker and Maynard Smith (1990) note that the purpose of optimality models is not to show that the behavior is optimal. Rather, they are tools for understanding the behavior. Oster and Wilson (1978, 311–12) write, “Rather than a grande scheme for predicting the course of natural selection, optimization theory provides a tactical tool for making educated guesses about evolutionary trends.” Oster and Wilson (1978) go on to note that when predictions of a particular optimality model prove inadequate, the investigator knows precisely how to revise it since the assumptions that went into the model were explicitly and precisely made at the outset.\nAll the main evolutionary approaches to understanding human behavior take as their foundation such observations of fit between environment and behavior. It uses a priori reasoning about the action of natural selection (e.g., maximizing the long-run rate of energy gain in foraging or reproductive value in life history decision-making) to posit models for decisions.\nAs a distinct subset of the human evolutionary sciences, HBE is fading. We have largely failed to culturally reproduce. This said, the ideas of HBE permeate the human evolutionary sciences and human ecology more generally. Many of the latest generation of students trained by human behavioral ecologists have moved into more applied work in health, demography, conservation, development, and adaptation!\n\n\n2.3.3 Cultural Evolution\nHumans are cultural animals. Much of human adaptability is mediated by culture (Alvard 2003).\nThe perspective that I ultimately take on human adaptability melds these different approaches. We will discuss this topic at length in Chapter 4.\n\n\n\n\nAlland, Alexander. 1975. “Adaptation.” Annual Review of Anthropology 4 (1): 59–73. https://doi.org/10.1146/annurev.an.04.100175.000423.\n\n\nAlvard, Michael S. 2003. “The Adaptive Nature of Culture.” Evolutionary Anthropology 12 (3): 136–49. https://doi.org/10.1002/evan.10109.\n\n\nBennett, J. W. 1976. “Anticipation, Adaptation, and Concept of Culture in Anthropology.” Science 192 (4242): 847–53. https://doi.org/10.1126/science.192.4242.847.\n\n\nBird, R. B., D. W. Bird, E. A. Smith, and G. C. Kushnick. 2002. “Risk and Reciprocity in Meriam Food Sharing.” Evolution and Human Behavior 23 (4): 297–321. https://doi.org/10.1016/S1090-5138(02)00098-3.\n\n\nBowden, Rory, Tammie S. MacFie, Simon Myers, Garrett Hellenthal, Eric Nerrienet, Ronald E. Bontrop, Colin Freeman, Peter Donnelly, and Nicholas I. Mundy. 2012. “Genomic Tools for Evolution and Conservation in the Chimpanzee: Pan Troglodytes Ellioti Is a Genetically Distinct Population.” PLOS Genetics 8 (3): e1002504. https://doi.org/10.1371/journal.pgen.1002504.\n\n\nBrown, R. A., and G. J. Armelagos. 2001. “Apportionment of Racial Diversity: A Review.” Evolutionary Anthropology 10: 34–40. https://doi.org/10.1002/1520-6505(2001)10:1&lt;34::AID-EVAN1011&gt;3.0.CO;2-P.\n\n\nCosmides, Leda, and John Tooby. 1996. “Are Humans Good Intuitive Statisticians After All? Rethinking Some Conclusions from the Literature on Judgment Under Uncertainty.” Cognition 58 (1): 1–73. https://doi.org/10.1016/0010-0277(95)00664-8.\n\n\nCrook, John H., and Stamati J. Crook. 1988. “Tibetan Polyandry: Problems of Adaptation and Fitness.” In Human Reproductive Behavior, edited by L. Betzig, M. Borgerhoff Mulder, and P. W. Turke, 97–114. Cambridge: Cambridge University Press.\n\n\nDaly, Martin, and Margo I. Wilson. 1999. “Human Evolutionary Psychology and Animal Behaviour.” Animal Behaviour 57 (3): 509–19. https://doi.org/10.1006/anbe.1998.1027.\n\n\nEndler, J. A. 1986. Natural Selection in the Wild. Princeton: Princeton University Press. https://books.google.com/books?id=MYk1XbelDssC.\n\n\nFoley, Robert. 1995. “The Adaptive Legacy of Human Evolution: A Search for the Environment of Evolutionary Adaptedness.” Evolutionary Anthropology 4 (6): 194–203. https://doi.org/10.1002/evan.1360040603.\n\n\nFutuyma, D. J. 2013. Evolution. 3rd ed. Sunderland, MA: Sinauer Associates. https://books.google.com/books?id=YkrRlwEACAAJ.\n\n\nGagneux, Pascal, Christopher Wills, Ulrike Gerloff, Diethard Tautz, Phillip A. Morin, Christophe Boesch, Barbara Fruth, Gottfried Hohmann, Oliver A. Ryder, and David S. Woodruff. 1999. “Mitochondrial Sequences Show Diverse Evolutionary Histories of African Hominoids.” Proceedings of the National Academy of Sciences 96 (9): 5077–82. https://doi.org/10.1073/pnas.96.9.5077.\n\n\nGibson, M. A., and D. W. Lawson. 2014. Applied Evolutionary Anthropology: Darwinian Approaches to Contemporary World Issues. Springer New York. https://books.google.com/books?id=xAS9BAAAQBAJ.\n\n\nGigerenzer, Gerd. 1991. “How to Make Cognitive Illusions Disappear: Beyond ‘Heuristics and Biases’.” European Review of Social Psychology 2 (1): 83–115. https://doi.org/10.1080/14792779143000033.\n\n\nGoodman, M. 1963. “Man’s Place in the Phylogeny of the Primates as Reflected in Serum Proteins.” In Classification and Human Evolu­tion, edited by S. L. Washburn, 204–34. Chicago: Aldine.\n\n\nGould, S. J., and R. C. Lewontin. 1979. “Spandrels of San Marco and the Panglossian Paradigm: A Critique of the Adaptationist Program.” Proceedings of the Royal Society Series B-Biological Sciences 205 (1161): 581–98. https://doi.org/10.1098/rspb.1979.0086.\n\n\nHadfield, J. D., A. Nutall, D. Osorio, and I. P. F. Owens. 2007. “Testing the Phenotypic Gambit: Phenotypic, Genetic and Environmental Correlations of Colour.” Journal of Evolutionary Biology 20 (2): 549–57. https://doi.org/10.1111/j.1420-9101.2006.01262.x.\n\n\nIrons, W. 1990. “Let’s Make Our Perspective Broader Rather Than Narrower: A Comment on Turke Which Humans Behave Adaptively, and Why Does It Matter and on the so-Called DA-DP Debate.” Ethology and Sociobiology 11 (4-5): 361–74. https://doi.org/10.1016/0162-3095(90)90016-Y.\n\n\nJones, James Holland, Elspeth Ready, and Anne C. Pisor. 2020. “Want Climate-Change Adaptation? Evolutionary Theory Can Help.” American Journal of Human Biology 33 (4): e23539. https://doi.org/10.1002/ajhb.23539.\n\n\nKahneman, Daniel, and Amos Tversky. 1973. “On the Psychology of Prediction.” Psychological Review 80 (4): 237–51. https://doi.org/10.1037/h0034747.\n\n\nLaland, Kevin N., and Gillian R. Brown. 2002. Sense and Nonsense: Evolutionary Perspectives on Human Behaviour. New York: Oxford University Press.\n\n\nLande, Russell. 1979. “Quantitative Genetic Analysis of Multivariate Evolution, Applied to Brain:body Size Allometry.” Evolution 33 (1): 402–16. https://doi.org/10.1111/j.1558-5646.1979.tb04694.x.\n\n\nLasker, Gabriel W. 1969. “Human Biological Adaptability.” Science 166 (3912): 1480–86. https://doi.org/10.1126/science.166.3912.1480.\n\n\nLewis, Anna C. F., Santiago J. Molina, Paul S. Appelbaum, Bege Dauda, Anna Di Rienzo, Agustin Fuentes, Stephanie M. Fullerton, et al. 2022. “Getting Genetic Ancestry Right for Science and Society.” Science 376 (6590): 250–52. https://doi.org/10.1126/science.abm7530.\n\n\nLewontin, R. C. 1972. “The Apportionment of Human Diversity.” In Evolutionary Biology: Volume 6, edited by Theodosius Dobzhansky, Max K. Hecht, and William C. Steere, 381–98. New York, NY: Springer US. https://doi.org/10.1007/978-1-4684-9063-3_14.\n\n\n———. 1978. “Adaptation.” Scientific American 239 (9): 212–30. https://doi.org/10.1038/scientificamerican0978-212.\n\n\nLipton, Michael. 1968. “Theory of Optimising Peasant.” Journal of Development Studies 4 (3): 327–51. https://doi.org/10.1080/00220386808421262.\n\n\nLovejoy, C. Owen. 1981. “The Origin of Man.” Science 211 (4480): 341–50. https://doi.org/10.1126/science.211.4480.341.\n\n\nMaynard Smith, John. 1978. “Optimization Theory in Evolution.” Annual Review of Ecology and Systematics 9 (1): 31–56. https://doi.org/10.1146/annurev.es.09.110178.000335.\n\n\nMayr, E. 1982. The Growth of Biological Thought. Cambridge: Belknap.\n\n\nOster, G. F., and E. O. Wilson. 1978. Caste and Ecology in the Social Insects. Princeton: Princeton University Press.\n\n\nParker, Geoffrey A., and John Maynard Smith. 1990. “Optimality Theory in Evolutionary Biology.” Nature 348: 27–33. https://doi.org/10.1038/348027a0.\n\n\nRappaport, Roy A. 1971. “Ritual, Sanctity, and Cybernetics.” American Anthropologist 73 (1): 59–76. https://doi.org/10.2307/671812.\n\n\nReal, LA. 1991. “Animal Choice Behavior and the Evolution of Cognitive Architecture.” Science 253 (5023): 980–86. https://doi.org/10.1126/science.1887231.\n\n\nRoseman, Charles C. 2021. “Lewontin Did Not Commit Lewontin’s Fallacy, His Critics Do: Why Racial Taxonomy Is Not Useful for the Scientific Study of Human Variation.” BioEssays 43 (12): 2100204. https://doi.org/10.1002/bies.202100204.\n\n\nRosenberg, Alexander, and Frederic Bouchard. 2015. “Fitness.” In The Stanford Encyclopedia of Philosophy, edited by Edward N. Zalta. Metaphysics Research Lab, Stanford University. https://plato.stanford.edu/entries/fitness/.\n\n\nRuvolo, M. 1997. “Genetic Diversity in Hominoid Primates.” Annual Review of Anthropology 26: 515–40. http://www.jstor.org/stable/2952533.\n\n\nScott, James C. 1977. The Moral Economy of the Peasant: Rebellion and Subsistence in Southeast Asia. New Haven: Yale University Press.\n\n\nSmith, Eric A., Monique Borgerhoff Mulder, and Kim Hill. 2001. “Controversies in the Evolutionary Social Sciences: A Guide for the Perplexed.” Trends in Ecology & Evolution 16 (3): 128–35. https://doi.org/10.1016/S0169-5347(00)02077-2.\n\n\nSymons, D. 1989. “A Critique of Darwinian Anthropology.” Ethology and Sociobiology 10 (1-3): 131–44. https://doi.org/10.1016/0162-3095(89)90016-2.\n\n\nTodd, P. M., and G. Gigerenzer. 2012. Ecological Rationality: Intelligence in the World. Oxford: Oxford University Press. https://books.google.com/books?id=lO4EdShcg7AC.\n\n\nTooby, J., and L. Cosmides. 1990. “The Past Explains the Present: Emotional Adaptations and the Structure of Ancestral Environments.” Ethology and Sociobiology 11 (4-5): 375–424. https://doi.org/10.1016/0162-3095(90)90017-Z.\n\n\nTooby, John, and Leda Cosmides. 1990. “On the Universality of Human Nature and the Uniqueness of the Individual: The Role of Genetics and Adaptation.” Journal of Personality 58 (1): 17–67. https://doi.org/10.1111/j.1467-6494.1990.tb00907.x.\n\n\nTurke, P. W. 1990. “Which Humans Behave Adaptively, and Why Does It Matter?” Ethology and Sociobiology 11 (4-5): 305–39. https://doi.org/10.1016/0162-3095(90)90013-V.\n\n\nVayda, A. P., and B. J. McCay. 1975. “New Directions in Ecology and Ecological Anthropology.” Annual Review of Anthropology 4: 293–306. https://doi.org/10.1146/annurev.an.04.100175.001453.\n\n\nWinterhalder, B., and E. A. Smith. 2000. “Analyzing Adaptive Strategies: Human Behavioral Ecology at Twenty-Five.” Evolutionary Anthropology 9 (2): 51–72. https://doi.org/10.1002/(SICI)1520-6505(2000)9:2&lt;51::AID-EVAN1&gt;3.0.CO;2-7.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Evolutionary Foundations</span>"
    ]
  },
  {
    "objectID": "populations.html",
    "href": "populations.html",
    "title": "3  Population Ecology",
    "section": "",
    "text": "3.1 Population Growth\nA fundamental feature of the human predicament is the growth and size of human populations. Here, we will introduce some simple models of population growth that are essential for understanding human ecology, resource use, etc.\nThe total human population now substantially exceeds six billion people. Yet when modern humans first emerged on the savannas of Africa, our population was very small. Population growth—often dramatic—is a central feature of human history and the human experience. Here is a plot of the growth of the global human population from 10,000 years before present to the present day.\nyear &lt;- c(-10000, -8000, -6500,-5000,-4000,-3000,-2000,-1000, -500, -400, -200, 1, 200, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1250, 1300, 1340, 1400, 1500, 1600, 1650, 1700, 1750, 1800, 1850, 1900, 1910, 1920, 1930, 1940, 1950, 1975, 2000, 2024)\n\npop &lt;- c(1, 5, 5, 5, 7, 14, 27, 50, 100, 162, 150, 170, 190, 190, 190, 200, 207, 220, 226, 254, 301, 360, 400, 360, 443, 350, 425, 545, 470, 600, 629, 813, 1128, 1550, 1750, 1860, 2070, 2300, 2400, 4100, 6100, 8100)\n\nplot(year, pop, type=\"l\",\n                   lwd=2,\n                   col=\"red\",\n                   axes=FALSE,\n                   frame=TRUE,                \n                   xlab=\"Year\",\n                   ylab=\"Human Population (millions)\")\n\npts &lt;- c(-10000,-7500,-5000,-2500, 0, 1000, 1500, 2000)\nlbls &lt;- c(\"10000\",\"7500\",\"5000\",\"2500\",\"0\",\"1000\", \"1500\", \"2000\")\naxis(1, at=pts, labels=lbls)\naxis(2)\n,\nWe can see from this plot that there appear to be multiple regimes of apparent stagnation, moderate growth, occasional decline, and very rapid growth.\nCoale (1974) suggested that the median estimate for world hunter-gatherer populations at the dawn of agriculture was 8 million. Coale took the emergence of humans to be about a million years ago. Our contemporary understanding of human evolution indicates that it was a much more complicated process than was generally thought when Coale wrote his important paper on human population history. Rather than a million years of human history, contemporary paleoanthropologists would argue that anatomically modern humans represent the relevant population and that they have considerably less than a million years. Regardless of when we begin counting modern human populations (200Kya as suggested by mtDNA or 60Kya as suggested by the Upper Paleolithic Revoution), this implies a very small growth rate for much of human history on earth.\nEven if human population started with a hypothetical Adam and Eve, it has only doubled 32 times, with an average doubling time of 30,000 years. Coale, in fact, stated that the world has doubled 31 times. It just so happens that the total human population has approximately doubled again from the value of 3.9 billion that Coale cites in his 1974 paper!",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Population Ecology</span>"
    ]
  },
  {
    "objectID": "populations.html#population-growth",
    "href": "populations.html#population-growth",
    "title": "3  Population Ecology",
    "section": "",
    "text": "3.1.1 Simple Models of Population Growth\nConsider a closed population that has \\(N\\) individuals in it. A closed population is one in which there is neither immigration nor emigration. We perform a census every year and thus have measurements of the annual population size. Assume that the population is characterized by a per capita birth rate of \\(B\\) and a per capita death rate of \\(D\\). This means that in any given year there will be \\(N \\times B\\) births and \\(N \\times D\\) deaths. Note also that if there are \\(N \\times D\\) deaths, the surviving fraction of the population will be \\(N \\times (1-D)\\). Assume that these rates remain constant over some period of time. What happens to the population? As we move from one year to the next, the population will change. Next year’s population will consist of those who survived the current year (\\(N \\times (1-D)\\)) and those who entered the population in the current year (\\(N \\times B\\)). It is not difficult to see that as we go from our starting time, \\(t=0\\), to the next time, \\(t=1\\), the size of the population will simply be\n\\[\nN_1 = BN_0 + (1-D)N_0,\n\\]\nwhere the population size is subscripted by the year in which it is measured (thus, \\(N_0\\) is the population size in time zero).\nUsing elementary algebra, and writing \\(R = 1 + B - D\\), we can re-write this equation as\n\\[\nN_1 = RN_0.\n\\]\nSay now that we want to find the population size in for \\(t=2\\). This is clearly\n\\[\nN_2 = RN_1 = R(RN_0) = R^2N_0.\n\\] It should not be difficult to see that for any arbitrary time \\(t\\), given an initial population \\(N_0\\) and constant per capita birth and death rates \\(B\\) and \\(D\\), the size of the population will be\n\\[\nN_t = R^tN_0\n\\]\nThis is what is known as geometric growth. \\(R\\) is the multiplicative annual growth rate. Geometric growth occurs when constant birth and death rates work on a population in discrete time steps. Each year, the population increases (or decreases if deaths exceed births) by a factor of \\(R\\). Another way to think of this is that the ratio of the population size from one year to the next is a constant \\(R\\). This constant growth, without regard to the size of the population, can lead to very large populations quite quickly. This arises because the process of geometric growth is compounding. When t gets even moderately large and \\(R&gt;1\\), \\(R^t\\) can be a very big number.\n\nt &lt;- seq(1:100)\nR &lt;- rep(1.02,100)\nRR &lt;- R^t\n\nplot(0:100, c(1,RR),type=\"l\", xlab=\"Time\", ylab=\"Population Size\")\nsegments(0,1.02^0,20,1.02^0,lty=3)\nsegments(20,1.02^0,20,1.02^20,lty=3)\n\nsegments(20,1.02^20,40,1.02^20,lty=3)\nsegments(40,1.02^20,40,1.02^40,lty=3)\n\nsegments(40,1.02^40,60,1.02^40,lty=3)\nsegments(60,1.02^40,60,1.02^60,lty=3)\n\nsegments(60,1.02^60,80,1.02^60,lty=3)\nsegments(80,1.02^60,80,1.02^80,lty=3)\n\nsegments(80,1.02^80,100,1.02^80,lty=3)\nsegments(100,1.02^80,100,1.02^100,lty=3)\n\n\n\n\n\n\n\n\nGeometric growth applies when constant rates work on a population in discrete time steps. Remember, we measured the population size via a census every year and we assume that we only know the per capita birth and death rates on an annual time scale. In principle, human births and deaths do not happen on an annual scale. Rather, they occur more or less continuously throughout the year. However, data limitations usually mean that we only know things like population size or vital rates on an annual (or longer!) basis. The term geometric growth is perhaps not as familiar in common parlance as a related term, exponential growth. Exponential growth is simply the result of constant instantaneous birth and death rates working on a population in continuous time. Most applied work in demography (e.g., population forecasts) is done in discrete time because data are collected on an annual or decadal basis (e.g., the United States census). There are also some organisms in which life-cycle transitions do, in fact, happen on a more or less discrete basis. The population dynamics of organisms with marked birth seasonality or discrete life-cycle stages, such as most insects and many plants, are more naturally modeled in discrete time. However, most demographic and evolutionary theory is done in terms of continuous time so it is important to have a familiarity with the notation for this process as well. Unlike the geometric growth model, which requires only elementary algebra, solving the growth equation in continuous time requires calculus.\nWhen we work in continuous time, we write our instantaneous rates as lower case symbols, \\(b\\) and \\(d\\), and we define the instantaneous rate of increase (or decrease) as \\(r=b-d\\). The continuous growth model for an unstructured population is represented as a simple differential equation:\n\\[\n\\frac{dN}{dt} = rN\n\\] We solve this by separating variables and integrating, yielding\n\\[\nN(t) = N(0) e^{rt},\n\\]\nwhere \\(e=2.7183\\ldots\\) is the base of the natural logarithm.\nNote tha in the exponential growth case, all we have really done is substitute \\(e^r\\) for \\(R\\) (since \\((e^r)^t=e^{rt})\\). Thus the ratio of the population size in two successive years will be \\(e^r\\) and the ratio of population sizes between two times \\(t\\) years apart is \\(e^{rt}\\)\nAs with geometric growth, exponential growth can lead to very large population sizes quite quickly. Indeed, in everyday speech when a people say something is “increasing exponentially,” they are usually using a shorthand for “increasing really, really fast.” Populations can increase rapidly and not be increasing exponentially. Also, exponential growth is hardly the most rapid type of growth, as we will see shortly. When we use the term “exponential growth” what we mean is that the ratio of the population in two successive time steps is \\(e^r\\). Another way of saying this is that for exponential growth, the per capita rate of increase of the population remains constant, regardless of the size of the population.\nTo understand how this constant per capita growth works, it is useful to think in terms of the doubling time of the population. That is, how many years will it take for a population growing at instantaneous rate \\(r\\) to become twice as big as it currently is? We begin by noting that all we care about is the ratio of population size—we want to know when the population will be twice as big as it currently is, regardless of the specifics of the current size. We thus use values of \\(N(0)=1\\) and \\(N(t)=2\\). We can now solve the exponential gowth equation for \\(t\\) by taking natural logarithms of both sides and rearranging to yield\n\\[\n\\frac{0.6931}{r}=t.\n\\]\nThe numerator is simply the natural logarithm of 2 to four decimal places. If a population is growing with an instantaneous rate of 0.01 (1%), then it will take approximately 69 years to double. If it is growing at 2%, then it will double in 35 years. In the twentieth century, the world population increased at a rate of approximately 1.37%. This means a doubling time of 50.6 years. Thus, the human population doubled approximately twice in the twentieth century alone if we assume that the growth rate was constant. This equation can just as easily be used to find the halving time of a population that is declining at a constant rate as well (\\(\\log(0.5)=-0.6931\\)). Thus, a population declining at a constant rate of 1% (i.e., \\(r=-0.01\\)) will be half its current size in 69 years.\nWe can use this equation to calculate the average growth rate under an exponential model when we have two population estimates with a known interval between censuses. This time, we simply solve for \\(r\\), again taking natural logarithms of both sides:\n\\[\nr = \\frac{\\log N(t) - \\log N(0)}{t},\n\\]\nUsing values from the US Census Bureau’s historical estimates of world population, we can calculate the implied exponential growth rate for the total human population in the twentieth century as\n\\[\nr = \\frac{\\log(6100) - \\log(1550)}{100} = 0.0137.\n\\]\nReturning to Coale’s (1974) statement that the the human population has doubled only 32 times with an average doubling time of 30,000 years, even if it started from a hypothetical two individuals, we can see that the growth rate for Homo sapiens has been \\((\\log(6.7\\times 10^9) - \\log(2))/200,000=0.00011\\). Here, I have used the more conservative value for the origin of modern humans of 200kya, which is based on the coalescence time of mtDNA. Calculating the doubling time from this growth rate, we actually get \\(\\log(2)/0.0001=6,321\\). This doubling time is approximately five times shorter than Coale’s estimate because we use a time of 200k years instead of 1M years.\nWhen we plot the population size against time for the cases of both geometric and exponential growth, we will see that the curves are convex (i.e., bend up). They are characterized by positive second derivatives. A useful graphical diagnostic for such growth is to plot the logarithm of population size against time. Because of the role that the base of the natural logarithm plays in the exponential growth model, population biologists typically work with natural logarithms and that is what we will use here. For the case of exponential growth, take the natural logarithms of both sides of the growth equation:\n\\[\n\\log N(t) = \\log N(0) + rt\n\\]\nThis is an equation for a straight line with a \\(y\\)-intercept of \\(\\log N(0)\\) and slope of \\(r\\). This result is useful for a number of reasons. First, it is much easier to visually diagnose the existence of a straight line compared to an exponential curve. Second, it provides a simple means for estimating \\(r\\) using the statistical technique of linear regression.\n\n\n3.1.2 Balance\nWe have seen how a net excess of births over deaths can lead to explosive population growth. For instance the growth of the total human population from a hypothetical first woman and man to the 8 billion people inhabiting the earth today resulted from an excess of just one ten-thousandth over 200 thousand years. When thinking about mortality and fertility, it is useful to employ summary measures that have more intuitive appeal than annual (or especially instantaneous!) rates. The two most often used summary measures of mortality and fertility are life expectancy at birth and the total fertility rate respectively. Life expectancy at birth, which we denote as \\(e_0\\), actually has several interpretations that actually all mean the same thing. The most natural of these is that \\(e_0\\) is the average number of years lived by an individual born into the population. It is also the average age of death in a population. The total fertility rate is simply the sum of a hypothetical average woman’s age-specific fertility assuming that she lived to the end of her reproductive span.\nHuman populations exhibit tremendous diversity in demographic rates. In Jones (2009), I used four populations that largely bracket the demographic space our species occupies. I only considered combinations of mortality and fertility that yield a growth rate of \\(r&gt;0\\) since, in the long run, any population that averages a growth rate of \\(r \\leq 0\\) goes extinct.\n\n\n\nHuman demographic space. Isoclines show the growth rate implied by the combination of TFR and life expectancy. Triangles represent four populations that largely define the boundaries of human demographic space. From left to right: USA (low mortality, low fertility), !Kung (high mortality, low fertility, Venezuela in 1967 (low mortality, high fertility), and the Forest-period Ache (high mortality, high fertility).\n\n\nDespite all the demographic diversity exhibited by our species, in the aggregate, the world population has been very close to zero growth for nearly its entire history as seen in the long horizontal leg of the plot of historical population growth or in the calculation that the long-run rate of increase of the human species is just over one on-hundredth of a percent per year. This observation suggests that, while there is a large degree of diversity in observed patterns, the possible combination of fertility and mortality patterns are highly constrained. Zero growth means that the ratio of population size from one generation to the next is equal to one. This means that from the geometric-growth equation, \\(R=1\\) or from the exponential-growth equation, \\(r=0\\) so that \\(e^r=1\\). In order for this ratio to be equal to one from one generation to the next, it should be clear that the average person should exactly replace herself. If the average person lives for \\(e_0\\) years, then the average person should also have \\(1/e_0\\) (same-sex) offspring. If we denote the gross fertility rate as \\(b\\), the simple equation that specifies these relationships is\n\\[\ne_0\\, b = 1.\n\\] This equation comes in handy when you want to assess the plausibility of demographic arguments.\n\n\n3.1.3 Growth Rate of a Mixture of Populations\nA population size \\(Q\\), with growth rate \\(r\\), increases in numbers by \\(Qe^{rt}\\) over the interval \\(t\\). The intrinsic rate of increase, \\(r\\), is the per capita rate of increase of the population. Thus, by definition, we can write it as:\n\\[\n  r = \\frac{1}{N(t)}\\cdot\\frac{dN(t)}{dt}\n\\]\nFor a mixture of \\(n\\) subpopulations, each with its own rate of increase \\(r_{i}\\), the increase in interval \\(t\\) will simply be\n\\[ N(t) = \\sum_{i}^{n} Q_i e^{r_i t} \\]\nThe derivative of \\(N(t)\\) is\n\\[ \\frac{dN(t)}{dt} = \\sum_{i}^{n} Q_i r_i e^{r_i t} \\]\nSubstituting these, the overall rate of increase, \\(\\tilde{r}\\) is thus\n\\[\n\\tilde{r} = \\frac{1}{N(t)}\\cdot\\frac{dN(t)}{dt} =\n  \\frac{\\sum_{i}^{n} Q_i r_i e^{r_i t}}{\\sum_{i}^{n} Q_i e^{r_i t}}\n\\]\nThis is just a weighted mean of the subpopulation growth rates, with weights the initial population size of the subpopulations.\nHow does the mean rate of increase change? Differentiate \\(\\tilde{r}\\) with respect to \\(t\\):\n\\[ \\frac{d\\tilde{r}}{dt} = \\frac{\\sum_{i}^{n}\n  Q_i r^{2}_{i} e^{r_i t}}{\\sum_{i}^{n} Q_i e^{r_i t}} -\n  \\left(\\frac{\\sum_{i}^{n} Q_i r_i e^{r_i t}}{\\sum_{i}^{n} Q_i e^{r_i\n  t}}\\right)^2.\n\\] This messy looking equation actually has a pretty straightforward form, namely, \\(E(X^2) - E(X)^2\\), which is the definition of variance of the random variable \\(X\\). Thus,\n\\[ \\frac{d\\tilde{r}}{dt} = \\sigma^{2}(t) \\]\nWhat does this mean? First, clearly since variance is, by definition, non-negative, \\(\\tilde{r}\\) increases. Can it increase without bound? No, since \\(\\tilde{r}\\) is the average of an ensemble of constituent \\(r_i\\), it can never be greater than the largest of its constituents. Note that this derivation is reminiscent of Fisher’s Fundamental Theorem of Natural Selection. It also means that the sum of a mixture of population projections with different growth rates will grow faster than the the population projected by the mean growth rate. This arises because of Jensen’s Inequality, which states for a convex function (i.e., one with a positive second derivative like exponential growth):\n\\[ E[f(x)] \\geq f(E[x]). \\] In words, the expected value (i.e., mean) of a convex function of some random variable \\(X\\) is greater than or equal to the function of the expected value of \\(X\\).\nNote that the inequality is reversed for concave function, as we will see in Chapter 5.\n\n\n3.1.4 How Fast Can Human Populations Grow?\nCole (1954)\nThe derivation of this formula relies on assuming that age-specific demographic rates like fertility and survival are constant and then uses an identity for finite geometric sums, namely,\n\\[\n\\sum_{k=0}^{n} r^k = \\frac{1-r^{n+1}}{1-r}.\n\\] We will skip the derivation here, though you can find it in my Notes on Life History Theory.\nCole made some pretty heroic assumptions, the most notable of which is that there is no mortality in the population. Keeping this limitation in mind, Cole’s famous formula for the maximum possible growth rate is:\n\\[\n1 = e^{-r} + b e^{-r\\alpha} - be^{-r(n+\\alpha)},\n\\] where \\(b\\) is the birth rate, \\(\\alpha\\) is age at first reproduction, and \\(n\\) is the age of last reproduction/death.\nThis is the equation the defines what became known as Cole’s \\(r_{max}\\). It represents the best-case scenario for the growth of a population (since it assumes no mortality).\nWe can add just a bit of realism by adding mortality. As Slade, Gomulkiewicz, and Alexander (1998) note, we can just as easily assume that mortality is non-trivial. Continue to assume that mortality is constant within adults. Changes in age-specific mortality for pre-reproductives do not matter—all we need is the fraction of newborn individuals who survive to breeding age, \\(f\\). Assume that all adults have a constant survival probability \\(p\\). The fraction alive at age \\(x&gt;\\alpha\\) is thus \\(fp^{x-\\alpha}\\).\nThe generalization of Cole’s \\(r_{max}\\) equation that Slade, Gomulkiewicz, and Alexander (1998) derive is:\n\\[1 = p\\; e^{-r} + f\\; b\\; e^{-r\\alpha} - f\\; b\\; p^{n+1} e^{-r(n+\\alpha)}.\\] Some calculations. Use uniroot() to find the value of of \\(r\\) that solves the equation \\(F(r)-1=0\\), where \\(F(r)\\) is Cole’s or Slade et al.’s equation.\n\n# L = \\lambda = exp(r), multiplicative rate of increase\n# a = AFR\n# w = ALR\n# R = recruitment fraction (i.e., l(\\alpha))\n# b = annual fertility\n# p = annual survival probability\n\n## the function from Cole (1954)\ncole &lt;- function(r,a,w,b) exp(-r) + b*exp(-r*a) - b*exp(-r*(w+1)) - 1\n\n## see the output of uniroot -- growth rate is \"root\"\nuniroot(cole, lower=0.01, upper=0.1, a=20, b=0.125, w=50)\n\n$root\n[1] 0.04055331\n\n$f.root\n[1] 4.635049e-06\n\n$iter\n[1] 6\n\n$init.it\n[1] NA\n\n$estim.prec\n[1] 6.103516e-05\n\n## Compare great apes\n# chimps\nchimp &lt;- uniroot(cole, lower=0.01, upper=0.1, a=14, b=0.1, w=40)\n# gorillas\ngorilla &lt;- uniroot(cole, lower=0.01, upper=0.2, a=8, b=0.25, w=30)\n# orangutans\norangutan &lt;- uniroot(cole, lower=0.01, upper=0.1, a=14, b=0.0625, w=40)\n# Hutterites\nhutterites &lt;- uniroot(cole, lower=0.01, upper=0.2, a=20, b=0.3, w=50)\n\n(apes &lt;- round(c(Pan=chimp$root, Gorilla=gorilla$root, Orangutan=orangutan$root, Human=hutterites$root),3))\n\n      Pan   Gorilla Orangutan     Human \n    0.038     0.104     0.020     0.069 \n\n## expanded version from Slade et al. (1998)\ncole1 &lt;- function(L,a,w,R,b,p)  p*(L^-1) + R*b*(L^-a) - R*b*(p^(w - a +1))*(L^-(w+1)) - 1\n\nuniroot(cole1, lower=1, upper=1.2, a=20, b=0.125, w=45, R=0.8, p=0.98)\n\n$root\n[1] 1.023497\n\n$f.root\n[1] 2.737548e-05\n\n$iter\n[1] 4\n\n$init.it\n[1] NA\n\n$estim.prec\n[1] 6.103516e-05\n\n# use r instead of \\lambda to make comparable with Cole\n\ncole2 &lt;- function(r,a,w,R,b,p){\n  p*exp(-r) + R*b*exp(-r*a) - R*b*(p^(w - a +1))*exp(-r*(w+1)) - 1\n}\n\nuniroot(cole2, lower=0, upper=0.05, a=20, b=0.125, w=45, R=0.8, p=0.98)\n\n$root\n[1] 0.02324612\n\n$f.root\n[1] 7.988824e-07\n\n$iter\n[1] 5\n\n$init.it\n[1] NA\n\n$estim.prec\n[1] 6.103516e-05\n\n# what's a good value of R? 75% survival to age 5 and then 2% annual mortality\n# thereafter is not unreasonable\n(R &lt;- 0.75*0.98^15)\n\n[1] 0.5539268\n\n# Ache-like\nache &lt;- uniroot(cole2, lower=0, upper=0.05, a=20, b=0.2, w=45, R=0.55, p=0.98)\n## surprisingly close to Hill & Hurtado's observed r for the Forest Period\n# Hutterites\nhutterites2 &lt;- uniroot(cole2, lower=0.01, upper=0.2, a=22, b=0.3, w=50, R=0.75, p=0.99)\n(humans &lt;- round(c(Ache=ache$root, Hutterites=hutterites2$root), 3))\n\n      Ache Hutterites \n     0.026      0.052 \n\n\nThe most fecund population of humans ever recorded has a maximum growth rate of 6.9% annually, assuming no mortality, and 5.2% if we assume very low mortality. Of course, fertility is hardly constant across the nearly 30-year span of human reproduction. Even among the highly fecund Hutterites, fertility declines substantially with age. This means that this value of \\(r_{max} = 0.052\\) is much higher than what is realistically the maximum possible growth rate. This does not even account for the fact that mortality also increases with age (i.e., is not a constant 1% across adulthood) and the recruitment fraction of 75% is also high. Mortality removes newborns and pre-reproductive children from the potential breeding pool, but so do social factors such as failure to enter into a reproductive union. This value is frequently around 20%, even in conservative populations with very strong pro-natalist norms.\nIn reality, the highest growth rate achievable by actual human populations is probably quite close to that of Venezuela in the late 1960s. At the time, life expectancy at birth in Venezuela was nearly as high as it was in the United States, at almost \\(e_0=70\\). Despite this relatively low mortality, Venezuela in the late sixties was also characterized by extremely high fertility with a total fertility rate of more than seven! In 1967, the intrinsic rate of increase for Venezuela was \\(r=0.041\\). This seems like a pretty reasonable working value for the realistic maximum growth rate achievable by a human population. This matters a great deal as we will see in Chapter 5, since the it means that the upside of potential fitness-related gambles is highly constrained while the downsides are not.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Population Ecology</span>"
    ]
  },
  {
    "objectID": "populations.html#models-for-structured-populations",
    "href": "populations.html#models-for-structured-populations",
    "title": "3  Population Ecology",
    "section": "3.2 Models for Structured Populations",
    "text": "3.2 Models for Structured Populations\nAs we noted in the last section, demographic rates are not constant with age (and many other possible states). We can extend our simple models for population growth to account for age-structure. The characteristic equation for a population with given mortality and fertility schedules unites the important demographic concepts of mortality, fertility, age-structure, and growth into a single relationship. I will not derive the characteristic equation here, but you can check out my Notes on Life History Theory for a full derivation of the equations that characterize the stable population model, including the characteristic equation.\nWe typically assume what’s called female demographic dominance and analyze the female component of the population. Women give birth and the growth of populations is highly constrained by the female component.\nConsider a population with age-specific fertility rate \\(m(a)\\) for women age \\(a\\) and (cumulative) survival to age \\(a\\) of \\(l(a)\\). Let age at first birth be \\(\\alpha\\) and age at last birth be \\(\\beta\\). The characteristic equation, often called the Euler-Lotka equation, is then\n\\[  \n1 = \\int_{\\alpha}^{\\beta}  e^{-ra} l(a) m(a) da.\n\\] The unique solution is the value \\(r\\) that equates the two sides of the characteristic equation.\nIn a stationary population, where \\(r=0\\), \\(e^{-ra}=1\\) for all \\(a\\) (zero times anything is zero!), and the equation reduces to that for the net reproduction number, which is simply the sum of net fertility across all ages.\n\\[  \nR_0 = \\int_{\\alpha}^{\\beta}  l(a) m(a) da = 1.\n\\] In a stationary population, each woman replaces herself, on average, with a single daughter.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Population Ecology</span>"
    ]
  },
  {
    "objectID": "populations.html#matrix-population-models-for-structured-populations",
    "href": "populations.html#matrix-population-models-for-structured-populations",
    "title": "3  Population Ecology",
    "section": "3.3 Matrix Population Models for Structured Populations",
    "text": "3.3 Matrix Population Models for Structured Populations\nIt turns out that efforts to create a discrete-time form of the characteristic equation were often confused. The best way to represent structured populations in discrete time uses matrix algebra (H. Caswell 2001). Once again, you can find more details in my Notes on Life History Theory.\nThe Leslie matrix is a special matrix for demography and population biology. A Leslie matrix is sparse with two sets of non-zero elements: (1) age-specific fertilities (\\(F_j\\)) along the first row, and (2) age-specific survival probabilities (\\(P_i\\)) along the subdiagonal. Here is an example of a \\(5 \\times 5\\) Leslie matrix:\n\\[\n\\mathbf{A} = \\left[ \\begin{array}{ccccc}\n0     & F_{2}   & F_{3} & F_{4} & F_{5}\\\\\nP_{1} & 0       & 0     & 0     & 0 \\\\\n0     & P_2     & 0     & 0     & 0\\\\\n0     & 0       & P_3   & 0     & 0 \\\\\n0     & 0       & 0     & P_{4} & 0\n\\end{array} \\right]\n\\]\nA Leslie matrix is a representation of an age-structured population. We can also write demographic projection matrices for stage-structured populations.\nFor matrix \\(\\mathbf{A}\\), the entry \\(a_{ij}\\) is the transition probability of going from stage \\(j\\) to stage \\(i\\): \\(a_{ij} \\equiv a_{i \\leftarrow j}\\).\nA useful graphical tool to complement matrix models is the life-cycle graph, a directed graph that represents all the transitions in an organism’s life cycle. Like all graphs, the life-cycle graph is composed of a set of nodes and a set of edges. The nodes represent the states of the population such as the age classes, stages, subgroups, or localities (depending on the specifics of the model). The edges are directed and represent transitions between states. For the age-structured model, the only possible transitions are survival (from age-class \\(i\\) to age-class \\(i+1\\)) and fertility (from age-class \\(i\\) to age-class 1).\n\n\n\nLife-cycle graph corresponding to the \\(5 \\times 5\\) Leslie matrix\n\n\nDemographic projection matrices typically fall under the heading of non-negative negative matrices, such that when raised to sufficient powers, all matrix elements become positive. Moreover, if our projection matrix has two properties (which not all will), then the population will eventually be characterized by a stable age distribution. The requirements are the the matrix is irreducible and primitive. A matrix/life-cycle graph is irreducible if every state can be reached from every other state. In graph terminology, we say an imprimitive life-cycle graph is strongly connected. Primitivity simply means that the growth generated by repeated multiplication of the matrix is aperiodic. We can define a loop on a life-cycle graph as an alternating sequence of nodes and edges that starts and finishes on the same node. For example 1-2-3-1, 1-2-3-4-1, and 1-2-3-4-5-1 are the loops in our life-cycle graph above. A sufficient condition that ensures primitivity is that the greatest common divisor of the lengths of all the loops in a life-cycle graph is one.\nIf non-negative, square matrix \\(\\mathbf{A}\\) is irreducible and primitive, it meets the criteria for the Perron-Frobenius Theorem, which states that such a matrix will have a single eigenvalue which is positive, real, and strictly greater than all the others. We call this eigenvalue of the dominant eigenvalue of matrix \\(\\mathbf{A}\\). The dominant eigenvalue of the projection matrix is the asymptotic growth rate (and mean fitness) of the population described by that matrix. The corresponding right and left eigenvectors represent the stable age distribution and the reproductive values, respectively, of the population.\nDenote the dominant eigenvalue of matrix \\(\\mathbf{A}\\) as \\(\\lambda\\) and the corresponding right and left eigenvectors as \\(\\mathbf{u}\\) and \\(\\mathbf{v}\\). Hal Caswell (1978) showed that the sensitivity of the dominant eigenvalue to a small perturbation in matrix element \\(a_{ij}\\) is given by the product of the reproductive value of stage \\(i\\) (the receiving state) and the stable age value of stage \\(j\\) (the giving state), assuming that these vectors have been normed such that \\(\\langle \\mathbf{v},\\mathbf{u} \\rangle = 1\\).\n\\[\ns_{ij} = \\frac{\\partial \\lambda}{\\partial a_{ij}} = v_i u_j\n\\]\nThese sensitivities turn out to be very important in a number of applications in population biology. For example, the selection gradient in the multivariate breeder’s equation discussed in Chapter 2 is simply a vector of sensitivities. Sensitivities also provide important information about which demographic rates we need to measure precisely if we are to have any hope of making accurate population forecasts. In Chapter 10, we will discuss a fundamental trade-off between the responsiveness to selection (or optimality) and robustness that arises because of sensitivities with different signs appearing in equations relating to these qualities (Schmid et al. 2022).\nIt is often useful to transform sensitivities into elasticities or proportional sensitivities. Note a handy fact from calculus:\n\\[\n\\frac{dy}{dx} \\frac{1}{y} = \\frac{d\\log y}{dx}.\n\\]\nIf we multiply our sensitivity \\(s_{ij}\\) by \\(a_{ij}/\\lambda\\), we get\n\\[\ne_{ij} = \\frac{\\partial \\lambda}{\\partial a_{ij}} \\frac{a_{ij}}{\\lambda} = \\frac{\\partial \\log \\lambda}{\\partial \\log a_{ij}}\n\\]\nAn elasticity tells us by what percentage \\(\\lambda\\) will change if we change \\(a_{ij}\\) by, say, 1%.\nElasticities are ubiquitous in economics. We will encounter them in both Chapter 5 and ?sec-popenv.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Population Ecology</span>"
    ]
  },
  {
    "objectID": "populations.html#density-dependent-growth",
    "href": "populations.html#density-dependent-growth",
    "title": "3  Population Ecology",
    "section": "3.4 Density Dependent Growth",
    "text": "3.4 Density Dependent Growth\n\nThere is no exception to the rule that every organic being naturally increases at so high a rate, that if not destroyed, the earth would soon be covered by the progeny of a single pair. Even slow-breeding man has doubled in twenty-five years, and at this rate, in a few thousand years, there would literally not be standing room for his progeny. Linnaeus has calculated that if an annual plant produced only two seeds and there is no plant so unproductive as this and their seedlings next year produced two, and so on, then in twenty years there would be a million plants. The elephant is reckoned to be the slowest breeder of all known animals, and I have taken some pains to estimate its probable minimum rate of natural increase: it will be under the mark to assume that it breeds when thirty years old, and goes on breeding till ninety years old, bringing forth three pairs of young in this interval; if this be so, at the end of the fifth century there would be alive fifteen million elephants, descended from the first pair. Darwin, The Origin of Species\n\nTo understand catastrophes, it helps to know something about stability analysis. We’ll do a quick introduction here, using the logistic population growth model as a concrete example.\n\n3.4.1 Logistic Growth\nThe logistic growth model is a model of population growth where the rate of increase of the population depends on the population size. In general, density-dependent models work such that as the population size gets large, the growth rate decreases:\n\\[ \\frac{dN}{dt} = N f(N) \\]\n\\(f(N)\\) is some function of population size \\(N\\) that decreases in \\(N\\). The simplest form for this function is linear:\n\\[  f(N) = r(1 - N/K), \\]\nwhere \\(r\\) is the intrinsic rate of increase and \\(K\\) is known as the carrying capacity of the population. This leads to the most commonly seen version of the logistic equation\n\\[\n\\frac{dN}{dt} = rN (1 - N/K)\n\\]\nThe logistic model is sigmoidal, meaning that it is S-shaped. It turns out that the logistic model is simple enough that it can be solved analytically. When we integrate it, we get the following expression for the population size at time \\(t\\):\n\\[N(t) = \\frac{N(0)e^{rt}}{1+N(0)(e^{rt}-1)/K} \\]\nThis is a logistic function, which gives the population model its name. We can write out an R expression and plot the logistic curve as a function of time.\n\nlogistic.int &lt;- expression(n0*exp(r*t)/((1+n0*(exp(r*t)-1)/K)))\nn0 &lt;- 1\nr &lt;- 0.1\nK &lt;- 100\nt &lt;- 0:100\nplot(t,eval(logistic.int),type=\"l\",col=\"blue\",xlab=\"Time\",ylab=\"Population Size\") \n\n\n\n\n\n\n\n\n\n\n3.4.2 The Recruitment Curve\nFor a variety of reasons, it often turns out to be easier to work with what is known as the recruitment curve for the population model. Rather than the integrated model in time, this is essentially a plot of the density-dependent function \\(f(N)\\) times the current population size \\(N\\) as a function of the population size.\nWe call it a recruitment curve because it plots the number of recruits we get when the population is a given population size.\n\nDn &lt;- expression(r * (1 - N/K) * N)\nr &lt;- 1\nK &lt;- 1000\nN &lt;- seq(0,1000,by=10)\nplot(N,eval(Dn),type=\"l\",col=\"blue\",xlab=\"Population Size\", ylab=\"Recruitment\")\n\n\n\n\n\n\n\n\nIf you were a natural resource manager like a hunter or forester, at what population size would you want to harvest your population to maximize your yield? The Maximum Sustainable Yield is the peak of the recruitment curve and represents the value of \\(N\\) that maximizes production of the natural resource. For the logistic model, this curve is symmetric. In general, this is not true (and leads to interesting phenomena such as overshoot and subsequent population crashes/booms).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Population Ecology</span>"
    ]
  },
  {
    "objectID": "populations.html#stability-analysis-of-the-logistic-model",
    "href": "populations.html#stability-analysis-of-the-logistic-model",
    "title": "3  Population Ecology",
    "section": "3.5 Stability Analysis of the Logistic Model",
    "text": "3.5 Stability Analysis of the Logistic Model\nFirst, we solve the logistic equation for its equilibria. To do this, we set the rate of population change equal to zero and find the conditions that make this true.\n\\[ \\frac{dN}{dt} = rN(1-N/K) = 0 \\]\nIt’s not difficult to see that there are two equilibria:\n\n\\(N=0\\)\n\\(N=K\\)\n\nThe first solution is when the population size is exactly zero. When there is no population, there is no chance of the population growing, so that makes sense. The second solution is when the population size equals the carrying capacity, \\(K\\). This also makes sense, since it’s the basic idea behind density-dependent population growth models – when the population reaches its carrying capacity, it should stop increasing. So now the question is: are these two equilibria stable?\nWhen we calculate the stability of a continuous-time models like the logistic growth model, we basically tweak a population that is at equilibrium and see what happens. At least two possibilities include:\n\nIt will continue to move in the direction of the tweak\nIt will move back to the equilibrium value\n\nTo perform out stability analysis, write the production function in generic form:\n\\[ \\frac{dN}{dt} = F(N) \\]\nFor the logistic model \\(F(N) = rN(1-N/K)\\). We’ve already determine the equilibria (\\(N=0\\) and \\(N=K\\))\nDefine a deviation from an equilibrium point \\(\\hat{N}\\):\n\\[ n = N - \\hat{N} \\]\nRearrange, putting \\(N\\) on the left-hand side \\(N = \\hat{N}+n\\), and substitute back into the generic equation.\n\\[ \\frac{d(\\hat{N}+n)}{dt} = F(\\hat{N}+n) \\]\nNow, \\(\\hat{N}\\) is a fixed number (i.e., it’s the equilibrium), so it won’t change. All the change in this differential will therefore come from \\(n\\) which is free to vary (its change is, in fact, what we care about here)\n\\[ \\frac{dn}{dt} = F(\\hat{N}+n) \\]\nWe don’t (necessarily) know what \\(F(\\hat{N}+n)\\) will be. For many interesting models, there is no closed-form solution to this differential equation. Our strategy is therefore to approximate it with a Taylor Series approximation, which means that we’re assuming that \\(n\\) is small and that we are contenting ourselves to investigating the behavior of our model near the equilibrium.\n\\[ F(\\hat{N}+n) \\approx  F(\\hat{N}) + F^{\\prime}(\\hat{N})n \\]\n\\(F^{\\prime}(\\hat{N})\\) is the derivative of \\(F\\) with respect to \\(N\\) evaluated at \\(\\hat{N}\\). The equation for the dynamics of our perturbation becomes:\n\\[ \\frac{dn}{dt} = F(\\hat{N}) + F^{\\prime}(\\hat{N})n \\]\nBut, we are evaluating at an equilibrium where, by definition, \\(F(\\hat{N})=0\\), so we are left with:\n\\[ \\frac{dn}{dt} = F^{\\prime}(\\hat{N})n \\]\nRename as follows to make notation simpler:\n\\[ F^{\\prime}(\\hat{N}) = \\lambda \\]\nThis gives us our final step\n\\[ \\frac{dn}{dt} = \\lambda n \\]\nThis is simply the exponential growth model, the solution of which is:\n\\[ n(t) = n(0)e^{\\lambda t} \\]\nWhat this tells us is that if \\(\\lambda &gt; 0\\), the equilibrium is unstable because it will grow away from the equilibrium without bound. On the other hand, if \\(\\lambda &lt; 0\\), the equilibrium is stable because the perturbation will decay back to zero (i.e., back to the equilibrium).\nThis whole process is known as linearizing around the equilibrium or local linearization.\nReturning to the logistic model, we can calculate \\(\\lambda = F^{\\prime}(\\hat{N})\\). We use the product rule for differentiation to show that for \\(\\hat{N}=0\\), \\(\\lambda=r\\) and for \\(\\hat{N}=K\\), \\(\\lambda=-r\\). So what does this mean? For small deviations near the equilibrium of \\(N=0\\), the population will increase exponentially at rate \\(r\\). For small deviations near the equilibrium of \\(N=K\\), the population will decay back to the equilibrium exponentially at rate \\(-r\\).\n\n3.5.1 Steps to Calculating \\(F^{\\prime}(N)\\) for the Logistic Model\nWhere do the values \\(F^{\\prime}(N) = r\\) and \\(F^{\\prime}(N) = -r\\) for the two equilibria of the logistic model come from? Use the Product Rule for Differentiation. If we let some function \\(h(N)\\) be the product of two other function \\(f(N)\\) and \\(g(N)\\), the product rule for differentiation specifies that:\n\\[h^{\\prime}(N) = f^{\\prime}(N) g(N) + f(N) g^{\\prime}(N) \\]\nFor the logistic model, \\(f(N) = rN\\) and \\(g(N) = (1-N/K)\\). Therefore, \\(f^{\\prime}(N) = r\\) and \\(g^{\\prime}(N) = -\\frac{1}{K}\\). Therefore,\n\\[h^{\\prime}(N) = r(1-N/K) -\\frac{rN}{K} \\]\nFinally, substitute back in the values for the equilibria (\\(N=0\\) and \\(N=K\\)) and we recover our to values for \\(\\lambda\\):\n\\[ N \\rightarrow 0,~~~~~h^{\\prime}(N) = r \\]\n\\[ N \\rightarrow K,~~~~~h^{\\prime}(N) = -r \\]\n\n\n\n\nCaswell, H. 2001. Matrix Population Models: Construction, Analysis and Interpretation. 2nd ed. Sunderland, MA: Sinauer.\n\n\nCaswell, Hal. 1978. “A General Formula for the Sensitivity of Population Growth Rate to Changes in Life History Parameters.” Theoretical Population Biology 14 (2): 215–30. https://doi.org/10.1016/0040-5809(78)90025-4.\n\n\nCoale, A. 1974. “The History of Human Population.” Scientific American 231 (40-51).\n\n\nCole, L. C. 1954. “The Population Consequences of Life History Phenomena.” Quarterly Review of Biology 29 (2): 103–37. http://www.jstor.org/stable/2817654.\n\n\nJones, J. H. 2009. “The Force of Selection on the Human Life Cycle.” Evolution and Human Behavior 30 (5): 305–14. https://doi.org/10.1016/j.evolhumbehav.2009.01.005.\n\n\nSchmid, Max, Maria Paniw, Maarten Postuma, Arpat Ozgul, and Frédéric Guillaume. 2022. “A Trade-Off Between Robustness to Environmental Fluctuations and Speed of Evolution.” The American Naturalist 200 (1): E16–35. https://doi.org/10.1086/719654.\n\n\nSlade, Norman A., Richard Gomulkiewicz, and Helen M. Alexander. 1998. “Alternatives to Robinson and Redford’s Method of Assessing Overharvest from Incomplete Demographic Data.” Conservation Biology 12 (1): 148–55. https://doi.org/10.1111/j.1523-1739.1998.96273.x.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Population Ecology</span>"
    ]
  },
  {
    "objectID": "culture.html",
    "href": "culture.html",
    "title": "4  Does Culture Evolve?",
    "section": "",
    "text": "4.1 Is Culture Adaptive?\nTo illustrate the importance of culture for human adaptation, Joseph Henrich and McElreath (2003) discuss the Burke and Wills Expedition of 1860–61. The goal of the expedition was to cross the interior of Australia from South to North, starting in Melbourne and ending up in the Gulf of Carpentaria, 2,000 miles to the north. No European explorers had yet managed to live in this area or traverse this route, though it was settled by many thriving aboriginal groups.\nThey departed with all the pomp and arrogance of Victorian British explorers. Alas, things didn’t work out so well for them. Of the 19 men who left Melbourne, only one survived to return (and he was plagued with ill health for the rest of his short life; dying at age 33, 11 years subsequent to the ill-fated expedition).\nMarsilea drummondii, or nardoo, is a species of fern. The sporocarps of this fern are processed by Aboriginal Australians into a type of flour that can be made into flour cakes (known as “damper” in Aus). If they are not properly processed, however, they are toxic, containing high concentrations of thiaminase, which destroys thiamine (vitamin B1). What results is a vitamin B1 deficiency, known as beriberi.\nWills’ last journal entry includes the following:\nBurke & Wills seem to have died of beriberi because they lacked the (cumulative) cultural knowledge of how to live in the Australian outback.\nThe Ratchet Effect:\nMichael Tomasello defined the ratchet effect: “some individual or group of individuals first invented a primitive version of an artifact or practice, and then some later user or users made a modification, an ‘improvement,’ that others then adopted perhaps without change for many generations, at which point some other individual or group of individuals made another modification, which was then learned and used by others, and so on over historical time in what has sometimes been dubbed ‘the ratchet effect’” (Tomasello 1999: 5).\nJoseph Henrich and McElreath (2003): “The mental representations that allow individuals to detoxify the fern spores…do not come coded in their genes, nor are these continually relearned by each individual via trial-and-error experimentation or deduced solely by fitness-oriented cost-benefit analysis. Instead, such adaptations result from and embody the cumulative effects of the efforts, experiments, errors, insight, and interactions of many individuals across generations.”\nOur dependence on cumulative culture that no one person could begin to recreate in her lifetime is highlighted by the first episode of James Burke’s (1978) PBS series, Connections. Burke uses the blackouts in New York City as a launching point for a meditation on how the typical citizen of a rich country in the Global North would fair if civilization collapsed.  “And what, in your comfortable urban life, has ever prepared you for that decision?” (26:20)\nThe transmission described by Tomasello, in his discussion of the ratchet effect, and the adaptiveness alluded to by both him and Henrich & McElreath suggest that culture dynamics might have analogous properties to biological evolution.\nGenetic transmission and subsequent modification produces tree-like structures Showing a tree can be a powerful tool for inferring evolutionary process Tinbergen’s phylogenetic cause There are problems with culture though\nBorgerhoff Mulder et al. note: “any trait can be fed into a software program to produce, or map, a phylogeny. This does not mean that the phylogeny is the most accurate depiction of the trait’s history, nor that vertical transmission best accounts for its distribution.”\n“We strongly agree with the authors Mesoudi et al. (2006) that the potential for horizontal transmission of cultural traits does not invalidate an evolutionary approach to culture. We suggest, however, that it does require a different evolutionary treatment.”\nCultural Evolution Is Not Identical to Genetic Evolution\nFor example, individuals can have more than two “parents” because learning happens from non-parents as well. In particular, there is extensiveh horizontal transmission (peer-to-peer) as well as oblique transmission (non-parent older-to-younger). Cultural traits are acquired by copying phenotype, rather than inheriting a genotype, though both may involve ontogenetic processes. Mutation can be nonrandom. Mutation more likely to be “directed” in times of uncertainty. Transmission and change happens within a lifetime.\nCultural evolution can be Lammarckian: Evolution by acquired characteristics.\nAdaptations are characteristics that make organisms better suited for the environments Unfortunately, some writers suggest that natural selection produces adaptation by definition not true!\nIn his pioneering paper on the adaptive value of culture, Rogers (1988) writes, “When selection does not maximize mean fitness, there is no reason to think that it will produce adaptation. Thus, the capacity for culture is expected to be adaptive only if the mean fitness of a population with culture is higher than that of one without.”\nRogers looks at two different extremes. The first is the Weak Constraint Model, in which biological constraints on culture are too weak to be significant, therefore, models of genetic evolution will be of little use in understanding variation in human behavior. The second is the Acultural Model: If culturally acquired-behaviors tended to reduce Darwinian fitness, then the capacity for culture would be altered or destroyed by natural selection and behavior should tend to enhance fitness whether transmission is cultural or not.\n## Figure 1 from Rogers (1988)\nwi &lt;- function(b=1,c=0.9) 1 + b*(1-c)\nws &lt;- function(b=1,s=0,p,u=0.8) 1 + (b*(1-s)*(1-p)*(1-u))/(1 - p*(1-u))\n\np &lt;- seq(0,1,,100)\n\ncult &lt;- ws(p=p)\nacult &lt;- rep(wi(),100)\nm &lt;- cult*p + acult*(1-p)\n\nplot(p,cult, type=\"l\", lwd=2, axes=FALSE, frame=TRUE,\n     xaxs=\"i\",\n     xlab=\"Frequency of Social Learning (p)\", ylab=\"Fitness\")\nlines(p,acult, col=\"red\",lwd=2)\nlines(p,m, col=grey(0.75), lty=2,lwd=2)\naxis(1)\nlegend(\"topright\", c(\"individual\",\"social\",\"mean\"), \n       col=c(\"red\",\"black\",grey(0.75)), lty=c(1,1,2))\nMean fitness does not, in fact, increase at the equilibrium. While it increases for low-frequencies of social learning, it comes right back to baseline for the equilibrium. Note that this equilibrium is stable since to the left of it, social learners have higher fitness, whereas to the right of it, individual learners have higher fitness.\nCorrelation decreases as the cost of individual learning increases or as the frequency of environmental perturbation and cost of social learning decrease.\nNote that this is really just a ratio between the efficiency of individual learning to the efficiency of social learning.\n“The model’s main result is equation 4, which relates the correlation between behavior and the environment to the efficiencies of individual and social learning. As these undoubtedly vary from behavior to behavior, it follows that some behaviors should track the environment well, others poorly. Consequently, ecology should be more useful in understanding some behaviors than others, a fact that cultural ecologists have long understood (Oliver 1962:Steward 1955). This equation also implies that acultural evolutionary models are unlikely to be helpful in understanding behaviors that are usually learned socially.” (pp. 827-28)\n\\[\nr=\\frac{1-c}{(1-u)(1-s)}\n\\]\nIncreasing the cost of individual learning (\\(c\\)) reduces the correlation between the environment and the behavior.\nIncreasing the frequency of environmental perturbation or the cost of social learning increases the correlation between the environment and behavior.\nchanging \\(u\\) or \\(s\\) has the same effect (assuming the other is held constant) since they are involved in a product in the denominator.\n“The weak form of the argument from natural origins assumes that mechanisms of cultural transmission can evolve only if the behaviors produced tend to be consistent with the predictions of acultural evolutionary models.” consistency between behavior and acultural models measured by correlation \\(r\\).\nSome tendency for behavior to accord with acultural models\n“However, if the efficiency of social learning is high, then \\(r=0\\), and this tendency will be negligible. There is therefore no basis for the claim that, if the capacity for culture evolved by natural selection, then culture must be explicable in terms of ordinary, acultural evolutionary models.” (pp. 826-27)\nFrequency dependence of handedness in humans. Fighting Hypothesis: Left-Handers have a small advantage in fighting, but only when they are relatively rare (Raymond et al. 1996).\nRecent evidence suggests left-handers are over-represented in combat sports and win more often than expected by chance (Richardson and Gilman 2019).\nEnquist, Eriksson, and Ghirlanda (2007) introduce Critical Social Learning: a strategy that tries to solve an adaptive problem first by social learning, and then by individual learning if socially acquired behavior proves unsatisfactory\nUnlike Rogers’ model, mean fitness increases as the frequency of critical social learners increases. Culture is adaptive!\n## Enquvist et al. (2007)\n\neeq2 &lt;- function(piok=0.5,ci=0.2) piok - ci\n\neeq7 &lt;- function(qsi,psokok=0.9,cs=0.02,piok=0.5,ci=0.2){\n  qok &lt;- piok/(1-psokok*(1-piok)*qsi)\n  wsi &lt;- qok*psokok - cs + (1-qok*psokok)*(piok-ci)\n  return(wsi)\n}\n\nplot(p,eeq7(qsi=p), type=\"l\", lwd=2, axes=FALSE, frame=TRUE,\n     xaxs=\"i\",\n     ylim=c(0,1),\n     xlab=\"Frequency of Critical Social Learners (qsi)\", ylab=\"Fitness\")\nabline(h=eeq2(),lty=2,lwd=2)\naxis(1)\nlegend(\"topright\", c(\"individual\",\"critical social\"), lty=c(2,1))\nThe critical social learner first tries social learning, and if the result is unsatisfactory, they then try individual learning.\nSpatial Structure Overcomes Rogers’ Paradox Rendell, Fogarty, and Laland (2010). the fitness of social learners is highest in the zones of contact with asocial learners. Essentially, they get costless information from the asocial learners on these borders.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Does Culture Evolve?</span>"
    ]
  },
  {
    "objectID": "culture.html#diffusion-of-innovations",
    "href": "culture.html#diffusion-of-innovations",
    "title": "4  Does Culture Evolve?",
    "section": "4.2 Diffusion of Innovations",
    "text": "4.2 Diffusion of Innovations\n\n## Ryan & Gross (1943) Adoption of hybrid corn\n## measured from their figure 2 using a lucite ruler!\ncorn &lt;- c(0.5, 1.5, 2, 2, 2.5, 1.5, 3.5, 6.5, 8.5, 14, 24, 18.5, 14, 5.5, 1.5)\nyrs &lt;- 1927:1941\nbarplot(corn,names.arg=yrs, axis.lty = 1, \n        xlab=\"Year\", ylab=\"Precentage Adopting\", ylim=c(0,25))\n\n\n\n\n\n\n\n# fit logistic curve\nlog.ss &lt;- nls(cumsum(corn) ~ SSlogis(yrs, phi1, phi2, phi3))\n#C\nC &lt;- summary(log.ss)$coef[1]\n#a\nA &lt;- exp((summary(log.ss)$coef[2]) * (1/summary(log.ss)$coef[3]))\n#k\nK &lt;- (1 / summary(log.ss)$coef[3])\n\nplot(yrs, cumsum(corn), pch=16, col=grey(0.65), \n     xlab=\"Year\", ylab=\"Cumulative Percent Adopting\")\nlines(1927:1941, predict(log.ss, data.frame(yrs=1927:1941)), col=\"black\", lwd=3)\n\n\n\n\n\n\n\n\nVery different Rogers.\n\n## stylized adoption curve\nx &lt;- seq(-4,4,,500)\nq &lt;- c(0.025, 0.16, 0.5, 0.84)\nqq &lt;- qnorm(q)\ndd &lt;- dnorm(qq)\nzz &lt;- rep(0,4)\n\n#pdf(file=\"adoption.pdf\")\nplot(x, dnorm(x), type=\"n\", axes=FALSE, frame=TRUE,\n     xaxs=\"i\", yaxs=\"i\",\n     xlab=\"Time\", ylab=\"Fraction Adopting\", ylim=c(0,1.05))\naxis(2)\nsegments(qq,zz,qq,dd, lwd=3, col=rgb(1,0,0,0.5))\nlines(x, dnorm(x), lwd=3, col=grey(0.65))\nlines(x,pnorm(x), lwd=3)\nlegend(\"topleft\",c(\"incident\",\"cumulative\"),lwd=3, col=c(grey(0.65),\"black\"))\n\n\n\n\n\n\n\n\nThe cumulative adoption curve is S-shaped. Nonlinear least-squares fit to the observed data (note that the prediction for year &gt; 1939 is &gt;100% adoption!).\nInnovators, Early Adopters, Early Majority, Late Majority, Laggards",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Does Culture Evolve?</span>"
    ]
  },
  {
    "objectID": "culture.html#modes-of-cultural-transmission",
    "href": "culture.html#modes-of-cultural-transmission",
    "title": "4  Does Culture Evolve?",
    "section": "4.3 Modes of Cultural Transmission",
    "text": "4.3 Modes of Cultural Transmission\nUnbiased Transmission Unbiased Transmission with Mutation Random Mutation Biased Mutation Biased Transmission Direct Bias: Bias depends on properties of the trait Indirect Bias: Bias depends on properties of the model\nRapid Diffusion of Steel Axes Among the Yir-Yoront\nmissionaries on the Cape Yorke Peninsula freely gave out steel axes, hoping to improve productivity and, naturally, civilize this hold-out group. The social consequences were devastating as Yir-Yoront society was largely structured around the production and control of stone axes.\nYou’re in a new city and you want to go out and get dinner. How do you choose a restaurant?\n\n4.3.1 Conformist Bias\nA Particularly Important Form of Indirect Bias\nWhen in doubt, do what the majority of people around you are doing Boyd & Richerson (1985) show valuable strategy in a spatially-variable environment with dispersal If the most frequent local variant also happens to be most adaptive, “individuals who have a tendency to acquire the most common variant would also have an improved chance of acquiring the locally favored variant” (p. 220) Liken conformist bias to robust estimators in statistics\nConformity means something particular: specifically, it means that you choose a behavior more frequently than its frequency in the population. So, if 40% of people are doing something, you exhibit a conformist bias if you are more than 40% likely to copy that behavior.\nIt does not mean you have to go with the majority, though it often amounts to that.\nlikening to robust estimators suggests variance-bias trade-off.\nJ. Henrich and Boyd (1998) argue for broad superiority Note that it’s a mechanism for generating cultural differences McElreath et al. (2005) find that participants in experiments are more likely to follow a linear rule than conformity",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Does Culture Evolve?</span>"
    ]
  },
  {
    "objectID": "culture.html#culture-can-be-remarkably-persistent",
    "href": "culture.html#culture-can-be-remarkably-persistent",
    "title": "4  Does Culture Evolve?",
    "section": "4.4 Culture Can Be Remarkably Persistent",
    "text": "4.4 Culture Can Be Remarkably Persistent\nSonya Salamon studied farming communities in Illinois settled in mid 1800’s by immigrants from different regions: Germans (2 communities, Westfalian Catholics, Friesian Protestants) Yankees (2 communities, mainly from Ohio and mid-Atlantic states) (Salamon 1985). She suggested that these groups differed in systematic ways. For Yankee “Entrepreneurs,” farming was a business, the goal of which was to make money. They placed a high value on education and didn’t pressure children to go into farming. There was considerable intergenerational competition and son’s were responsible for their own livelihoods.\nIn contrast, for “German Yeomen” farming was a valuable way of life. The goal was to keep the farm in the family. They did not place a high value on education and urged children to go into farming. Parents were responsible for setting up their son/heir financially and there was generally a spirit of intergenerational cooperation.\nSalamon found that these cultural differences persisted for the approximately 100 years between when the region was settled and her study. The descendants of the German colonists rented less land and maintained smaller farms than the descendants of Yankees. Yankee farmers grew commodities for sale, whereas German farmers pursued livestock for subsistence (not an ideal place for commercial dairying or livestock-rearing).\n\n## from Salamon (1985), table 2\nfarm_household &lt;- c(\"Tenant\", \"Part Owner\", \"Full Owner\", \"Landlord\")\nhouseholds &lt;- c(6,32,17,19,5,26,8,31)\nmean_age &lt;- c(38.5, 48.5, 50.4, 63.7, 24.4, 45.0, 59.8, 70.7)\nfarm_size &lt;- c(253, 331, 182, 151, 280, 591, 428, 148)\ntype &lt;- c(rep(\"Yeoman\",4), rep(\"Yankee\",4))\nfarmers &lt;- data.frame(household_type=rep(farm_household,2), type, households, mean_age, farm_size)\nfarmers\n\n  household_type   type households mean_age farm_size\n1         Tenant Yeoman          6     38.5       253\n2     Part Owner Yeoman         32     48.5       331\n3     Full Owner Yeoman         17     50.4       182\n4       Landlord Yeoman         19     63.7       151\n5         Tenant Yankee          5     24.4       280\n6     Part Owner Yankee         26     45.0       591\n7     Full Owner Yankee          8     59.8       428\n8       Landlord Yankee         31     70.7       148\n\n\nWicked John and the Devil is an Appalachian folk tale. Wicked John is mean to everyone but, for some reason, not to strangers. A stranger comes to his remote blacksmith shop one day and Wicked John feeds him. The stranger transmutes into St. Peter, who grants Wicked John three wishes for his kindness. Wicked John, being a grumpy man who is always trying to protect his property from his neighbors, basically asks for magic that can trap people until he lets them go (in a hammer, a rocking chair, and a thorn bush). Fast forward, he tricks the devil into getting trapped by the thorn bush and avoids getting brought down to hell.\nThere is an alternative version in African American folklore which, frankly, makes a bit more sense than this “canonical” version (Zora Neale Hurston).\nThis story turns out to be potentially 6000 years old! The tale known as “The Smith and the Devil” and was told by the people who spoke Proto-Indo-European (Silva and Tehrani 2016). Other, more famous, fairy tales like Rumpelstiltskin and Cinderella might be nearly as old. Neil Gaiman talks about the idea that the tales are using us to reproduce.\n\n\n\n\nEnquist, Magnus, Kimmo Eriksson, and Stefano Ghirlanda. 2007. “Critical Social Learning: A Solution to Rogers’s Paradox of Nonadaptive Culture.” American Anthropologist 109 (4): 727–34. http://www.jstor.org/stable/27563823.\n\n\nHenrich, J., and R. Boyd. 1998. “The Evolution of Conformist Transmission and the Emergence of Between-Group Differences.” Evolution and Human Behavior 19 (4): 215–41. https://doi.org/10.1016/S1090-5138(98)00018-X.\n\n\nHenrich, Joseph, and Richard McElreath. 2003. “The Evolution of Cultural Evolution.” Evolutionary Anthropology 12 (3): 123–35. https://doi.org/10.1002/evan.10110.\n\n\nMcElreath, Richard, Mark Lubell, Peter J. Richerson, Timothy M. Waring, William Baum, Edward Edsten, Charles Efferson, and Brian Paciotti. 2005. “Applying Evolutionary Models to the Laboratory Study of Social Learning.” Evolution and Human Behavior 26 (6): 483–508. https://doi.org/10.1016/j.evolhumbehav.2005.04.003.\n\n\nRaymond, Michel, Dominique Pontier, Anne-bééatrice Dufour, and Anders Pape Møller. 1996. “Frequency-Dependent Maintenance of Left Handedness in Humans.” Proceedings of the Royal Society of London. Series B: Biological Sciences 263 (1377): 1627–33. https://doi.org/10.1098/rspb.1996.0238.\n\n\nRendell, Luke, Laurel Fogarty, and Kevin N. Laland. 2010. “Rogers’ Paradox Recast and Resolved: Population Structure and the Evolution of Social Learning Strategies.” Evolution 64 (2): 534–48. https://doi.org/10.1111/j.1558-5646.2009.00817.x.\n\n\nRichardson, Thomas, and R. Tucker Gilman. 2019. “Left-Handedness Is Associated with Greater Fighting Success in Humans.” Scientific Reports 9 (1): 15402. https://doi.org/10.1038/s41598-019-51975-3.\n\n\nRogers, A. R. 1988. “Does Biology Constrain Culture?” American Anthropologist 90 (4): 819–31. https://doi.org/10.1525/aa.1988.90.4.02a00030.\n\n\nSalamon, Sonya. 1985. “Ethnic Communities and the Structure of Agriculture.” Rural Sociology 50 (3): 323.\n\n\nSilva, Sara Graça da, and Jamshid J. Tehrani. 2016. “Comparative Phylogenetic Analyses Uncover the Ancient Roots of Indo-European Folktales.” Royal Society Open Science 3 (1): 150645. https://doi.org/10.1098/rsos.150645.\n\n\nTomasello, Michael. 1999. The Cultural Origins of Human Cognition. Cambridge, MA: Harvard University Press.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Does Culture Evolve?</span>"
    ]
  },
  {
    "objectID": "decision.html",
    "href": "decision.html",
    "title": "5  Risk, Uncertainty, and Decision-Making",
    "section": "",
    "text": "5.1 Utility\nA utility function is simply a mechanism for ordering preferences. I prefer choice \\(A\\) over choice \\(B\\) only if \\(U(A) &gt; U(B)\\). Utility functions are increasing: more stuff means more utility. Mathematically, this means that the first derivative of a utility function is greater than zero, \\(U'(x) &gt; 0\\). They often show diminishing marginal utility, which mathematically means that the second derivative is less than zero, \\(U''(x) &lt; 0\\). Debreu showed that all that is required for a valid utility function are two things: (1) complete ordering, and (2) transitive preferences. A transitive preference means that if I prefer \\(A\\) to \\(B\\) and \\(B\\) to \\(C\\), I prefer \\(A\\) to \\(C\\).\nWe can draw a utility function that has the two key properties of \\(U'(x)&gt;1\\) and \\(U''(x)&lt;0\\).\nx &lt;- seq(0,5,length=1000)\nr &lt;- 0.75\n## classic concave function\nfx &lt;- 1-exp(-r*x)\n## for part deux\naaa &lt;- (fx-0.4882412)^2\n#which(aaa==min(aaa))\n#[1] 179\n\nplot(x,fx, type=\"l\", lwd=3, axes=FALSE, frame=TRUE, \n     xlab=expression(x), ylab=expression(U(x)), \n     xaxs=\"i\", yaxs=\"i\", xlim=c(-0.1,5.1), ylim=c(0,1))\n#segments(0,0,5,fx[1000], lwd=2, col=grey(0.75))\naxis(1, at=c(0,2.5,5), labels=c(expression(x[0]), expression(bar(x)),\n                                expression(x[1])), tick=FALSE)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Risk, Uncertainty, and Decision-Making</span>"
    ]
  },
  {
    "objectID": "decision.html#expected-utility",
    "href": "decision.html#expected-utility",
    "title": "5  Risk, Uncertainty, and Decision-Making",
    "section": "5.2 Expected Utility",
    "text": "5.2 Expected Utility\nWhat happens when payoffs are variable? A lottery is just a choice that has a variable outcome. To value/rank lotteries, we need to combine possible outcomes of the lotteries with weights that we assign to those outcomes. The simplest way to do this is to use a linear combination of the utilities of outcomes and the probabilities of those outcomes. This particular operationalization of measures and weights is known as expected utility and is the foundation for most choice theory.\nHere we can plot two lotteries as trees using the ape package in R. Pictured are two different lotteries, one low-risk/low-gain and the other high-risk/high-gain. This might represent the sort of foraging decision faced by a Martu hunter in deciding whether to hunt for goanna (lottery A) or hill kangaroo (lottery B) (James Holland Jones, Bird, and Bird 2013).\n\nlibrary(ape)\n## two lotteries in nexus format\nttt &lt;- \"(20,30);\"\nttt &lt;- read.tree(text = ttt)\nttt1 &lt;- \"(0,100);\"\nttt1 &lt;- read.tree(text = ttt1)\nlablocs &lt;- list(x=c(0.45, 0.45), y=c(1.9, 1.1))\n#\npar(mfrow=c(1,2))\nplot(ttt, type=\"cladogram\", edge.width=3, label.offset=0.05)\ntext(lablocs, c(expression(p),expression(1-p)), cex=1.25, family=\"sans\")\ntitle(\"A: Low-Risk/Low-Gain\")\nplot(ttt1, type=\"cladogram\", edge.width=3, label.offset=0.05)\ntext(lablocs, c(expression(p),expression(1-p)), cex=1.25, family=\"sans\")\ntitle(\"B: High-Risk/High-Gain\")\n\n\n\n\n\n\n\n\nExpected utility theory (EUT) has axiomatic foundations and constitutes on the core ideas of the so-called “Rational-Choice” paradigm. The first axiomatization was by Neumann and Morgenstern (1947). Their approach lays out four axioms, which are broadly similar to subsequent axiomatizations:\n\nCompleteness: all possible decisions can be assigned a value\nTransitivity: if \\(A &gt; B\\) and \\(B &gt; C\\), then \\(A &gt; C\\)\nContinuity: there exists a \\(p\\) such that if \\(A &gt; B\\) and \\(B &gt; C\\), \\(B &lt; pA + (1-p)C\\)\nIndependence: preferences not altered by irrelevant alternatives\n\nAs noted by Gintis (2007) rationality, in the rational-choice sense, is really about consistency. While it is sometimes framed as focusing on self-regarding behavior, this is not necessarily true. An individual can have other-regarding preferences and still be “rational” as long as they are consistent in their preferences.\nGiven the above axioms, making decisions by expected utility will produce consistent, coherent preferences. Therefore, the theory of decision-making under risk takes as its objective function expected utility. Remember that mathematically, the word “expected” is synonymous with “average”. Suppose that there is some variable resource, the acquisition of which is associated with some utility. Following standard statistical convention, we denote our random variable (i.e., the resource in question) using uppercase Roman letter, \\(X\\), and denote specific realizations of this random variable in lowercase, \\(x\\). Expected utility is simply the average of the utilities \\(u(x)\\) associated with each value of \\(x\\):\n\\[\nE(u) = \\int_{\\Omega} u(x)\\, f(x) dx,\n\\]\nwhere \\(E()\\) indicates mathematical expectation (i.e., the arithmetic mean), \\(f(x)\\) is the probability density of outcome \\(x\\), \\(\\Omega\\) is the set of all possible outcomes being averaged over. The limits of \\(\\Omega\\) are based on the specifics of the problem but are defined such that \\(f(x)\\) is a true probability distribution – i.e., \\(\\int_{\\Omega} f(x)dx = 1\\).\n\n5.2.1 An Approximation\nWe often don’t know the full probability distribution \\(f(x)\\). Perhaps more importantly, this formula for the expected utility doesn’t provide us with any analytical insights that help us develop intuition about how features of the environment are likely to affect preferences. To help us develop such intuition, we do the thing that one (almost) always does in such a situation: we perform a Taylor series expansion!\nWe will use \\(\\bar{x}\\), the mean reward as the paint around which we expand expected utility. The Taylor series expansion around the mean reward looks something like this (at least for the first three terms):\n\\[\nu(x) = u(\\bar{x}) + u' (x - \\bar{x}) + \\frac{1}{2} u'' (x - \\bar{x})^2 + \\frac{1}{6} u''' (x - \\bar{x})^3 + \\ldots\n\\]\nWe will focus on the first two terms, and take expectations of both sides of the equation, yielding:\n\\[  \\overline{u(x)} \\approx u(\\bar{x}) + \\frac{1}{2} u''\\, \\operatorname{Var}(x)\n\\]\nThis result follows from the following two definitions:\n\nThe expected value of \\((x-\\bar{x})\\) is zero since \\(E(x-\\bar{x}) = \\bar{x}-\\bar{x}=0\\).\n\\(E(x - \\bar{x})^2)\\) is, by definition, equal to the variance of \\(X\\)\n\nNow let’s think about this result a bit. The second derivative is simply a measure of the curvature of the utility function. In this case, it is the curvature in a very particular point, namely, in the vicinity of the average environment \\(\\bar{x}\\). In the figure below, this is the point where the dashed grey lines converge on the function. If we look to the left side of this point, we see that the curvature is far steeper than on the right side of the point. This means that as we get larger and larger values, the gain in utility, while still positive (more is generally better), the increment by which it increases gets less. We call this situation diminishing marginal utility. In this context, the term “marginal” simply means the next increment. The term marginal is generally used to mean the derivative, or the local rate of change in the slope of a function. When marginal utility is diminishing, it means that the utility curve bends downward. From elementary calculus, we can say that such a curve has a negative second derivative. Inspecting our equation above, we can see that when \\(u''&lt;0\\), variance in \\(x\\) will reduce the expected utility from the utility of the average \\(x\\).\n\nplot(x,fx, type=\"n\", lwd=3, axes=FALSE, frame=TRUE,\n     xlab=expression(x), ylab=expression(U(x)),\n     xaxs=\"i\", yaxs=\"i\", xlim=c(-0.1,5.1), ylim=c(0,1))\n#segments(0,0,5,fx[1000], lwd=2, col=grey(0.75))\naxis(1, at=c(0,2.5,5), labels=c(expression(x[0]), expression(bar(x)),\n                                expression(x[1])), tick=FALSE)\nsegments(2.5,0,2.5,0.846645, lwd=3, lty=1, col=grey(0.65))\nsegments(2.5,0.846645,0,0.846645, lwd=3, lty=1, col=\"red\")\narrows(0,0.846645,0,0.01, lwd=3, lty=1, col=\"red\", length=.25,angle=10)\nsegments(2.5,0.846645,5,0.846645, lwd=3, lty=1, col=\"red\")\narrows(5,0.846645,5,fx[1000], lwd=3, lty=1, col=\"red\", length=.25,angle=10)\nlines(x,fx, lwd=3, col=\"black\")\n\n\n\n\n\n\n\n\nThe fundamental insight provided by our Taylor series analysis of expected utility is that when there is diminishing marginal utility, variance is bad for the decision-maker. This is because in such a case \\(u''&lt;0\\) so the second term in the equation is subtracted from the utility of the mean. Of course, if marginal utility increases, then \\(u''&gt;0\\) and the second term is positive. When there is increasing marginal utility, people are variance loving or risk prone.\nWe can explore in more detail what diminishing marginal utility means for decision-making. To do this, we will first simplify the system a bit. Assume that we are at a value of our resource \\(\\bar{x}\\). We now have to make a decision of whether to take a risk and try to increase our utility or remain where we are. Such a choice is often referred to as a lottery. The decision is risky because we assume that there is an equal probability that we will either succeed. If we succeed our payoff is \\(x+1\\) but if we fail, our payoff is \\(x-1\\). We can depict this situation graphically as in the figure below. The benefit associated with “winning” the lottery (i.e., scoring a return of \\(x_1\\)) is much smaller than the risk associated with losing (i.e., scoring return \\(x_0\\)). The implication of this is that the individual is risk-averse. That is, the would prefer not to take the gamble for the larger payoff if they did not have to. In fact, risk-averse agents should be willing to pay a price for certainty. The difference between the expected utility and the value that risk-averse agents are willing to pay for certainty is the so-called “certainty premium.”\n\nplot(x,fx, type=\"n\", lwd=3, axes=FALSE, frame=TRUE,\n     xlab=expression(x), ylab=\"\", \n     xaxs=\"i\", yaxs=\"i\", xlim=c(0,5.1), ylim=c(0,1))\nsegments(0,0,5,fx[1000], lwd=3, col=grey(0.75))\naxis(1, at=c(0.05,x[179],2.5,5), labels=c(expression(x[0]), expression(x[C]),\n                                          expression(bar(x)), expression(x[1])),\n     tick=FALSE)\nmtext(expression(U(x)), side=2,line=2, adj=0.65)\npar(las=2)\naxis(2, at=0.4882412, labels=\"\", tick=FALSE)\nsegments(2.5,0,2.5,0.4882412,lwd=3, lty=1, col=\"red\") # vertical line at bar(x)\nsegments(2.5,0.4882412,x[179],0.4882412,lwd=3, lty=1, col=\"red\") # horizontal line back to utility curve\nsegments(x[179],0.4882412,x[179],0, lwd=3, lty=1, col=\"green\") # vertical line to x_c\nlines(x,fx, lwd=3, col=\"black\")\ntext(0.35, 0.54, expression(pi==bar(x) - x[C]))\n\n\n\n\n\n\n\n\nTo find the certain payoff that the risk-averse individual would be willing to accept in lieu of the average (risky) payoff \\(\\bar{x}\\), we draw a chord connecting the points of the utility curve at \\(x_0\\) and \\(x_1\\). Because our lottery is a 50/50 chance of winning or losing, the expected value (i.e., average) is the midpoint of this chord. From this point we move horizontally to the left until we hit the utility curve (note that moving horizontally means that we are holding utility constant!). This is the certain utility the individual is willing to receive in lieu of the risky mean. Drawing a line segment down to the x-axis gives us the value of \\(x\\), which we call \\(x_C\\).\n\n\n5.2.2 Arrow-Pratt Index of Risk-Aversion\nThis figure suggests that the more concave (i.e., the more curved) the utility curve is, the more risk-averse the individual will be. We move back further from the utility of the mean to the utility curve when the function is more curved. For a linear utility function – i.e., one with no curve – the points are identical and the person is risk-neutral. The upside gain and downside risk are equal. We can measure the extent of a person’s risk aversion by measuring the curvature of her utility curve. Of course, this is a big “if.” In general, utility curves are theoretical constructs that give us insight into behavior, though this need not be the case (see J. H. Jones and Bliege Bird 2014) for an empirical measurement of a human fitness curve as a function of parity). How does we measure the curvature of a function? We can use calculus, where the second derivative of a function is a measure of local curvature. For our utility curves with diminishing marginal utility, we can see that toward the middle of \\(x\\) (i.e., near \\(\\bar{x}\\), the function \\(u(x)\\) has a high degree of curvature whereas at the upper-end of the range of \\(x\\), it is quite flat. Arrow (1965) used this observation to note that wealthy people tend to be less risk-averse on the margin. A wealthy person is willing to take a financial gamble like a chimpanzee sated on fruit is willing to take a risk hunting red colobus monkeys.\nSince the degree of risk-aversion, as measured by the certainty premium, depends on the degree of curvature of the fitness function. This suggests that a measure of risk using second derivatives of \\(u(x)\\) might be in order. This is exactly what the Arrow-Pratt measure of risk-aversion does. The Arrow-Pratt metric measures the curvature of \\(u(x)\\) (through the second derivative, \\(u''(x)\\)) and scales this by the first derivative, \\(u'(x)\\). Scaling by the first derivative removes the effect of any multiplicative constant on the fitness function (since both the first and second derivatives will contain this constant).\nThe so-called Arrow-Pratt Index of Absolute Risk Aversion is:\n\\[ R_A(x) = -\\frac{u''(x)}{u'(x)}. \\]\nA related measure is known as the index of relative risk aversion:\n\\[ R_R(x) = -\\frac{x u''(x)}{u'(x)}. \\]\nAnother way to think about the relative risk aversion is that it is an elasticity of the marginal utility. Elasticities measure the proportionate change in a quantity for some small change in an input. For example, by what percentage does mean fitness change if we improve juvenile survivorship by 10%? How much does garden production increase if we increase irrigation by 2%? Define an elasticity \\(e(w[x])\\) as\n\\[ e(u[x]) = \\frac{d \\log u}{d \\log x} = \\frac{du}{dx} \\frac{x}{u}. \\]\nIt is not difficult to see that, in fact,\n\\[ R_R(x) = -e(u'(x)). \\]\nThat is, how does marginal utility of a resource – such as food energy – change with an increase in energy availability? If this number is high, people are highly risk averse and should be willing to pay a premium for certainty.\nWe can derive an analytical approximation for the certainty premium. Since the risk premium is difference between expected utility and risk-free utility, we can approximate \\(\\pi\\) by equating respective Taylor series approximations for two functions. It is conventional to employ the second-order Taylor series approximation for expected utility derived for expected utility but to use a first-order Taylor series approximation of the risk-free utility. This bit of mathematical trickery allows us to write a simple formulation for \\(\\pi\\), but is limited in its applicability to small gambles.\nAssume a small gamble where your final wealth is \\(x + \\epsilon\\), where \\(\\epsilon\\) is a random variable with zero mean and variance \\(\\sigma^2\\). Since you would rather take the certainty equivalent to the gamble because you are risk averse, forcing you to take the gamble is effectively the equivalent of of subtracting \\(\\pi\\) from your wealth. This sets up the following equivalence:\n\\[ E\\left[ u(x+\\epsilon)\\right] = u(x-\\pi). \\]\nWe then perform a second-order Talor expansion of the left side and a first-order Taylor expansion of the right-hand side:\n\\[ E\\left[ u(x) + \\epsilon u'(x) + (\\epsilon^2/2)u''(x) \\right] = u(x) - \\pi u'(x).\n\\]\nAgain, the \\(E(\\epsilon)=0\\) and \\(E(\\epsilon^2) = \\operatorname{Var}(x)\\). Note also that \\(-u''(x)/u'(x) = A_u(x)\\), the Arrow-Pratt index of absolute risk aversion. Rearranging (and reminding ourselves this is only true for small gambles), we get\n\\[ \\pi \\approx \\frac{\\sigma^2}{2} A_u(x). \\]\nThis says that, for small gambles, the amount that a risk-averse agent is willing to pay for certainty is proportional to the curvature of her utility curve and the degree of variability, measured by the variance of the resource.\nSo far, all the examples of utility curves have had the same concavity throughout the range of resource values. We have seen that concave utility curves imply risk-aversion. However, there are certainly conditions in which we should expect people to be risk-prone. For example, at very low levels of resource holding (extreme destitution or near-starvation), people might be willing to take a risk to get a reward since, in effect, they have nothing to lose, but then at more average levels of resource holding, people become risk-averse. This is an insight applied in the classic paper by Friedman and Savage (1948) to suggest the origins of middle-class sensibilities. This insight has been applied more recently in an anthropological context by L. Kuznar (2002) and L. A. Kuznar and Frederick (2003).\n\nx &lt;- seq(10,30,length=1000)\n# logistic function\nux &lt;- expression(1/(1+exp(-(x-a)/b)))\na &lt;- 20\nb &lt;- 2\nplot(x,eval(ux), type=\"l\", lwd=3, axes=FALSE, frame=TRUE, yaxs=\"i\",\n     ylim=c(0,1), xaxs=\"i\",\n     xlab=expression(x), ylab=expression(U(x)))\n\n\n\n\n\n\n\n\nThe results of Milner-Gulland and colleagues (1996) provide an excellent demonstration of the relationship to risk changing with wealth in an apparently sigmoid manner. Farmers nearest destitution welcomed the high-variance crop (maize) since scoring a bumper crop of maize was their only chance of raising themselves out of destitution. As farmers become richer, they switch over to millet, despite its lower potential yields. Wealthy farmers do not like variance since they are risk-averse. In contrast, the destitute farmers welcome variance – they have convex utility. Their only hope of emerging from destitution is to get lucky with the rains and score a bumper crop of maize.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Risk, Uncertainty, and Decision-Making</span>"
    ]
  },
  {
    "objectID": "decision.html#time-discounting",
    "href": "decision.html#time-discounting",
    "title": "5  Risk, Uncertainty, and Decision-Making",
    "section": "5.3 Time Discounting",
    "text": "5.3 Time Discounting\nDiscounting is a way of determining preferences. A risk-averse decision-maker might prefer a smaller certain reward to a risky reward with a greater expected value. How does she feel about taking a reward now versus delaying some time \\(\\tau\\)?\n\n5.3.1 Reproductive Value\nWe will start with a concept introduced by Fisher called reproductive value. Reproductive value measures the contribution of an individual age \\(x\\) to the population in the distant future. This probably sounds oddly specific, but it turns out to be really important evolutionarily. Another way to think about reproductive value is that it measures the net present value of all future reproduction.\nFirst, a couple definitions. We will be using an age-structured population. This is a population where the vital rates (i.e., fertility and survival) change with age—you know, like humans? We also assume that these vital rates remain constant in time. We will denote age as \\(x\\). The life-table survivorship, \\(l(x)\\) is the fraction of individuals surviving to exact age \\(x\\). By definition, \\(l(0)=1\\). That is everyone is alive when they are born. At some future age, everyone is dead \\(l(\\infty)=0\\). Survivorship cannot increase with age. It is a cumulative measure of survival. The age-specific fertility rate (ASFR) is denoted \\(m(x)\\) (historically the m was for “maternity”). It is also useful to define the age-specific net reproduction rate, which is simply the product of survivorship and ASFR: \\(\\phi(x) = l(x) m(x)\\).\nWe first consider the case of a stationary population. A population is stationary if it does not change in size. Births exactly match deaths and the population growth rate is zero. In a stationary population, the expected number of future offspring of a newborn individual is the sum of net of the net reproduction rate at each age. In continuous time, this sum is an integral:\n\\[ 1 = \\int_0^{\\infty} l(x) m(x) dx.\\]\nThe summed contributions of each age totals to one. Each individual replaces herself exactly. This makes it clear that \\(\\phi(x) = l(x) m(x)\\) represents the fraction that individuals age \\(x\\) contribute to total reproduction.\nNow consider reproductive value of ages beyond birth. An individual of age \\(a\\) survives to age \\(x\\) with a probability \\(l(x)/l(a).\\)\nThe expected number of future offspring produced by an individual of age \\(a\\) is the integral starting at age \\(a\\) rather than birth, normalized by the probability of actually surviving to \\(a\\).\n\\[\nv(a) = \\int_{a}^{\\infty} \\frac{l(x)}{l(a)} m(x) dx = \\frac{1}{l(a)} \\int_{a}^{\\infty} l(x) m(x) dx.\n\\]\nWe call this the reproductive value at age \\(a\\). Note that \\(v(0)=1\\), since \\(l(0)=1\\). Note also that \\(v(a)\\) can increase up to age at first reproduction (AFR) since \\(1 \\geq l(a) \\geq 0\\). After AFR, it will decrease monotonically.\nNow we consider the more general case of nonstationarity, i.e., where births do not exactly balance out deaths. In this case, the population can increase of decline. If, on average, a population has a negative growth rate, this means it will go extinct, so we typically think about populations with positive growth rates. We will denote the instantaneous growth rate of the population as \\(r\\). This growth rate is the difference between the gross birth rate and the gross death rate. If \\(r&gt;0\\), then the population increases over time. While they change with age, we have assumed that our vital rates remain constant over time. Because the input rates remain constant, this means that the growth rate also remains constant. A constant growth rate in a continuous-time model implies exponential growth. This arises because in the limit (i.e., as the time step in which we account for the population goes to zero), population size at time \\(y\\) is the solution to the equation \\(dN/dx = rN\\) which is \\(e^{rx}\\) times the initial population size.\nIn a growing population, offspring born sooner constitute a larger fraction of the population. An offspring born into a population at time \\(a\\) represents \\(1/N(a)\\) of the population – remember, we are interested in an individual of age \\(a\\)’s contribution to the population. In an population growing exponentially at rate \\(r\\), the size of the population \\(x\\) years in the future will be \\(e^{rx}\\) times bigger than it is in the present. Thus, because the population is growing exponentially, an offspring born at time \\(x&gt;a\\) must be discounted by a factor of \\(e^{-rx}\\) (i.e., we divide the the factor by which the population has increased).\nA simple way to visualize.\n\nrequire(igraph)\naaa &lt;- graph.empty(20)\nbbb &lt;- graph.empty(100)\nvc20 &lt;- rep(\"cyan\",20)\nvc20[7] &lt;- \"magenta\"\nvc100 &lt;- c(vc20,rep(\"cyan\",80))\n\n# reproducing in a smaller population\nplot(aaa, vertex.color=vc20, vertex.frame.color=vc20,vertex.label=NA)\n\n\n\n\n\n\n\n# reproducing in a larger population\nplot(bbb, vertex.color=vc100, vertex.frame.color=vc100,vertex.label=NA)\n\n\n\n\n\n\n\n\nWe can now incorporate this information into the equation for reproductive value. To obtain the reproductive value at age \\(a\\), we need to sum all the above terms from age \\(a\\) to the maximum age \\(\\omega\\) (or alternatively, \\(\\infty\\)). The calculation of reproductive value at age \\(a\\) thus requires that we integrate across all expected future offspring starting at age \\(x\\) and divide by the probability of surviving to age \\(a\\) (as before). The only thing that is different is that we have to discount according to the population growth rate \\(r\\) and the delay \\(x - a\\). Putting this all together, we get:\n\\[\n  v(a) =  \\int_{a}^{\\infty} e^{-r(x - a)} \\frac{l(x)}{l(a)} m(x) dx\n\\]\nWith a little algebra (basically taking everything that doesn’t depend on \\(x\\) outside of the integral), we will get the form for reproductive value that Fisher first introduced in 1930 and which we usually encounter in the literature:\n\\[\n  v(a) = \\frac{e^{ra}}{l(a)} \\int_{a}^{\\infty} e^{-rx} l(x) m(x) dx.\n\\]\nWhat does this have to do with time preferences? Just as in the stationary case, we can think of the expression in the integral as the contribution to total reproductive value by each age \\(x\\). The obvious difference now is that the net reproduction at each age is multiplied by a discount factor \\(e^{-rx}\\), which accounts for the fact that the population is growing at a constant rate \\(r\\). At birth, \\(x=0\\), this discount factor is equal to one, since \\(e^0=1\\). We also know that \\(e^{-rx} \\rightarrow 0\\) as \\(x\\) goes to infinity.\nWhat this means is that, all things being equal, it’s better for fitness to reproduce early in life than it is late in life. In a growing population, when you reproduce early, your relative contribution to the total population is greater. The longer you wait to reproduce, the larger the population becomes, and the less your relative contribution will be. This is the essence of temporal discounting: you prefer to do something in the present because it is, for some reason, more valuable now than it is later. If you choose to delay, the reward that you receive in the future will need to be much bigger than it would be now.\n\n\n5.3.2 Temporal Discounting in Economic Models\nUnless you are a biologist or possibly a demographer, most applications of discounting involve economic choices. In the economic domain, we are asking the question of whether we would prefer to consume now or delay until some future time. In the demographic/evolutionary context, there was a clear reason why early reproduction is preferred: the delaying reproduction means that the population will grow in the interim and your contribution to the total population will be relatively smaller. Remarkably, it’s not as clear why time preferences exist in economic decision-making. Some early authors early authors such as Bohm-Bawerk and Fisher (different guy) were naturally impatient because of a lack of imagination. John Rae, in his The Sociological Theory of Capital suggested that mortality may actually drive time preferences. If you delay your consumption from now to some time in the future, there is a chance that you might die and be unable to enjoy the consumption you have foregone.\nOne possibility, of course, is that time preferences arise because of opportunity costs. If you receive a payment today, rather than waiting for some future payout, you could put that payment into an interest-bearing account of some sort and its value could grow. This makes it very similar to the logic of reproductive value. The major problem with this interpretation is that interest-bearing accounts are a (very) recent invention in human history, yet people seem to universally express time preferences. Risk as expressed over time — i.e., a hazard — seems like the best explanation. There is a risk you might die or that the person with whom you’ve agreed to some delayed payment might die or that there might be a catastrophe and the payment will become valueless for some reason or … There are lots of reasons why you might worry about the value of a future payoff. Sophisticated, evolutionary-minded scholars have weighed in on the foundations and consequences of discount rates (Rogers 1994; Sozou 1998; Sozou and Seymour 2003).\nRegardless of why we discount future consumption, there is near-universal agreement that time preferences are important for economic-choice problems. Varian (1992) noted succinctly that goods simply need to “be distinguished by any characteristic that agents care about,” which includes when they are available.\nThe simplest way to think about economic discounting is a two-period model of total utility. You utility is the sum of the utility of your consumption now and the utility of your consumption in the future time period, discounted to account for the delay.\n\\[\nU_0 = u(x_0) + D_1 u(x_1).\n\\]\nWe write the total utility as \\(U_0\\) to indicate that this is the total utility starting at time zero. We call \\(D_1 \\le 1\\) a discount factor. Depending on the level of generality, this can be a function, it can be a specific value for the time period, or it can be constant. In the classic approach first laid out by Samuelson (1937) and axiomatized by Koopmans (1960), the discount rate is constant. In continuous time, this leads to exponential discounting. This exponential discounting has since become a key element of the rational-choice/expected-utility framework that dominates the economic theory of choice, as only exponential discounting is consistent with the features deemed important for establishing time preferences, namely, certainty, stationarity, and time consistency. Certainty means that discounts are guaranteed for every time interval greater than zero. Stationarity means that the discount function is independent of the time in which it is applied. Time consistency means that the discount function is consistent across a time interval regardless of when that time interval occurs (i.e., a one-period delay is discounted at the same rate if it starts today or starts a year from now).\nThe frequent way that intertemporal preferences enter scholarship focused on human ecology and adpation is studying consumption streams over a lifetime or across generations (e.g., Dasgupta 2008). This is just a series of levels of consumption over time. The total utility or present value of a consumption stream is\n\\[\nU_0 = \\sum_0^T u(x_t)/(1+\\delta)^t.\n\\]\nHere \\(U_0\\) indicates that this is the total utility starting at time zero, \\(x_0, x_1, \\ldots, x_T\\) is the consumption stream to maximum time \\(T\\) (which may be \\(T=\\infty\\)), and \\(\\delta\\) is the discount rate. The discount factor at some time \\(t\\) is \\(1/(1+\\delta)^t\\), which is the discrete-time equivalent of \\(e^{-\\delta t}\\) (so certainty, stationarity, and time consistency are fulfilled).\nThis model is also said to be separable, which simply means that the utilities at any given time point do not depend on either past or present utilities. Incidentally, if our total utility is the sum of all of a group’s (e.g., a society, a generation) individual utilities (as it often is in applications), there is another big assumption built in. In particular, it assumes that the individual units (people, households) derive no utility from the consumption of other units. We can say that there are no consumption externalities (Acemoglu 2009). This is a major individualist assumption that may not be appropriate for some social systems.\n\n\n5.3.3 Non-Constant Discounting\nExponential discounting (i.e., discounting at a constant rate in continuous time) provides a way to discount future consumption that satisfies stationarity, and time consistency. That doesn’t mean that this is how people actually express their time preferences.\nIn particular, people’s actual time-preferences are frequently not constant in time, but are characterized by two key features. First, is a present bias (PB) that causes very steep (i.e., faster than exponential) initial discounting. People often really prefer the immediate to even a brief waiting period. Second, is a flattening of discounting for longer time periods, known as diminishing impatience (DI). Taken together, these characteristics are often described as hyperbolic discounting because the qualitatively resemble of hyperbolic curve (Ainslie 1975; Loewenstein and Prelec 1992; Laibson 1997). Such time preferences are inconsistent in the sense that two curves are likely to cross, leading to preference reversals. Hyperbolic-like time preferences are frequently interpreted as problems in self-control (Ainslie 1975; O’Donoghue and Rabin 1999).\nHere, we can compare hyperbolic and exponential discount curves. While the hyperbolic curve decays much faster to start, it levels out as time gets more remote from the present.\n\nt &lt;- seq(0,10,length=100)\nhyperf &lt;- expression(1/(1+t))\nexpf &lt;- expression(2^-t)\nplot(t,eval(hyperf), type=\"l\", col=\"red\", lwd=3, xlab=\"Time\", ylab=\"Discount\", ylim=c(0,1))\nlines(t,eval(expf), col=\"black\", lwd=3)\nlegend(\"topright\",c(\"exponential\", \"hyperbolic\"), lwd=3, col=c(\"black\",\"red\"))\n\n\n\n\n\n\n\n\nWe can, of course, check to see that the exponential curve yields time-consistent dicounts, while the hyperbolic curve does not.\n\nplot(t[-100],exp(diff(log(eval(expf)))), type=\"l\", col=\"black\", lwd=3, xlab=\"Time\", ylab=\"Ratio of Discount Factors\", ylim=c(0.9,1))\nlines(t[-100], exp(diff(log(eval(hyperf)))), type=\"l\", col=\"red\", lwd=3)\nlegend(\"topleft\",c(\"exponential\", \"hyperbolic\"), lwd=3, col=c(\"black\",\"red\"))\n\n\n\n\n\n\n\n\nThe argument of Ainslie (1975) that hyperbolic preferences reveal problems in self-control is actually made using hyperbolic growth curves. Here, the less-preferred option (the black curve starts lower than the red curve) is chosen because it “matures” faster.\n\nt &lt;- seq(0,100,length=500)\ntc &lt;- 110\nK &lt;- 20\na &lt;- 1\nhgf &lt;- expression(K/(tc-t*a))\nslow &lt;- eval(hgf)\nplot(t,slow, type=\"l\", col=\"red\", lwd=3, xlab=\"Time\", ylab=\"Value\", ylim=c(0,2))\ntc &lt;- 100\nK &lt;- 10\na &lt;- 1.01\nfast &lt;- eval(hgf)\nlines(t[fast&gt;0],fast[fast&gt;0], type=\"l\", col=\"black\", lwd=3)\nlegend(\"topleft\",c(\"Fast-Small\", \"Slow-Large\"), lwd=3, col=c(\"black\",\"red\"))",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Risk, Uncertainty, and Decision-Making</span>"
    ]
  },
  {
    "objectID": "decision.html#uncertainty",
    "href": "decision.html#uncertainty",
    "title": "5  Risk, Uncertainty, and Decision-Making",
    "section": "5.4 Uncertainty",
    "text": "5.4 Uncertainty\n\n5.4.1 Uncertainty Explains Hyperbolic Discounting\nSozou (1998) demonstrated how uncertainty can lead an individual who has otherwise time-consistent preferences to show PB/DI. This result has been replicated in the economic literature as well (Martin L. Weitzman 1998; Dasgupta and Maskin 2005; Halevy 2008). Essentially, when uncertainty about the discount rate is sufficiently high, an earlier and later payoff are (stochastically) indistinguishable. Circling back to Varian’s (1992) justification for time preferences, namely, that it is a way to distinguish potential choices, uncertainty means that you might not be able to distinguish, say, an option that pays out in 10 years vs. one that pays out in 20 years because of uncertainty. The further removed in time an event is, the more that uncertainty gets compounded. It thus makes sense that we should see diminished impatience under uncertainty. Halevy (2008, 1145) noted “the crucial distinction between the present and the future is that only the present can be certain, while any future plan is uncertain.”\n\n\n5.4.2 Uncertainty Breaks Intertemporal Choice and Cost-Benefit Analysis\nSuppose we have some measured variable which we assume follows a normal distribution with unknown mean and variance. Using Bayesian reasoning, it is straightforward (though tedious) to derive the posterior distribution of both the unknown mean and variance (this is known as the joint posterior distribution). However, we’re typically primarily interested in the mean in applications and relegate variance to the status of a “nuisance parameter,” necessary for estimation of the quantities of interest but not generally of direct interest itself. One therefore typically focuses on the marginal distribution for the mean by averaging over the uncertainty in the variance. This leads to the interpretation of the posterior distribution as being a mixture of normals with the same mean, conditional on the variance – i.e., we essentially overlay different bell-shaped normal curves with different heights and breadths but all centered at the same point.\nWith some standard assumptions about our prior information on this measurement, guess what the resulting distribution is? If you’ve been paying attention and haven’t been lulled to sleep, you probably guessed Student’s \\(t\\)-distribution! This is the classical result that is used in a \\(t\\)-test for comparing two means with unknown variance. The best estimate of the mean is the sample mean, and its standard deviation is given by the standard error. How spread out a \\(t\\)-distribution is depends on the number of degrees of freedom it has. This is essentially just the number of observations that are used to estimate the distribution. If you have fewer data, you have fewer degrees of freedom and a shorter, wider distribution. The fewer the degrees of freedom, the greater the uncertainty.\nGeweke (2001) made this observation. He used a simple Bayesian conjugate model for a normal mean. If the variance of the distribution is known, the posterior is simply another normal with variance scaled by the sample size. However, if the variance is also unknown, the marginal posterior distribution is \\(t\\). The heavy tails come from the fact that you have to integrate the normal distribution for the mean over the uncertainty in variance. If you have a finite number of trials in which to learn, you end up with heavy tails. The moment-generating function for the \\(t\\) distribution does not exist and this means that expected utility is not well-defined.\nSo what? As we discussed above, the Student-\\(t\\) distribution is known as a fat-tailed or heavy-tailed distribution. This essentially means that there is non-negligible probability of extreme outcomes. More technically, we can say that a random variable is heavy-tailed if and only if its moment generating function \\(M(s)\\) is infinite for all \\(s &gt; 0\\). We can also say that a random variable \\(X\\) is heavy-tailed if the log of the probability of \\(x\\) as \\(x \\rightarrow \\infty\\) decays sub-linearly (Nair, Wierman, and Zwart 2022). This latter condition captures the idea that there will be non-negligible probabilities potentially associated with extreme values when a random variable has a heavy-tailed distribution.\nWe do a cost-benefit analysis (CBA). Discount the future benefits. A funny thing happens when we calculate the expected utility of investing in climate mitigation when the distribution of future disutility is a fat-tailed. The benefit to averting the worst outcomes is essentially infinite. So we can discount the future as much as we want in order to favor the immediate. Ain’t no discounting infinity tho.\nM. L. Weitzman (2009) argues that the logic that leads from structural uncertainty to heavy-tailed distributions of environmental outcomes naturally leads to a precautionary principle. Weitzman also notes that his so-called “Dismal Theorem” makes positing an ad hoc additional of ambiguity aversion to the theory of decision-making under risk unnecessary.\nIntegrate that text with the more technical bits:\nThe natural conclusion from the CBA is that, given the fat tail of outcomes-of-global-warming distribution, is that strong action to mitigate the future effects of this looming problem is clearly rational.\nNotes that the expected moment, \\(E[M] = \\beta\\; E[\\exp(-\\eta Y)]\\), is the amount of present consumption the agent would be willing to give up in the present period to obtain one extra sure unit of consumption in the future. \\(Y\\) is the log of “reduced-form consumption that has been adjusted for welfare by subtracting out all damages from climate change” (\\(C\\)).\n\\(\\beta\\) is the time-preference parameter (\\(\\delta = -\\log(\\beta)\\)) is the instantaneous rate of pure time preference) in the ‘stochastic discount factor’ or ‘pricing kernel’ ” (quotes in original)\n\\[M[C] = \\beta \\frac{U'(C)}{U'(1)} = \\beta \\exp(- \\eta Y)\\]\n\\(E[M]\\) is a shadow price for discounting future costs and benefits.\nLetting \\(y\\) represent a realization of the random variable \\(Y\\), and \\(f(y)\\) denoting the PDF of \\(Y\\) (this is the expected stochastic discount factor),\n\\[E[M] = \\beta \\int_{-\\infty}^{\\infty} e^{-\\eta y} f(y) dy\\]\n\\(E[M]\\) is the Laplace-transform or moment-generating function of \\(f(y)\\). This is convenient since it means that the expected stochastic discount factor has the same properties as the moment-generating function of the PDF of \\(f(y)\\).\nThe MGF of a t-distribution is infinite. This is true for any fat tail distribution (Nair, Wierman, and Zwart 2022).\nWithout well-defined moments of the distribution, you cannot do standard cost-benefit analysis. That “expected” in expected utility theory refers to the first moment of a distribution!\nthe \\(t\\)-distribution arises from a compounding a normal distribution with known mean and variances given by an inverse-gamma distribution (which is a standard distribution for unknown variance). When you marginalize (i.e., average over) this unknown variance, the resulting distribution of \\(t\\).\nDenote the data used for calculating the posterior distribution \\(y\\), the parameters of this distribution \\(\\theta\\), and new data not yet collected as \\(\\tilde{y}\\). The posterior predictive distribution of \\(\\tilde{y}\\) given \\(y\\) can be written as:\n\\[\np(\\tilde{y}|y) = \\int_{\\Theta} p(\\tilde{y}|\\theta) p(\\theta|y) d\\theta\n\\]\nThat is, we calculate the expectation of \\(\\tilde{y}\\), given the posterior distribution \\(p(\\theta|y)\\).\n“Something quite extraordinary seems to be happening here, which is crying out for further elucidation! Thousands of applications of EU theory in thousands of articles and books are based on formulas like (5) or (6). Yet when it is acknowledged that s is unknown (with a standard noninformative reference prior) and its value in formula (5) or (6) must instead be inferred as if from a data sample that can be arbitrarily large (but finite), expected marginal utility explodes. The question then naturally arises: What is EU theory trying to tell us when its conclusions for a host of important applications—in CBA, asset pricing, and many other fields of economics—seem so sensitive merely to the recognition that conditioned on finite realized data the distribution implied by the normal is the Student-t?” (p. 8)\nExperience will generally overweight information on the least-consequential part of the outcome distribution. Rare but highly-consequential outcomes are still rare. You are unlikely to experience one in a small sample.\nWeitzman’s Dismal Theorem (DT):\n\\[ \\lim_{\\lambda \\rightarrow \\infty} E[M|\\lambda]] = +\\infty \\]\ni.e., as the value of statistical life gets large, the shadow price of future consumption becomes infinite.\n“No matter how much data-evidence exists—or even can be imagined to exist—DT says that \\(E[M|\\lambda]\\) is always exceedingly sensitive to very large values of \\(\\lambda\\)” (p. 12).\n(where \\(\\lambda\\) the statistical-value-of-life-like parameter)\nGeneralized Ramsey formula for the risk-free interest rate:\n\\[ r^f = \\delta + \\eta \\mu - \\frac{1}{2} \\eta^2 s^2 \\]\nwhere \\(\\delta\\) is the rate of pure time preference, \\(\\mu\\) is the mean of \\(Y\\), the log of adjusted consumption), \\(\\eta\\) is the CRRA parameter.\nThis assumes that utility is CRRA, of course. CRRA means constant relative risk aversion. It is a utility model that is also known as the power utility function or isoelastic utility function. For consumption level \\(c\\), the CRRA utility is given by:\n\\[\nu(c)= \\begin{cases}\\frac{c^{1-\\eta}-1}{1-\\eta} & \\eta \\geq 0, \\eta \\neq 1 \\\\ \\ln (c) & \\eta=1\\end{cases}.\n\\]\nCRRA utility is increasing and concave because \\(u'(c ) = c^{-\\eta}\\) The index of relative aversion (\\(R\\)) to intertemporal inequality is constant, and is equal to \\(\\eta\\).\nGollier (2013) explains that the key question is “What is the maximum reduction \\(k\\) of current consumption that you are ready to sacrifice, or invest, to increase future consumption by 1 dollar?”\nThe power utility form makes big assumption that \\(k\\) only on the growth rate and not on the initial absolute level of consumption. Moreover, Gollier (2013) notes that a power utility is inappropriate when there is the possibility of ruin. For example, it suggests that marginal utility tends to infinity when \\(c\\) approaches zero. This means that if there was some future state of the world where consumption approached zero, someone using a CRRA utility function would be ready to sacrifice almost 100% of their current wealth to increase wealth in this future state by one dollar. This means that we should be very cautious about any strong statements about extreme futures made using CRRA.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Risk, Uncertainty, and Decision-Making</span>"
    ]
  },
  {
    "objectID": "decision.html#ontogeny-of-decision-making",
    "href": "decision.html#ontogeny-of-decision-making",
    "title": "5  Risk, Uncertainty, and Decision-Making",
    "section": "5.5 Ontogeny of Decision-Making",
    "text": "5.5 Ontogeny of Decision-Making\nRationality is generally seen as a factory-installed feature of the human brain. Hobbes famously imagined that men suddenly sprang from the Earth “like mushrooms come to full maturity, without all kind of engagement to each other.”\nIn the Philosophical Baby, Alison Gopnik writes “you could read 2,500 years of philosophy and find almost nothing about children.”",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Risk, Uncertainty, and Decision-Making</span>"
    ]
  },
  {
    "objectID": "decision.html#the-erasure-of-uncertainty",
    "href": "decision.html#the-erasure-of-uncertainty",
    "title": "5  Risk, Uncertainty, and Decision-Making",
    "section": "5.6 The Erasure of Uncertainty",
    "text": "5.6 The Erasure of Uncertainty\nKay and King (2020): “After the Second World War Friedman denied the existence of such a distinction and the two concepts were elided not just in the field of economics, but in a much wider arena in which decision theory and Bayesian reasoning held sway.” (loc 5931)\nAccording to this worldview, “Radical uncertainty must be erased from the picture because it cannot be measured and cannot be priced.” (loc 5940)\n\n\n\n\nAcemoglu, Daron. 2009. Introduction to Modern Economic Growth. Princeton: Princeton University Press.\n\n\nAinslie, G. 1975. “Specious Reward: Behavioral Theory of Impulsiveness and Impulse Control.” Psychological Bulletin 82 (4): 463–96. https://doi.org/10.1037/h0076860.\n\n\nArrow, K. J. 1965. Aspects of the Theory of Risk-Bearing. Helsinki: Yrjö Hahnsson Foundation.\n\n\nDasgupta, P. 2008. “Discounting Climate Change.” Journal of Risk and Uncertainty 37 (2-3): 141–69. https://doi.org/10.1007/s11166-008-9049-6.\n\n\nDasgupta, P., and E. Maskin. 2005. “Uncertainty and Hyperbolic Discounting.” American Economic Review 95 (4): 1290–99. https://doi.org/10.1257/0002828054825637.\n\n\nFriedman, M., and L. J. Savage. 1948. “The Utility Analysis of Choices Involving Risk.” The Journal of Political Economy 56 (4): 279–304. https://doi.org/10.1086/256692.\n\n\nGeweke, John. 2001. “A Note on Some Limitations of CRRA Utility.” Economics Letters 71 (3): 341–45. https://doi.org/10.1016/S0165-1765(01)00391-3.\n\n\nGintis, H. 2007. “A Framework for the Unification of the Behavioral Sciences.” Behavioral and Brain Sciences 30 (1): 1–61. https://doi.org/10.1017/S0140525X07000581.\n\n\nGollier, Christian. 2013. Pricing the Planet’s Future: The Economics of Discounting in an Uncertain World. Princeton: Princeton University Press.\n\n\nHalevy, Yoram. 2008. “Strotz Meets Allais: Diminishing Impatience and the Certainty Effect.” American Economic Review 98 (3): 1145–62. https://doi.org/10.1257/aer.98.3.1145.\n\n\nJones, J. H., and R. Bliege Bird. 2014. “The Marginal Valuation of Fertility.” Evolution and Human Behavior 35 (1): 65–71. https://doi.org/10.1016/j.evolhumbehav.2013.10.002.\n\n\nJones, James Holland, Rebecca Bliege Bird, and Douglas W. Bird. 2013. “To Kill a Kangaroo: Understanding the Decision to Pursue High-Risk/High-Gain Resources.” Proceedings of the Royal Society B: Biological Sciences 280 (1767): 20131210. https://doi.org/10.1098/rspb.2013.1210.\n\n\nKay, J. A., and M. A. King. 2020. Radical Uncertainty: Decision-Making Beyond the Numbers. W. W. Norton, Incorporated. https://books.google.com/books?id=1S1AxQEACAAJ.\n\n\nKoopmans, Tjalling C. 1960. “Stationary Ordinal Utility and Impatience.” Econometrica 28 (2): 287–309. https://doi.org/10.2307/1907722.\n\n\nKuznar, L. 2002. “On Risk-Prone Peasants: Cultural Transmission or Sigmoid Utility Maximization?” Current Anthropology 43 (5): 787–89. https://doi.org/10.1086/344370.\n\n\nKuznar, L. A., and W. G. Frederick. 2003. “Environmental Constraints and Sigmoid Utility: Implications for Value, Risk Sensitivity, and Social Status.” Ecological Economics 46 (2): 293–306. https://doi.org/10.1016/S0921-8009(03)00167-8.\n\n\nLaibson, David. 1997. “Golden Eggs and Hyperbolic Discounting.” The Quarterly Journal of Economics 112 (2): 443–78. https://doi.org/10.1162/003355397555253.\n\n\nLoewenstein, George, and Drazen Prelec. 1992. “Anomalies in Intertemporal Choice: Evidence and an Interpretation.” The Quarterly Journal of Economics 107 (2): 573–97. https://doi.org/10.2307/2118482.\n\n\nMilner-Gulland, E. J., Ruth Mace, and Ian Scoones. 1996. “A Model of Household Decisions in Dryland Agropastoral Systems.” Agricultural Systems 51 (4): 407–30. https://doi.org/10.1016/0308-521X(95)00057-C.\n\n\nNair, Jayakrishnan, Adam Wierman, and Bert Zwart. 2022. The Fundamentals of Heavy Tails: Properties, Emergence, and Estimation. Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge: Cambridge University Press.\n\n\nNeumann, John von, and Oskar Morgenstern. 1947. Theory of Games and Economic Behavior. 2nd Ed. Princeton, NJ: Princeton University Press.\n\n\nO’Donoghue, Ted, and Matthew Rabin. 1999. “Doing It Now or Later.” The American Economic Review 89 (1): 103–24. https://doi.org/10.1257/aer.89.1.103.\n\n\nRogers, A. R. 1994. “Evolution of Time Preference by Natural Selection.” American Economic Review 84 (3): 460–81. http://www.jstor.org/stable/2118062.\n\n\nSamuelson, Paul A. 1937. “A Note on Measurement of Utility.” The Review of Economic Studies 4 (2): 155–61. https://doi.org/10.2307/2967612.\n\n\nSozou, P. D. 1998. “On Hyperbolic Discounting and Uncertain Hazard Rates.” Proceedings of the Royal Society of London. Series B: Biological Sciences 265 (1409): 2015–20. https://doi.org/10.1098/rspb.1998.0534.\n\n\nSozou, P. D., and R. M. Seymour. 2003. “Augmented Discounting: Interaction Between Ageing and Time-Preference Behaviour.” Proceedings of the Royal Society of London Series B-Biological Sciences 270 (1519): 1047–53. https://doi.org/10.1098/rspb.2003.2344.\n\n\nVarian, Hal R. 1992. Microeconomic Analysis. 3rd ed. New York: Norton.\n\n\nWeitzman, M. L. 2009. “On Modeling and Interpreting the Economics of Catastrophic Climate Change.” The Review of Economics and Statistics XCI (1): 1–19. https://doi.org/10.1162/rest.91.1.1 .\n\n\nWeitzman, Martin L. 1998. “Why the Far-Distant Future Should Be Discounted at Its Lowest Possible Rate.” Journal of Environmental Economics and Management 36 (3): 201–8. https://doi.org/10.1006/jeem.1998.1052.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Risk, Uncertainty, and Decision-Making</span>"
    ]
  },
  {
    "objectID": "complex.html",
    "href": "complex.html",
    "title": "6  Complexity",
    "section": "",
    "text": "6.0.1 Lotka-Volterra\nThe Italian biologist Humberto D’Ancona noted that during the first World War, the composition of fish in the markets around the Adriatic Sea changed substantially. During the war, the percentage of predatory fish for sale in the markets of Trieste, Fiume, and Venice increased. D’Ancona had no explanation for this and approached his father-in-law, the eminent mathematician Vito Volterra, with the riddle. Volterra’s solution forms the foundation for nearly all subsequent theory regarding the interaction of species within communities. The great American biologist and demographer, Alfred Lotka, developed the same framework about the same time and the equations have since been known as the Lotka-Volterra model for predatory/prey dynamics.\nThe classical theory of species interactions is attributable to Alfred Lotka and Vito Volterra Reduce communities to a single consumer-resource relationship – typically between a primary consumer (i.e., a herbivore) and a secondary consumer (i.e., a carnivore)\nAssumptions of Lotka-Volterra Model: 1. in the absence of a predator, the prey population increases exponentially 2. in the absence of prey, the predator population decays exponentially 3. per capita rate of kill a linear function of prey density 4. each kill contributes equally to predator growth\nWe can write the equations for the predator-prey model that encapsulates these assumptions.\n\\[\n\\begin{align}\n\\dot{x}_1 &=  x_1 (r_1 - a_{12} x_2) \\\\\n\\dot{x}_2 &=  x_2 (-r_2 + a_{21} x_1)\n\\end{align}\n\\] Here, we have used the notation that \\(\\dot{x} \\equiv dx/dt\\). That is the dotted variable represents a time derivative. The prey population is \\(x_1\\) and its growth rate is \\(r_1\\). Similarly, the predator population is \\(x_2\\) and its growth rate is \\(r_2\\). The parameters \\(a_{ij}\\) are interaction terms, where \\(a_{12}\\) is the impact that predators have on the growth rate of the prey population and \\(a_{21}\\) is the rate a which prey are converted into more predators. Note that in the absence of predator/prey, the solutions to the two equations are exponential increase/decay as per assumptions 1 and 2 above.\nWe can use the R package deSolve to numerically integrate these equations, plot the solutions, etc.\nrequire(deSolve)\n## Lotka-Volterra equations\nlv &lt;- function(t, x, parms) {\n  with(as.list(parms), {\n    dx1 &lt;- r1*x[1] - c1*x[1]*x[2]\n    dx2 &lt;- -r2*x[2] + c2*x[1]*x[2]\n    results &lt;- c(dx1,dx2)\n    list(results)\n  })\n}\n\n# parameters\nxstart &lt;- c(x1=10,x2=1)\ntimes &lt;- seq(0,100,length=1001)\nparms &lt;- c(r1=0.5,r2=0.5, c1=0.1,c2=0.02)\nout1 &lt;- as.data.frame(ode(xstart,times,lv,parms))\n\n# plot\nwith(out1, plot(time, x1, type=\"l\", lwd=3, col=\"red\", \n                xlab=\"Time\", ylab=\"Population Size\", xlim=c(0,100), ylim=c(0,90)))\nwith(out1, lines(time, x2, lwd=3, col=\"blue\"))\nlegend(\"topleft\",c(\"prey\",\"predator\"), lwd=3, col=c(\"red\",\"blue\"))\nTime series of the two-species Lotka-Volterra system.\nAnd the phase portrait, which takes out the middle man, as it were (i.e., time).\n#Phase Portrait\nwith(out1, plot(x1, x2, type=\"l\", col=\"magenta\", lwd=3, \n                xlab=\"Prey Population Size\", \n                ylab=\"Predator Population Size\",\n                xlim=c(0,90), ylim=c(0,20)))\nIt just keeps cycling…\nThe canonical model of lynxes and hares, the Lotka-Volterra predator-prey model shows clock-like regularity. Usually presented as an endlessly-cycling time series, but I think it’s more useful to show the phase portrait, where the abundances of the predator are plotted directly against the abundances of the prey, rather than both of the against time.\nlh &lt;- read.table(\"data/LynxHare.txt\")\nnames(lh) &lt;- c(\"Year\",\"Hare\",\"Lynx\")\nplot(lh$Year, lh$Hare, type=\"l\", lwd=2, xaxs=\"i\", \n     col=\"red\", xlab=\"Year\", ylab=\"Abundance\")\nlines(lh$Year, lh$Lynx, lwd=2, col=\"blue\")\nlegend(\"topright\", c(\"Hares\",\"Lynx\"), col=c(\"red\",\"blue\"), lty=1, lwd=2)\nReality is always messier than theory.\nHastings and Powell (1991) took the standard Lotka-Volterra model and added a third species. They used biologically realistic parameter values for a three-level food web. Chaos ensued (literally).\nhp91 &lt;- function(t,x,parms){\n  with(as.list(c(parms,x)), {\n    dx1 &lt;- x1*(1-x1) - x2*a1*x1/(1+b1*x1)\n    dx2 &lt;- x2*a1*x1/(1+b1*x1) - x3*a2*x2/(1+b2*x2) - d1*x2\n    dx3 &lt;- x3*a2*x2/(1+b2*x2) - d2*x3\n    res &lt;- c(dx1,dx2,dx3)\n    list(res)\n  })\n}\n\n#b1 varied from 2.0-6.2\nparms &lt;- c(a1=5.0, b1=3.0, a2=0.1, b2=2.0, d1=0.4, d2=0.01)\nxstart &lt;- c(x1=0.9692178, x2=0.02620731, x3=7.865967) #their starting values\ntimes &lt;- seq(0,1000, length=10001)\nout1 &lt;- as.data.frame(lsoda(xstart, times, hp91, parms))\n\nplot(out1[,1]/20,out1[,4], log=\"y\",type=\"l\",col=\"blue\", lwd=3,\n     xlab=\"Time\",ylab=\"Population Size\", ylim=c(0.01,10.5))\nlines(out1[,1]/20,out1[,3],col=\"red\", lwd=3)\nlines(out1[,1]/20,out1[,2],col=\"magenta\", lwd=3)\nAnd the phase portraits\npar(mfrow=c(1,3))\nplot(out1[,2],out1[,3], type=\"l\",col=\"blue\", xlab=\"species 1\", ylab=\"species 2\")\nplot(out1[,2],out1[,4], type=\"l\",col=\"blue\", xlab=\"species 1\", ylab=\"species 3\")\nplot(out1[,3],out1[,4], type=\"l\",col=\"blue\", xlab=\"species 2\", ylab=\"species 3\")\nThis is a canonical example of complexity.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Complexity</span>"
    ]
  },
  {
    "objectID": "complex.html#feedback",
    "href": "complex.html#feedback",
    "title": "6  Complexity",
    "section": "6.1 Feedback",
    "text": "6.1 Feedback\nFeedback is when the output of a system becomes the input for future iteration. Feedback systems can greatly complicated the analysis (and meaning) of cause and effect. Feedback is the foundation of complex systems. Feedback is necessarily nonlinear.\nThere are two broad categories of feedback. Negative Feedback is self-regulatory. Examples include thermostats, insulin-glucagon regulation of blood glucose, logistic growth. Positive Feedback is runaway. Examples include: nuclear fission, economic cycles, lactation, human capital. When you have positive feedback, small disturbances will grow. Another way to describe positive feedback is to say that it is in phase with inputs.\n\n\n\nA feedback loop.\n\n\nMore…",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Complexity</span>"
    ]
  },
  {
    "objectID": "complex.html#complex-systems",
    "href": "complex.html#complex-systems",
    "title": "6  Complexity",
    "section": "6.2 Complex Systems",
    "text": "6.2 Complex Systems\nCollection of interacting units bound together through feedback (coupling) Complex systems lie at the boundary between perfect order and perfect disorder A Complex Adaptive System (CAS) is a subset of a complex system in which there is the capacity for learning and adaptation\nComplex systems generally have many connections between elements (i.e., coupling) Many complex systems are characterized by nonlinear change (e.g., competition, predation, mobility, economic production, epidemic models) These can make prediction and management difficult Just because things vary, doesn’t mean anything is wrong This is what we expect of complex systems – not simple equilibria\nA nice illustration of the sensitivity to initial conditions comes from May (1976). logistic map is a discrete-time model for population dynamics. It’s a simple equation that can lead to some very complex dynamics.\n\n6.2.1 Sensitivity to Initial Conditions\nConsider the plot below inspired by the work of May (1973). Plot time series for a logistic map where the growth rate is in the chaotic region (\\(a=3.8284\\)). The logistic map is a nonlinear difference equation. It is a discrete-time popualtion model that takes the form,\n\\[ x_{t+1} = a x_t (1-x_t). \\] We start the two populations from barely different initial conditions \\(x_0=0.2\\) vs. \\(x_0=0.20001\\).\n\n## logistic map\nf &lt;- expression(a*x*(1-x))\n## every integer period cycle\na &lt;- 3.8284\nxx &lt;- (0.2)\nx &lt;- xx\nfor(t in 1:200){\n  x &lt;- eval(f)\n  xx &lt;- c(xx,x)\n}\n\n## just barely different initial conditions\nxx1 &lt;- (0.20001)\nx &lt;- xx1\nfor(t in 1:200){\n  x &lt;- eval(f)\n  xx1 &lt;- c(xx1,x)\n}\n\nplot(0:200,xx,type=\"l\", xlab=\"Time\", ylab=\"X\", lwd=1, ylim=c(0,1.1), col=\"blue\")\nlines(0:200,xx1, lty=1, lwd=1, col=\"red\")\n\n\n\n\n\n\n\n\nPretty wild. Two populations that differ initially by just \\(1 \\times 10^{-5}\\) take totally different trajectories when the same population model is applied to them. This is the essence of sensitivity to initial conditions.\n\n\n6.2.2 Equilibria and Attractors\nSupply is upward-sloping. When the price increases, producers have more incentive to increase supply. Similarly, as the price is high, there isn’t much demand from consumers, so it is downward-sloping.\nThe classic equilibrium is a single point as seen in the ubiquitous model for a competitive equilibrium price in economics.\nIs it just me or are the axes on this classic models reversed from what we would expect in science? The quantity (either supplied or demanded) is responding to price, which suggests that Quantity is the dependent variable and should be on the y-axis.\nThe ESSs for the frequency-dependent models discussed in Chapter 4 have this form too.\nAn attractor is a generalization of the idea of an equilibrium In essence, an attractor is just a set of points to which a dynamical system tends to evolve from a wide range of initial conditions A basin of attraction is a region in the phase space where once the system is in that region, it will end up on the attractor\nHysteresis.\nHysteresis is simply the dependence of the state of a system on its history It’s one important form a path-dependence Appreciation of the dollar and factory closures Scheffer and Carpenter (2003) use a slightly different meaning: Multiple states persisting under the same environmental conditions Basically, synonymous with alternative stable states\ndeMenocal et al. (2000) provide an example of a sudden shift in a stable state.\nA system has alternative attractors if there can be more than one stable state for the same values of external conditions (Scheffer and Carpenter 2003)\nForcing. Slow dynamics.\n\n\n6.2.3 Catastrophes\nAn example from Noy-Meir (1975)\n\n## Noy-Meir (1975) model\nlogistic.recruit &lt;- expression(r*N*(1 - (N/K)^theta))\nno &lt;- 1\nr &lt;- 0.45\nK &lt;- 100\ntheta &lt;- 1\nN &lt;- seq(0,K,length=500)\n\nplot(N,eval(logistic.recruit), type=\"l\", yaxs=\"i\", \n     lwd=3, axes=FALSE, \n     xlab=\"Relative Producer Density\", \n     ylab=\"Relative Productivity\", ylim=c(0,15))\nbox()\n\n\n\n\n\n\n\n\nThis is known as a “production function” or “recruitment function.” It tells you how big a change in a population will be next year based on its size this year (e.g., how many “recruits”). They are typically humped, where the number of recruits is very small at either very low population densities or near carrying capacity. Sometimes, they’re not humped when density-dependence is weak or absent, but usually they are humped, often asymmetrically.\n\n# Holling Type II\nh2 &lt;- expression(a*N/(b + a*x))\nx &lt;- N+1\na &lt;- 0.7\nb &lt;- 3\n\nplot(x, 6*eval(h2), type=\"l\", yaxs=\"i\", \n     lwd=3, axes=FALSE, \n     xlab=\"Relative Producer Density\", \n     ylab=\"Consumer Attack Rate\", ylim=c(0,15))\nbox()\n\n\n\n\n\n\n\n\nThis is the Holling Type II Functional Response (yes, that Holling). It is a saturating function. For a fixed number of predators, the number of prey they take (their “attack rate”) will increase with the prey density, but it will saturate. You can only eat so much.\nNow, suppose there is population growth of the predators/consumers. What’s going to happen to this curve? Well, it will shift upward because there are more consumers so the rate at which they remove prey will be higher.\n\nplot(x, 6*eval(h2), type=\"l\", yaxs=\"i\", \n     lwd=3, axes=FALSE, \n     xlab=\"Relative Producer Density\", \n     ylab=\"Consumer Attack Rate\", ylim=c(0,15))\nlines(x,12*eval(h2), lwd=3)\nbox()\n\n\n\n\n\n\n\n\nMore consumers harvesting at the same rate means that the overall attack rate increases.\nWe can now put this all together.\n\nplot(N,eval(logistic.recruit), type=\"l\", yaxs=\"i\", lwd=3, axes=FALSE, xlab=\"Relative Producer Density\", ylab=\"Relative Productivity\", ylim=c(0,15))\nbox()\nlines(x, 6*eval(h2), lwd=2)\n#lines(x, 8*eval(h2))\n#lines(x, 10*eval(h2))\nlines(x, 12*eval(h2), lwd=2)\n#lines(x, 13*eval(h2))\n#lines(x, 14*eval(h2))\npoints(c(8.702413, 36.521362, 57.497146, 85.464859), c(3.485678, 10.441517, 11.003335,  5.652690), col=c(\"red\",\"red\",\"green\",\"green\"), cex=2, pch=16)\narrows(36.521362-7.5, 10.441517+2, 36.521362-1, 10.441517+2, code=1, lwd=3, length=0.1, col=grey(0.75))\narrows(36.521362+1, 10.441517+2, 36.521362+7.5, 10.441517+2, code=2, lwd=3, length=0.1, col=grey(0.75))\n#\narrows(57.497146-7.5, 10.441517+2, 57.497146-1, 10.441517+2, code=2, lwd=3, length=0.1, col=grey(0.75))\narrows(57.497146+1, 10.441517+2, 57.497146+7.5, 10.441517+2, code=1, lwd=3, length=0.1, col=grey(0.75))\ntext(c(59.13355, 86.65497), c(11.458140,  6.107494), c(\"F2\", \"F1\"))\n\n\n\n\n\n\n\n\nThe growth of the consumers is typically very slow relative to the recruitment of the producer population. It’s not hard to imagine a series of functional-response curves sweeping upward gradually as the population of consumers increases.\nIn this figure, the humped recruitment curve is intersected by a nonlinear extraction curve. Harvesting effort increases as the resource population increases, but it does so in a decelerating manner. In this particular curve, extraction also accelerates for the lowest levels of the resource population. The shapes of these curves (which are pretty standard models for resource-extraction known as “functional response” curves) mean that they hit the recruitment function in three places each. Equilibria occur at three points: near zero, middle producer density, and high producer density. The green points (high consumer density) are stable equilibria – the movement of perturbations on this side of the curve is indicated by the grey arrows at the top. The red points are unstable (note the grey arrows). Depending on the size and direction of a perturbation from this point in the system, the productivity can easily be knocked down to the catastrophic equilibrium of extremely low productivity. Note that the fold catastrophe also has three equilibria for any set of conditions (except the special cases of the folds).\nNote that each harvest curve produces 3 equilibria: the green ones are stable, the red ones are unstable, and the unmarked ones near zero turn out also to be stable (just not marked because the dots would get crowded down there).\nThis is what we could call “forcing.” It’s a slow change—in a specific direction—that gradually changes the state of the system overall. Slow forcing ultimately produces catastrophes.\nIf we perform the forcing of a functional-response curve on that hump-shaped recruitment curve, collect the three stable points for each changing functional-response curve, and plot those, we get something that looks like this. The stable points are the solid lines of the attractor. The unstable points are the dotted line. This model was developed by Noy-Meir (1975).\nIf we trace a series of curves moving from low to high exploitation like the two intersecting functional responses in this figure, what we end up with is an attractor that looks very much like the fold-catastrophe. This doesn’t actually seem that exotic after all.\nIn high-sensitivity environments like a semi-desert or the Arctic, the extent of human exploitation is very likely near the maximum sustainable level. If environmental productivity were to decline as a function of climate change, while the extent of exploitation remains constant, the system can be pushed into catastrophic regime-shift.\nThe the system state approaches the fold, the derivative of the attractor goes infinite. This means that perturbations on or very near the fold can lead the system to change wildly, potentially entering a new (and worse) basin of attraction – in this case, the lower branch of the attractor.\nIt resurfaced in the work of Carpenter, Scheffer, and their collaborators. Scheffer et al. (2009) use the fold-catastrophe model extensively in their work on predicting catastrophes.\n\n## Fold Catastrophe\nx &lt;- seq(-12,12,length=1000)\ny &lt;- seq(12,10/sqrt(3), length=1000)\n\nplot(-x^3+100*x,x,type=\"l\", axes=FALSE, lwd=2, lty=2, xlab=\"Conditions\", ylab=\"System State\")\nbox()\nlines(-y^3+100*y,y, lwd=2)\nlines(y^3-100*y,-y, lwd=2)\n\n# unstable\narrows(-200,-5,-200,-2.75, code=1, lwd=3, length=0.1, col=grey(0.75))\narrows(-200,-1.5,-200, 0.75, code=2, lwd=3, length=0.1, col=grey(0.75))\n#lower stable\narrows(-200,-6,-200, -8.25, code=2, lwd=3, length=0.1, col=grey(0.75))\narrows(-200,-11.5,-200, -9.25, code=2, lwd=3, length=0.1, col=grey(0.75))\n#upper stable\narrows(-200,13.5,-200, 11.25, code=2, lwd=3, length=0.1, col=grey(0.75))\narrows(-200,8.25,-200, 10.5, code=2, lwd=3, length=0.1, col=grey(0.75))\n\npoints(357,7, pch=21, cex=2, lwd=3, bg=grey(0.75))\ntext(376.6749, 7.87279, \"F1\")\ntext(391.1386, -11, \"F2\")     \npoints(357,-11.452987, pch=21, cex=2, lwd=3, bg=\"white\")\narrows(357,6.5,357,4.9, lwd=3, length=0.1)\narrows(357,4,357,-10.8, code=2, lwd=3, length=0.1, col=grey(0.75))\npoints(358.1289,4.37, pch=21, cex=2, lwd=3, bg=grey(0.75))\n\n\n\n\n\n\n\n\nSolid lines indicate stable attractor. Perturbations tend to return. Dashed lines indicate unstable attractor: perturbations tend to move away from attractor. There are thus two basins of attraction.\nWhen you approach the fold (point F1), a small perturbation can push you from the stable to unstable branch quite easily. Then, if there is another perturbation below the attractor, the system state can move rapidly down to the bad stable branch (F2).\nA catastrophe is a sudden shift given a small perturbation.\nThe solid parts of the curve are stable—when the system state is perturbed when in the vicinity of this part of the attractor, it tends to return, as indicated by the grey arrows pointing back to the attractor. The dashed part of the attractor is unstable—perturbations in this neighborhood tend to move away from the attractor. This graphical representation of the system makes it pretty easy to see how a small perturbation could dramatically change the system if the current combination of conditions and system state place the system on the attractor near the neighborhood where the attractor changes from stable to unstable. The figure illustrates one such scenario. The conditions/system state start at point F1. A small forcing perturbs the system off this point across the bifurcation. Further forcing now moves the system way off the current state to some new, far away, stable state. We go from a very high value of the system state to a very low value with only a very small change in conditions. Indeed, in this figure, the conditions remain constant from point F1 to the new value indicated by the white point—just a brief perturbation was sufficient to cause the drastic change.\nAt the fold, the derivative disappears (the derivative of a vertical line is undefined). This means that a perturbation that happens at a fold can lead to the system wandering well away from its local attractor.\nNote that for most environmental conditions, there are three equilibria. Two of these are stable and one is unstable. One of the stable equilibria is in the good range of the system state. Specific examples might include high biomass or population size of a resource species, high forest cover, or clear water. One of the stable equilibria is in the bad range of the conditions such as low population density or biomass, deforested, or turbid water. The third equilibrium is intermediate, but it is unstable. When the system moves to that part of the attractor, perturbations will tend to move the system away to one of the stable parts of the attractor.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Complexity</span>"
    ]
  },
  {
    "objectID": "complex.html#hysteresis",
    "href": "complex.html#hysteresis",
    "title": "6  Complexity",
    "section": "6.3 Hysteresis",
    "text": "6.3 Hysteresis\nAnother notable feature of the fold-catastrophe model is known as hysteresis or path-dependency. Suppose that the system has been forced through point F2 to the fold and then a perturbation has driven it to the bad stable state of F1. Suppose also that, having witnessed the dramatic collapse of the system, people decided to do something to try to bring back the biological functionality. The problem is that shape of the attractor means that it will take an enormous investment to get the system back to its healthy state. In effect, the system needs to be forced back up the attractor toward the left-facing fold. Once there, it is possible to shock the system back up to the healthy (stable) leg of attractor, but in order to get it to this point, the system needs to nearly be brought back to its initial state.\n\n\n\nForced to the fold; drive to the bad state.\n\n\nA catastrophe only happens when the attractor folds back on itself. A system can change by a large amount and not experience a catastrophe. This can happen because either there is a region of the attractor that has very high sensitivity or because the perturbation is just very large.\n\nlibrary(shape)\nlogist &lt;- function(x,a,b) 1/(1+exp(-(a+b*x)))\n\nx &lt;- seq(0,20,,200)\n## need to make a&lt;0 so that whole curve appears\n\n# High Sensitivity\nplot(x,1-logist(x=x,a=-10,b=1), type=\"l\", lwd=3, \n     axes=FALSE,\n     frame=TRUE,\n     xaxs=\"i\",\n     xlab=\"Conditions\", ylab=\"State\")\nArrows(8,1-logist(8,a=-10,b=1),11.8,1-logist(8,a=-10,b=1), arr.type = \"triangle\", arr.length = 0.2, lwd=2, col=\"red\")\nArrows(12,1-logist(8,a=-10,b=1),12,1-logist(11.9,a=-10,b=1), arr.type = \"triangle\", arr.length = 0.2, lwd=2, col=\"red\")\n\n\n\n\n\n\n\n## Large Perturbation\nplot(x,exp(-0.07*x), type=\"l\", lwd=3, \n     axes=FALSE,\n     frame=TRUE,\n     xaxs=\"i\",\n     xlab=\"Conditions\", ylab=\"State\")\nArrows(5,exp(-0.07*5),11.8,exp(-0.07*5), arr.type = \"triangle\", arr.length = 0.2, lwd=2, col=\"red\")\nArrows(12,exp(-0.07*5),12,exp(-0.07*11.7), arr.type = \"triangle\", arr.length = 0.2, lwd=2, col=\"red\")\n\n\n\n\n\n\n\n\n\n6.3.1 Critical Slowing Down\nAn important part of this work is that there are signals of catastrophe. Scheffer et al. (2009) argue that there are certain generic features of many systems as they move toward catastrophic change. The paper discusses epileptic seizures, asthma attacks, market collapses, abrupt shifts in oceanic circulation and climate, and ecological catastrophes such as sudden shifts in rangelands, or crashes of fish or wildlife populations. At first, it sounds like the vaguely mystical ideas about transcendent complexity, financial physics, etc. But really, there are a number of very sensible observations about dynamical systems and a convincing argument that these features will be commonly seen in real complex systems.\nThe basic idea is that there are a number of harbingers of catastrophic change in time series of certain complex systems. As one gets close to a catastrophic bifurcation, the very straightforward analysis that we used for evaluating the stability of the logistic model shows that the rate of return to the attractor decreases. As we move from the upper-left branch of the attractor toward point F2 in the figure, note that the slope of the tangent line at each point gets larger and larger. The slope on these tangent lines tells us about the behavior of the system following a small perturbation. As before, call the slope of these tangent lines \\(\\lambda\\). Perturbations away from the attractor will grow or decay according to the equation \\(n(t) = n(0) e^{\\lambda t}\\), where \\(n(t)\\) is the size of the perturbation away from the attractor at time \\(t\\). If external forcing moves the state along the attractor to point \\(B\\), the slope is infinite (i.e., vertical) and the perturbation will grow rapidly away from the attractor in the direction of the perturbation.\nAs Scheffer et al. (2009) note, one rarely has the luxury of measuring rates of return to equilibria in real systems but, fortunately, there are relatively easily measured consequences of this slow-down of rates of return to the attractor. They show in a lucid manner how the correlations between consecutive observations in a time series will increase as one approaches one of these catastrophic bifurcation points. This increased correlation has the effect of increasing the variance.\nTwo ways to diagnose an impending catastrophe in a system that is characterized by the fold bifurcation model are: (1) an increase in variance of the observations in the series and (2) an increase in the lag-1 autocorrelation. A third feature of impending catastrophes does not have quite as intuitive an explanation, but is also relatively straightforward. Dynamical systems approaching a catastrophic bifurcation will exhibit increased skewness to the fluctuations as well as flickering. The skewness means that the distribution of period-to-period fluctuations will become increasingly asymmetric. This has to do with the shape of the underlying attractor and how the values of the system are forced across it. Flickering means that the values will bounce back and forth between two different regimes (say, high and low) rapidly for a period before the catastrophe. This happens when the system is being forced with sufficient strength that it is bounced between two basins of attraction before getting sucked into a new one for good (or at least a long time).\nIn summary, there are four generic indicators of impending catastrophe in the fold catastrophe model:\n\nIncreased variance in the series\nIncreased autocorrelation\nIncreased skewness in the distribution of fluctuations\nFlickering between two states\n\nThese early-warning signs of impending catastrophe are collectively known as the critical-slowing-down hypothesis Scheffer et al. (2012).\nIn a system characterized by high resilience, a stochastic forcing will be followed by the rapid return to the attractor. As a result, there will be low correlation between subsequent states.\nA nice way to visualize this is to imagine a ball rolling on a landscape. We can think of the equilibrium (or “attractor”) as being a valley on the landscape, which we will call the basin of attraction. Pushing the ball toward the basin of attraction will lead to it settling in to the attractor.\nOnce the ball has settled into this basin of attraction, it is difficult to push it out because the basin is deep and the sides are steep. The red arrows in the following sketch indicate the high-frequency oscillations of the ball in this deep attractor arising from the steep sides. The perturbed ball will rapidly settle back into its attractor following the perturbation.\nWhen the system is low-resilience, it has a longer memory for perturbations and correlations increase. We can visualize this as a flattened-out basin of attraction. The longer red arrows in the sketch below indicate how the same perturbation will cause the ball to roll further – because the sides of the basin are less steep – as it settles back down. This leads to the greater variance and increased temporal autocorrelation predicted by the critical slowing down model of Scheffer et al. (2009).\nThere are all sorts of worrisome implications in these types of models for climate change, production systems, disease ecology, and the dynamics of endangered species. What I hope is that by really getting a handle on these generic systems, we will develop tools that will help us identify catastrophes soon enough that we might actually be able to do something about some of them. The real challenge, of course, is developing tools that give us the political will to tackle serious problems subject to structural uncertainty. I won’t hold my breath…\nAll the examples so far of the fold-catastrophe model use generic labels for the axes: “Conditions” and “System State”\nWhat are the “shocks” that knock the system off its attractor? These are brief increases/decreases in either of the conditions or the system state that are exogenous to the system we’re studying. For example, the human population might decrease because there is an epidemic or a war. The temperature might temporarily be decreased because of a volcanic eruption. Forest cover might drop suddenly because there was an earthquake and people cut down more trees to cook and keep warm because they lost gas to their homes. These changes have nothing to do with the specific set of conditions/system state that we’re measuring so they are “exogenous” — they push the value of the system state off the attractor and the system either reverts back to where it was (if the perturbation was in a stable region) or it moves to a new part of the attractor if it was in an unstable region.\nWhy do we care? 1. possibility for abrupt changes 2. highlights importance of slow dynamics/forcing and relationship to fast dynamics 3. hysteresis should give us all pause\nPrecursors of Catastrophes (Scheffer et al. 2009)\nA general phenomenon of a dynamical system approaching catastrophic change is known as Critical Slowing Down Some specific signs from time series: Increased Variance Increased Autocorrelation In addition, warning signs not necessarily related to slowing down Flickering Skewness\nLow-resilience leads to high variance in the perturbed state and high temporal autocorrelation of state values.\nTry to recreate the analysis of Scheffer and colleagues. The problem is they don’t fully specify the model and certainly don’t share code. This is close (though the non-resilient case is more variable than theirs).\nThe model they use is for a density-dependent population that experiences harvesting. Density dependence is logistic, while the harvesting rate is governed by a Holling Type III functional response:\n\\[\n\\frac{dX}{dt} = X(1 - \\frac{X}{K}) - \\frac{c X^2}{X^2 + 1}\n\\] Where \\(K\\) is the carrying capacity and \\(c\\) is the maximum (asymptotic) harvest rate. This is essentially the model employed by both Noy-Meir (1975) and May (1977).\n\n## logistic growth with harvesting\ndX &lt;- function(X,K,c) X*(1 - X/K) - c*(X^2/(X^2+1))\n\nX0 &lt;- 17\n\n## high resilience\nnmax &lt;- 1000\nX &lt;- rep(0,nmax)\n## mean-zero normal noise\nepsilon &lt;- rnorm(nmax) # normal innovations\nX[1] &lt;- X0\nfor(i in 2:nmax){\n  X[i] &lt;- X[i-1] + dX(X[i-1],15,1) + epsilon[i]\n}\n\n# time series\nplot(1:1000,X, type=\"l\", xlab=\"Time\", ylab=expression(X[t]), ylim=c(0,18))\n\n\n\n\n\n\n\n# correlation\nplot(X[-nmax],X[-1], pch=16, \n     xlab=expression(X[t]),  ylab=expression(X[t+1]), xlim=c(8,18), ylim=c(8,18))\nabline(a=0,b=1)\n\n\n\n\n\n\n\ncor(X[-nmax],X[-1])\n\n[1] 0.1399281\n\nac &lt;- acf(X)\n\n\n\n\n\n\n\nac[1]\n\n\nAutocorrelations of series 'X', by lag\n\n    1 \n0.139 \n\n## low resilience\nX1 &lt;- rep(0,nmax)\nepsilon &lt;- rnorm(nmax) \nX1[1] &lt;- X0\nfor(i in 2:nmax){\n  X1[i] &lt;- pmax(X1[i-1] + dX(X1[i-1],15,2.6) + epsilon[i],0)\n}\n\n# time series\nplot(1:1000,X1, type=\"l\", xlab=\"Time\", ylab=expression(X[t]), ylim=c(0,18))\n\n\n\n\n\n\n\n# correlation\nplot(X1[-nmax],X1[-1], pch=16, \n     xlab=expression(X[t]),  ylab=expression(X[t+1]),xlim=c(6,18), ylim=c(6,18))\nabline(a=0,b=1)\n\n\n\n\n\n\n\ncor(X1[-nmax],X1[-1])\n\n[1] 0.4589379\n\nac1 &lt;- acf(X1)\n\n\n\n\n\n\n\nac1[1]\n\n\nAutocorrelations of series 'X1', by lag\n\n    1 \n0.454 \n\n\nBoth the variance and the covariance is greater less-resilient scenario with the high extraction rate. The high-frequency fluctuations are larger, making the variance large. This also makes it take longer for the deviations to to dissipate, so it’s more likely that two consecutive time steps will be above (or below) the average.\nThe overall lag-1 autocorrelation is significantly higher in this lower-resilience case. Moreover, the lag-2 autocovariance is also significantly greater than zero (indicated by being above the blue dashed line), indicating a much slower decay in the autocovariance.\n\nrequire(zoo)\nset.seed(42)\n## logistic growth with harvesting\ndX &lt;- function(X,K,c) X*(1 - X/K) - c*(X^2/(X^2+1))\n\nX0 &lt;- 17\nnmax &lt;- 1000\nccc &lt;- c(rep(1,100), seq(1,4,,900))\nX2 &lt;- rep(0,nmax)         \nepsilon &lt;- rnorm(nmax)\nX2[1] &lt;- X0\n\nfor(i in 2:nmax){\n  X2[i] &lt;- pmax(X2[i-1] + dX(X2[i-1],15,ccc[i]) + epsilon[i],0)\n  if(X2[i]==0) break # no random resurrection\n}\n\n## index of the extinction\nextinct &lt;- min(which(X2==0))\n\nplot(1:extinct,X2[1:extinct], type=\"l\", xlab=\"Time\", ylab=expression(X[t]), ylim=c(0,18))\n\n\n\n\n\n\n\ncor(X2[-nmax],X2[-1])\n\n[1] 0.9413534\n\nac2 &lt;- acf(X2[1:extinct])\n\n\n\n\n\n\n\nsdd &lt;- rollapplyr(X2[1:extinct], 100, sd)\nplot(sdd, type=\"l\", xlab=\"Time\", ylab=\"Standard Deviation\")\n\n\n\n\n\n\n\n\nNow look at how the correlations change over time.\n\nrequire(zoo)\n\n## a little function to calculate a rolling autocorrelation\ngetacf &lt;- function(x) {\n  tmp &lt;- acf(x,lag.max=1,plot=FALSE)\n  return(tmp$acf[2])\n}\n\naaa &lt;- rollapplyr(X2[1:extinct], 100, getacf)\nplot(aaa, type=\"l\", xlab=\"Time\", ylab=\"Autocorrelation\")\n\n\n\n\n\n\n\nx2early &lt;- X2[1:200]\nx2late &lt;- X2[(extinct-200):extinct]\n\nplot(x2early[-200],x2early[-1], pch=16, \n     xlab=expression(X[t]),  ylab=expression(X[t+1]),xlim=c(0,18), ylim=c(0,18))\nabline(a=0,b=1)\n\n\n\n\n\n\n\nplot(x2late[-200],x2late[-1], pch=16, \n     xlab=expression(X[t]),  ylab=expression(X[t+1]),xlim=c(0,18), ylim=c(0,18))\nabline(a=0,b=1)\n\n\n\n\n\n\n\nc(cor(x2early[-200],x2early[-1]),cor(x2late[-200],x2late[-1]))\n\n[1] 0.1740171 0.8205540\n\n\nWhat happens when a the system is forced onto the unstable part of the attractor? Until it’s pushed over the boundary, it will tend to return the stable arm. If this happens repeatedly, you will see flickering\nIf one side of the basin is stretched out, making it shallower, the distribution of oscillations will be skewed.\nIncreased skewness of perturbations (Guttal and Jayaprakash 2008).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Complexity</span>"
    ]
  },
  {
    "objectID": "complex.html#stability-analysis-of-the-lotka-volterra-model",
    "href": "complex.html#stability-analysis-of-the-lotka-volterra-model",
    "title": "6  Complexity",
    "section": "6.4 Stability Analysis of the Lotka-Volterra Model",
    "text": "6.4 Stability Analysis of the Lotka-Volterra Model\nAs we saw in Section 6.0.1, the classic predator-prey model of Lotka and Volterra shows cyclical dynamics. What happens if we perturb the model off of its simplex? Will the system return to the simplex and continue cycling in the same manner as before the perturbation? Will the system diverge, perhaps leading to the extinction of one or both species? We can use stability analysis to investigate these questions. In a nutshell, we use the structural information contained in the equations to investigate whether or not a small perturbation off of the simplex (i.e., the phase portrait) will increase or decay back to the simplex.\nFirst solve the predation equations to find their equilibrium values. Solving the first, we see that there is an equlibrium (i.e., \\(\\dot{x}_1=0\\)) at \\(x_1=0\\) or, less trivially, \\(x_1=b_1/a_{12}\\). Solving the second, we similarly find \\(x_2=0\\) and \\(x_2=b_2/a_{21}\\). There are thus two equilibria for this model: \\((0,0)\\) and \\((b_1/a_{12}, b_2/a_{21})\\).\nIt doesn’t take too much thought to see that the first of these equilibria is unstable. Since the first term in the model contains an exponential growth term (corresponding to the first assumption), any perturbation away from the zero equilibrium will grow.\nThe Lotka-Volterra equations are nonlinear – the rate of prey removal and the rate of growth of predators depends on the interaction of the two state variables, \\(x_1\\) and \\(x_2\\). To determine the stability of the non-trivial equilibrium, we need to linearize the system around the equilibrium point. That is, we perform a Taylor series expansion of the system around the equilibrium, discarding all higher-order terms (i.e., square and above). For the multivariate system, we use the Jacobian matrix of the system\n\\[\n\\mathbf{J} =\n\\begin{pmatrix}\n      \\partial F/\\partial x_1 & \\partial F/\\partial x_2 \\\\\n      \\partial G/\\partial x_1 & \\partial G/\\partial x_2\n\\end{pmatrix},\n\\]\nwhere \\(F\\) is the equation for herbivores and \\(G\\) is the equation for predators, which is equal to:\n\\[\n\\mathbf{J} =\n\\begin{pmatrix}\n      b_1 - a_{12} x_2 & - a_{12} x_1 \\\\\n      a_{21} x_2 & -b_2 + a_{12} x_1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n      0 & \\frac{-b_2 a_{12}}{a_{21}}\\\\\n      \\frac{b_1 a_{21}}{a_{12}}  & 0\n\\end{pmatrix}\n\\]\nThe latter matrix comes from substituting the equilibrium values for \\(x_1\\) and \\(x_2\\) and simplifying.\nThe stability criterion where a perturbation decays back to the equilibrium translates into all the eigenvalues of \\(\\mathbf{J}\\) having negative real parts. We can calucate the eigenvalues of \\(\\mathbf{J}\\) by solving the characteristic equation \\(\\det(\\mathbf{J} - \\lambda \\mathbf{I})=0\\):\n\\[\n\\det\n\\begin{bmatrix}\n      \\lambda & \\frac{-b_2 a_{12}}{a_{21}}  \\\\\n      \\frac{b_1 a_{21}}{a_{12}}  & -\\lambda\n\\end{bmatrix}\n= \\lambda^2 + b_1 b_2 = 0.\n\\]\nThe solution to the characteristic equation is thus \\(\\lambda = \\pm i\\sqrt{b_1b_2}\\). This solution contains no real parts – i.e., the real parts are zero – only imaginary. This means that the equilibrium is neither stable nor unstable but that the model is purely oscillatory.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Complexity</span>"
    ]
  },
  {
    "objectID": "complex.html#stability-and-complexity",
    "href": "complex.html#stability-and-complexity",
    "title": "6  Complexity",
    "section": "6.5 Stability and Complexity",
    "text": "6.5 Stability and Complexity\nIn model ecosystems, the more species the model contains, the less asymptotically stable it is (this results from the requirement that the real parts of all eigenvalues of the Jacobian matrix be negative for stability)\nOne of the central debates in ecology surrounds the problem of stability and complexity. Biological intuition suggests that more complex ecosystems are more stable. More species should lead to greater functional redundancy, e.g., leading to greater resilience. Simple experiments support this intuition refs. Elton: “simple communities were more easily upset than that of richer ones; that is, more subject to destructive oscillations in populations, and more vulnerable to invasions”\nIn his foundational (1973) monograph, Robert May noted that the mathematical theory of community ecology did something very odd. May (1973) shows that the standard, off-the-shelf mathematics of stability analysis say that increased food web complexity actually leads to lower stability! This prediction was odd because it violated the intuitions of most field ecologists, who felt that more complex communities were more stable. Surely, with more species in a given community, there should be greater functional redundancy which, in turn, should make complex communities robust to perturbations—really the definition of stability.\nHow did this work? First, linearize the model around the equilibrium vector:\n\\[ \\dot{\\mathbf{u}} = \\mathbf{A} \\mathbf{u}, \\]\nwhere \\(\\mathbf{u}\\) is a vector of length \\(k\\) of deviations of the populations from their equilibria, i.e., \\(u_i = x_i - x^*_i\\), where \\(x^*_i\\) is the equilibrium value for species \\(i\\).\nFor the equilibrium to be stable, all the eigenvalues of matrix \\(\\mathbf{A}\\) msut have negative real parts. If all of the eigenvalues of \\(\\mathbf{A}\\) have negative real parts, it means that all the perturbations away from the equilibrium, \\(\\mathbf{u}\\), will decay exponentially back toward the equilibrium. Were any of the eigenvalues non-negative, perturbations would grow and the equilibrium would be, by definition, unstable.\nMay (1973) showed that as \\(k\\) gets larger (i.e., the number of species in a community increases), the likelihood that all the eigenvalues of \\(\\mathbf{A}\\) will be negative decreases.\nHow do we reconcile this mathematical fact with the very strong intuition that more complex ecological systems are more stable? Some clues:\nMay (1973) used random values for the interaction strengths for the community matrix. Yodzis (1981) found that food webs constructed from real interaction data were more stable than randomly-assembled food webs. Moreover, he found that interaction strengths were often weaker than the random-interaction models, such as those used by May (1973). Pimm and Lawton (1978) found that empirical food webs with omnivores were more stable than those without. Omnivores, by spreading their consumption out over a large range of prey types, generally have weak ecological interactions with other species. McCann, Hastings, and Huxel (1998) showed formally that the key to stability was many weak connections in food webs.\nLotka-Volterra cycles because of the over-shooting of a tightly-coupled system. Omnivores are generalists, which means they have low interaction strengths with their different prey. We can summarize the feature of food webs that promote stability. These include:\n\nMany connections\nLow average interaction strength\nPrey switching/omnivory\nNegative covariance between abundances\n\nNegative covariance stabilizes abundance. The variance of productivity of two species (a and b) follows from the definition of variance\n\\[\ns_{(a+b)}^2=s_a^2+s_b^2+2 \\operatorname{cov}(a, b)\n\\]\nIt is the sum of the individual variances plus twice the covariance between them. If \\(a\\) and \\(b\\) are positively correlated the variance of their sum will exceed the sum of their individual variances. Not exactly the behavior you want in a portfolio!\nHunter-gatherers are generalists, omnivores who engage in extensive prey-switching. Dunne et al. (2016) show that human foragers are what they call “super-generalist and highly-omnivorous consumers” who actually have substantial stabilizing effects on marine and coastal food webs in the Aleutian Islands. Crabtree, Bird, and Bird (2019) suggest that Martu hunter-gatherers were “knitters” of food webs in the Western Desert of Australia and that food webs lost substantial complexity when the Martu were forced off their land and foraging way of life.\nFood items are ranked in quality (lower is better). E/h is the net energy that an item yields. E/t is energy gained per unit of search time. The optimal diet includes all items in the diet more highly ranked than where these lines intersect (MacArthur and Pianka 1966).\nFallback Foods: Increased diet breadth. In a bad year, you search longer so the net energy per time spent searching is lower. This moves the equilibrium out and you add more items to the diet.\n\n## Fallback Foods\nx &lt;- seq(0,20,length=500)\nf &lt;- function(x,b) {\n  1 - exp(-b*(x-1))\n}\n\nf1 &lt;- function(x,a) a/x\n\nplot(x,f(x,b=0.1), type=\"l\", lwd=3, xaxs=\"i\", yaxs=\"i\",\n     axes=FALSE,\n     xlab=\"Item Rank\",\n     ylab=\"Energy Gain\",\n     ylim=c(0,1))\naxis(1)\nbox()\nlines(x,f(x,b=0.05), lwd=3, col=\"red\")\nlines(x,f1(x,a=2), lwd=3, col=\"grey\")\n# found approximate points using locator()\ntext(2.9,0.9648077,expression(E/h))\ntext(18.75,0.8848253,expression(E^g/T))\ntext(18.75,0.6362313,expression(E^b/T))\nsegments(5.5,0,7.4,0, lwd=10, col=\"green\", lend=2) \ntext(6.45,0.04825, \"Fallback Foods\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Complexity</span>"
    ]
  },
  {
    "objectID": "complex.html#stability-vulnerability-resilience",
    "href": "complex.html#stability-vulnerability-resilience",
    "title": "6  Complexity",
    "section": "6.6 Stability, Vulnerability, Resilience",
    "text": "6.6 Stability, Vulnerability, Resilience\nVulnerability the susceptibility of a system to disturbances from perturbations, sensitivity to perturbations, and the capacity to adapt Adaptation (small-a) reduction vulnerability Resiliency “the capacity of a system to absorb disturbance and reorganize while undergoing change so as to still retain essentially the same function, structure, identity, and feedbacks” (Walker et al. 2007) cf. ‘time to return to equilibrium following perturbation’\nAn obvious example of panarchy — specifically cross-scale interactions — is a federal system of government. There are interactions between cities/counties/municipalities at the lowest level, states at the intermediate level, and the federal government at the top level.\nThe economic/social resilience of Rust-Belt city is likely to be affected by federal assistance programs, which are typically brokered by the states. For example, a state that refuses Medicare expansion affects the resilience of a small county hospital in a poor area where many people are uninsured.\nThe Adaptive cycle is similar to the model for the collapse of complex societies proposed by Tainter (1988). Societies gain complexity as they solve problems. There comes a point where the diminishing marginal returns to added complexity get so great that added complexity comes at a cost (note that after the peak, it’s no longer simply diminishing marginal returns, but diminishing returns period). This is quite similar to the idea of crystallization in the adaptive cycle. We can model this using the function described in Leslie and Winterhalder (2002).\n\n# Leslie & Winterhalder (2002) right-ibis function\nm &lt;- 8\nn &lt;- 2\nr &lt;- 18\nx &lt;- 0:16\n\nribis &lt;- function(x,m,n,r){\n  if(x&lt;0 | x&gt;=r){\n    ibis &lt;- 0\n  }\n  if(x&gt;=0 & x&lt;m) {\n    ibis &lt;- exp(m^2/((m-n)^2) - (m*x/(m-n)^2)) * x^(m^2/((m-n)^2)) *\n      m^(-m^2/(m-n)^2)\n  }\n  if(x&gt;=m & x&lt;r){\n    ibis &lt;-  1-(x-m)^2/(m-r)^2\n  }\n  return(ibis)\n}\n\ny &lt;- seq(0,16,length=100)\naaa &lt;- rep(0,100)\nfor(i in 1:100) aaa[i] &lt;- ribis(x=y[i],m=m,n=n,r=r)\n\nmc &lt;- ribis(x=8,m=m,n=n,r=r)\ndb &lt;- ribis(x=15,m=m,n=n,r=r)\ncl &lt;- ribis(x=2.895,m=m,n=n,r=r)\n\nplot(y,aaa,type=\"l\", lwd=2, axes=FALSE, frame=TRUE,\n     xaxs=\"i\", yaxs=\"i\",\n     ylim=c(0,1.1),\n     xlab=\"Complexity\", ylab=\"Benefits to Complexity\")\nsegments(8,mc,0,mc,lty=3)\nsegments(8,0,8,mc,lty=3)\n\nsegments(15,db,0,db,lty=3, col=\"red\")\nsegments(15,0,15,db,lty=3, col=\"red\")\n#segments(2.895,cl,0,cl,lty=3, col=\"red\")\nsegments(2.895,0,2.895,cl,lty=3, col=\"red\")\n#mtext(expression(paste(B, \"*\")),2, at=mc, adj=1, las=2)\nmtext(expression(B[max]),2, at=mc, adj=1, las=2)\nmtext(expression(B[mid]),2, at=db, adj=1, las=2)\nmtext(expression(C[lo]),1, at=2.895, padj=1)\nmtext(expression(C[opt]),1, at=8, padj=1)\nmtext(expression(C[hi]),1, at=15, padj=1)\n\n\n\n\n\n\n\n\n\n\n\n\nCrabtree, Stefani A., Douglas W. Bird, and Rebecca Bliege Bird. 2019. “Subsistence Transitions and the Simplification of Ecological Networks in the Western Desert of Australia.” Human Ecology 47 (2): 165–77. https://doi.org/10.1007/s10745-019-0053-z.\n\n\ndeMenocal, Peter, Joseph Ortiz, Tom Guilderson, Jess Adkins, Michael Sarnthein, Linda Baker, and Martha Yarusinsky. 2000. “Abrupt Onset and Termination of the African Humid Period: Rapid Climate Responses to Gradual Insolation Forcing.” Quaternary Science Reviews 19 (1): 347–61. https://doi.org/10.1016/S0277-3791(99)00081-5.\n\n\nDunne, Jennifer A., Herbert Maschner, Matthew W. Betts, Nancy Huntly, Roly Russell, Richard J. Williams, and Spencer A. Wood. 2016. “The Roles and Impacts of Human Hunter-Gatherers in North Pacific Marine Food Webs.” Scientific Reports 6 (1): 21179. https://doi.org/10.1038/srep21179.\n\n\nGuttal, Vishwesha, and Ciriyam Jayaprakash. 2008. “Changing Skewness: An Early Warning Signal of Regime Shifts in Ecosystems.” Ecology Letters 11 (5): 450–60. https://doi.org/10.1111/j.1461-0248.2008.01160.x.\n\n\nHastings, Alan, and Thomas Powell. 1991. “Chaos in a Three-Species Food Chain.” Ecology 72 (3): 896–903. https://doi.org/10.2307/1940591.\n\n\nLeslie, P., and B. Winterhalder. 2002. “Demographic Consequences of Unpredictability in Fertility Outcomes.” American Journal of Human Biology 14 (2): 168–83. https://doi.org/10.1002/ajhb.10044.\n\n\nMacArthur, Robert H., and Eric R. Pianka. 1966. “On Optimal Use of a Patchy Environment.” The American Naturalist 100 (916): 603–9. http://www.jstor.org/stable/2459298.\n\n\nMay, R. M. 1973. Stability and Complexity in Model Ecosystems. Princeton: Princeton University Press.\n\n\n———. 1976. “Simple Mathematical-Models with Very Complicated Dynamics.” Nature 261 (5560): 459–67. https://doi.org/10.1038/261459a0.\n\n\n———. 1977. “Thresholds and Breakpoints in Ecosystems with a Multiplicity of Stable States.” Nature 269 (5628): 471–77. https://doi.org/10.1038/269471a0.\n\n\nMcCann, K., A. Hastings, and G. R. Huxel. 1998. “Weak Trophic Interactions and the Balance of Nature.” Nature 395: 794–98. https://doi.org/10.1038/27427.\n\n\nNoy-Meir, Imanuel. 1975. “Stability of Grazing Systems: An Application of Predator-Prey Graphs.” Journal of Ecology 63 (2): 459–81. https://doi.org/10.2307/2258730.\n\n\nPimm, S. L., and J. H. Lawton. 1978. “On Feeding on More Than One Trophic Level.” Nature 275: 542–44. https://doi.org/10.1038/275542a0.\n\n\nScheffer, M., J. Bascompte, W. A. Brock, V. Brovkin, S. R. Carpenter, V. Dakos, H. Held, E. H. van Nes, M. Rietkerk, and G. Sugihara. 2009. “Early-Warning Signals for Critical Transitions.” Nature 461 (7260): 53–59. https://doi.org/10.1038/nature08227.\n\n\nScheffer, M., and S. R. Carpenter. 2003. “Catastrophic Regime Shifts in Ecosystems: Linking Theory to Observation.” Trends in Ecology & Evolution 18 (12): 648–56. https://doi.org/10.1016/j.tree.2003.09.002.\n\n\nScheffer, M., S. R. Carpenter, Timothy M. Lenton, J. Bascompte, W. Brock, V. Dakos, J. van de Koppel, et al. 2012. “Anticipating Critical Transitions.” Science 338 (6105): 344–48. https://doi.org/10.1126/science.1225244.\n\n\nTainter, Joseph A. 1988. The Collapse of Complex Societies. Cambridge: Cambridge University Press. https://books.google.com/books?id=YdW5wSPJXIoC.\n\n\nYodzis, P. 1981. “The Stability of Real Ecosystems.” Nature 289 (5799): 674–76. https://doi.org/10.1038/289674a0.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Complexity</span>"
    ]
  },
  {
    "objectID": "commons.html",
    "href": "commons.html",
    "title": "7  Emergence and Governing the Commons",
    "section": "",
    "text": "7.1 Malthus vs. Boserup\nMalthus was central to the development of Darwin’s thinking. Darwin wrote in his (1876) autobiography: “In October 1838, that is, fifteen months after I had begun my systematic inquiry, I happened to read for amusement Malthus on Population, and being well prepared to appreciate the struggle for existence which everywhere goes on from long-continued observation of the habits of animals and plants, it at once struck me that under these circumstances favourable variations would tend to be preserved, and unfavourable ones to be destroyed. The results of this would be the formation of a new species. Here, then I had at last got a theory by which to work.”\nA central tenet of the Malthusian thesis is that agricultural production increases linearly, while human populations increase geometrically (i.e., exponentially in continuous time). At some point, the geometric increase wins and immiseration ensues.\nThere is a determinism and passivity in the Malthusian account. The Danish economist Esther Boserup provided a more dynamic and adptationist account of the relationship between population and agricultural productivity. Population pressure induces innovation, which increases productivity, which induces greater innovation in a positive feedback system. Innovation in intensification by smallholders can be fantastically productive as noted by human ecologists such as Robert Netting (e.g., Netting 1993).\nBoesrup suggests three main points:\nYou get more production, but you have work much harder to produce it. People only intensify when they must.\nR. D. Lee (1986) and Wood (1998) have both noted that population can behave in both Malthusian and Boserupian manners. Wood refers to the “MaB Ratchet” (MaB=Malthus and Boserup). Malthusian pressure incites Boserupian innovation, relaxing negative feedback and allowing further population growth. While a population is undergoing a Boserupian expansion, quality of life improves. Alas, given enough time, the population will always return to “the same level of marginal immiseration.” (Wood 1998: 114)\nWood (1998) summarized the important issues in population regulation for anthropological applications. He asks five questions:\nM. N. Cohen, Armelagos, and Larsen (1984) and M. N. Cohen (1989) have argued that health declined precipitously with the emergence of agriculture. They coin the term Neolithic Paradox which is characterized by several features:\nWood et al. (1992) and Wood (1998) suggest that the evidentiary basis for the Neolithic Paradox is lacking. It is rather immediately clear from the figures of long-term human population dynamics that point 4 is simply not true. The left tail of apparently stalled population growth extends well beyond the Neolithic. It is also interesting to compare this to the sometimes rapid growth of modern hunter-gatherers who nonetheless lack healthcare, etc., a point noted by Hill and Hurtado (1996) in their masterful book on hunter-gatherer demography.\nBoserup: “The power of ingenuity would always outmatch that of demand.” This is a very adaptationist sentiment!",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Emergence and Governing the Commons</span>"
    ]
  },
  {
    "objectID": "commons.html#malthus-vs.-boserup",
    "href": "commons.html#malthus-vs.-boserup",
    "title": "7  Emergence and Governing the Commons",
    "section": "",
    "text": "Environmental limits on type of agriculture are relatively “elastic”\nIncreased production/area usually leads to decreased yield/labor\nLabor minimization governs decision to intensify\n\n\n\n\n\nIs the growth of preindustrial populations “regulated” in any meaningful sense of the word?\nIs there an optimal population size, and do preindustrial populations tend to equilibrate at the optimum?\nWhat is the relationship between population growth and economic change?\nWhat are the implications of population growth and economic change for individual health and well being?\nWhat is the role of crisis mortality in preindustrial population dynamics?\n\n\n\ndeterioration in nutrition\ndeterioration in general health\nincrease in infectious disease\nexponential population growth",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Emergence and Governing the Commons</span>"
    ]
  },
  {
    "objectID": "commons.html#mechanistic-models-of-population-regulation",
    "href": "commons.html#mechanistic-models-of-population-regulation",
    "title": "7  Emergence and Governing the Commons",
    "section": "7.2 Mechanistic Models of Population Regulation",
    "text": "7.2 Mechanistic Models of Population Regulation\nIn a series of papers, Shripad Tuljapurkar and his students have developed a mechanistic model of resource-restricted human population dynamics that links agricultural inputs such as the amount of arable land and the productivity of the land, human nutritional requirements (and the resiliency of people when they find themselves living (chronically or acutely) below their requirements, age-specific mortality and fertility rates. The models are extremely technically demanding but the insights that they yield warrant our exploring them, at least in a broad overview.\nTheir models were developed to understand the peopling of Oceania, Hawai’i in particular. The model accounts for the amount of available food energy as a function of (1) available land, (2) rainfall, (3) the age-structure of the human workforce, (4) the amount of time spent in productive agricultural labor.\nThe model includes realistic demography. Mortality and fertility are age-specific and both depend upon the energy intake. If the available energy is less than required at baseline, then survival and fertility are lower than their baseline values. This is measured by the food ratio (\\(\\hat{E}\\)), which is simply “the number of calories available to consume in a given year relative to the number of calories needed to maximize survival and fertility.” (Lee & Tulja 2009:179). The shape of the decline in fertility and survival as the food ratio declines is estimated from demographic studies of populations at or near starvation.\nThis model has an equilibrium, like the logistic model. However, note the fundamental difference between the equilibrium of this model and that of the logistic. In the Tuljapurkar model, the carrying capacity is an emergent property of the model. It depends on the various inputs and it will be different depending upon choices that are made that correspond to real choices that human populations make. The equilibrium of the logistic model is imposed; it does not arise through the mechanisms of mortality and fertility.\nOne of the key findings of this model is that hunger emerges in the equilibrium. This is a fairly Malthusian result. There is less food than required for people to not go hungry, but there is still enough to sustain an equilibrium population.\nChanging input parameters of the model has different effects on the equilibrium. Increasing agricultural productivity or the amount of time spent working on agricultural production increases the food ratio, while keeping the population growth rate largely unchanged. Increasing baseline survival increases the food ratio but decreases the population growth rate. Decreasing fertility only decreases the growth rate – the food ratio remains unchanged.\nThis is somewhat surprising, because one might imagine that all three inputs would work through common chains of causality in producing the equilibrium population size and food ratio. The differences arise because the slopes of the functions relating food availability and survival/fertility/productivity differ. Population growth – and thus population size – is more sensitive to some inputs than others, making the equilibria different depending upon which input is affected.\nC. T. Lee and Tuljapurkar (2008) find that in expanding populations (e.g., colonists to islands), crop yield is the most important factor for determining both population growth and well-being. Increasing the mean (and decreasing the variance) of crop yield has the paradoxical effect of improving overall well-being but in driving the population to a state of limitation and scarcity more rapidly.\nWhile agricultural productivity affects the food ratio, the shape of the vital rates’ response to food availability dominates the dynamics of the food ratio.\nVariance in production can actually improve overall well-being but the cost of this improvement is episodic, widespread starvation.\nLee and Tuljapurkar conclude: “An important conclusion from our work is that human choices and the environment interact to shape the state of populations. The environment can have distinct effects depending on the specific variables upon which it acts. A population may respond to a harsh environment by increasing yield via improved agricultural methods or crops, or by increasing labor, or by controlling fertility. These choices are not equivalent, and their consequences depend on an intricate interplay between population age structure, food production, and hunger.”\nRegarding Wood’s fourth question, C. O. Puleston and Tuljapurkar (2008) conclude: “In terms of well being, a population’s hunger level will decrease as its numbers increase towards an equilibrium level. Economic growth that alters the productivity of land (or otherwise increases the caloric returns to labor via other forms of economic activity) will result in an increase in equilibrium population size. Economic growth that alters demographic conditions will affect the equilibrium level of hunger. The tradeoff between population size and individual well being at equilibrium is sensitive to changes in technology.”\nA troubling finding of C. Puleston, Tuljapurkar, and Winterhalder (2014) is their finding that a small population can grow at a relatively constant rate for hundreds of years before making a very rapid transition to the equilibrium. Growing populations experience higher levels of well-being. The approach to the equilibrium can be very abrupt, suggesting that people experiencing the transition may not notice the approach of the equilibrium.\n\n7.2.1 The Basic Model\nThe food-limited demographic model of C. T. Lee and Tuljapurkar (2008) turns on a key quantity known as the food ratio (\\(E\\)), which represents the ratio of food-energy availability to population need. When the availability of food meets or exceeds the population requirements, \\(E \\geq 1\\) and vital rates will be maximal. When \\(E &lt; 1\\), people are hungry and the population is food-limited. Demographic rates such as age-specific survival probabilities and fertility rates are a function of the average value of the food ratio, \\(\\hat{E}\\) or, more parsimoniously, average hunger.\nThe required consumption at age \\(x\\) is \\(J \\rho_x\\), where \\(J\\) is the largest age-specific nutritional need. We set \\(\\rho_x =1\\) for ages \\(x\\) where consumption equals \\(J\\), and \\(\\rho_x &lt; 1\\) for all other ages.\nThe total energetic consumption necessary for maximal vital rates, what C. T. Lee and Tuljapurkar (2008) call “ideal consumption,” is given by the summed product of the age-specific relative needs and the age-structure of the population:\n\\[\nJ( \\langle \\mathbf{\\rho}, \\mathbf{n}(t) \\rangle = J \\sum_x \\rho_x n_x(t)\n\\]\nParameters: \\(Y\\) is yield/area, \\(H\\) is the maximum number of hours of production, \\(k\\) is the area worked per hour, \\(\\phi_x\\) is the proportion of \\(H\\) at age \\(x\\), \\(m_x(0)\\) is maximum fertility (the zero indicates that this is the fertility of women age \\(x\\) when \\(\\log(E)=0\\), i.e., when there is no hunger), \\(p_x(0)\\) is maximum survival, \\(\\alpha_x = dp_x/d \\log(E)\\) is the elasticity of survival at age \\(x\\), \\(\\gamma_x = dm_x/d \\log(E)\\) is the fertility elasticity at age \\(x\\). Throughout, parameters evaluated at their food-limited equilibria will be marked with hats (e.g., equilibrium food ratio is \\(\\hat{E}\\)).\nThe food-limited characteristic equation:\n\\[\n1 = \\sum_x l_x(\\hat{E}) m_x(\\hat{E}) \\hat{\\lambda}_1^{-x}\n\\]\nHere \\(l_x\\) is the survival to age \\(x\\), \\(m_x\\) is the age-specific fertility rate for age \\(x\\) and \\(\\lambda_1\\) is the asymptotic multiplicative rate of increase of the population. Both survival and fertility are functions of average hunger, \\(\\hat{E}\\).\nAs in classic stable population theory, the equilibrium age structure for age \\(x\\) is proportional to the survival to age \\(x\\) and discounted by the growth rate:\n\\[\n\\hat{u}_1(x) = c\\, l_x(\\hat{E}) \\hat{\\lambda}_1^{(-x+1)},\n\\]\nwhere \\(c\\) is a constant chosen so that the sum of the equilibrium vector of age classes \\(\\mathbf{u_1}\\) is unity.\nAs in the classic theory, if the population is stationary (i.e., \\(\\lambda_1=1\\)), the age structure is simply equal to the survivorship curve, though in this case it is the hunger-dependent survivorship. The dependence on hunger might change the age structure substantially if certain age classes (e.g., young children) are more vulnerable to the effects of hunger.\n\n7.2.1.1 Age-Specific Schedules of Production and Needs\nThe total workforce is the inner-product of the age-schedule labor, \\(\\mathbf{\\phi}\\) and the age-structure of the population, \\(\\mathbf{n(t)}\\). \\(\\phi_x \\leq 1\\) gives the proportion of \\(H\\) (maximum number of hours in production) contributed by an individual age \\(x\\). In a similar way, the total need is the inner product of the age-schedule of physiological need \\(\\mathbf{\\rho}\\) and the age-structure, \\(\\mathbf{n(t)}\\). \\(\\rho_x \\leq 1\\) gives the proportion of the population that consume the largest nutritional need, \\(J\\).\nThe food ratio at time \\(t\\) is found by dividing the product of yield (\\(Y\\)), time worked (\\(H\\)), and efficiency (\\(k\\)) by the largest age-specific nutritional need (\\(J\\)). This ratio is scaled by the size of the workforce divided by the food need of the workforce:\n\\[\nE(t)=\\frac{Y H k}{J} \\frac{\\langle\\boldsymbol{\\phi}, \\mathbf{n}(t)\\rangle}{\\langle\\boldsymbol{\\rho}, \\mathbf{n}(t)\\rangle}=\\frac{Y H k}{J} \\frac{N\\langle\\boldsymbol{\\phi}, \\mathbf{u}(t)\\rangle}{N\\langle\\boldsymbol{\\rho}, \\mathbf{u}(t)\\rangle}=\\frac{Y H k}{J} \\frac{\\langle\\boldsymbol{\\phi}, \\mathbf{u}(t)\\rangle}{\\langle\\boldsymbol{\\rho}, \\mathbf{u}(t)\\rangle}\n\\]\nC. T. Lee and Tuljapurkar (2008) note that these equations simultaneously determine the equilibrium values of the growth rate, \\(\\hat{\\lambda_1}\\), and food ratio, \\(\\hat{E}\\).\nSome of the formal results of C. T. Lee and Tuljapurkar (2008):\nThe yield that is needed to achieve a food ratio of \\(E=1\\) is\n\\[\nY = Y(0) = \\frac{J}{Hk} \\frac{\\langle \\mathbf{\\rho, u_i(0)} \\rangle}{\\langle \\mathbf{\\phi, u_i(0)} \\rangle}.\n\\]\nAt the equilibrium, where the population size is smaller than the size under the no-hunger model (i.e., \\(Y &lt; Y(0)\\)), a growth rate less than the maximal (\\(\\hat{\\lambda}_1 &lt; \\lambda_1(0)\\)), and equilibrium hunger (\\(\\log(E) &lt; 0\\)), the food ratio is related to the scaled yield as:\n\\[\n\\hat{E} \\approx \\left( \\frac{Y}{Y(0)} \\right)^{K_1}\n\\]\n\\(K_1\\) is a function of many parameters, but C. T. Lee and Tuljapurkar (2008) find that under a wide range of realistic parameter combinations, \\(K_1 \\approx 1\\). This means that equilibrium hunger is approximately equal to the scaled yield. The common-sense interpretation of this is that if yield is cut from half of its ideal level, half the people would be hungry.\nThe scaled growth rate is related to \\(\\hat{E}\\) as:\n\\[\n\\frac{ \\hat{\\lambda}_1}{ \\lambda_1(0)} \\approx \\hat{E}^{K_2}\n\\]\n\\(K_2 = \\nu_G/T_G\\), where \\(\\nu_G\\) is a weighted average of the survival and fertility elasticities at \\(\\log(E) = 0\\), \\(T_G\\) is the generation time (i.e., mean age of childbearing) at maximum fertility and survival. \\(K_2\\) is always positive, meaning that \\(\\hat{lambda}_1/ \\lambda_1(0)\\) is an increasing, concave function of \\(\\hat{E}\\).\nEquilibrium food ratio:\n\\[\n\\hat{E} \\approx \\frac{YHk}{J} \\frac{\\langle \\mathbf{\\phi, u_i(0)} \\rangle}{\\langle \\mathbf{\\rho, u_i(0)} \\rangle}\n\\]\nC. T. Lee and Tuljapurkar (2008) derive a food-dependent counterpart to the classic demographic result of Keyfitz (1977) who showed that the population growth rate scales with the net reproductive rate (NRR) raised to the inverse of the generation time. The food-dependent counterpart is:\n\\[\n\\hat{\\lambda}_1 \\approx \\lambda_1(0) \\left[ \\hat{E}^{\\nu_G} \\right]^{1/T_G}\n\\]\nwhere \\(\\lambda_1(0)\\) is the maximum growth rate evaluated where \\(E=0\\) (i.e., everyone eats as much as they need – there is no hunger). In equation~\\(\\ref{eq:food-keyfitz}\\), NRR scales as \\(\\hat{E}^{\\nu_G}\\). We would expect food-limited demographic rates, which determine NRR, to increase with increasing food availability with diminishing marginal gains. The curvature of this function is determined by the elasticities of the vital rates with respect to food availability (C. T. Lee and Tuljapurkar 2008).\n\n\n7.2.1.2 Biological Consequences of Deprivation\nFirst, perform a Taylor series expansion of life expectancy at birth around life expectancy at birth for the unlimited population:\n\\[\n\\hat{e}_0 = \\sum_x \\hat{l}_x \\approx e_0(0) + \\log \\hat{E}^{\\langle \\mathbf{\\beta(0),l(0)} \\rangle}\n\\]\nwhere \\(\\mathbf{\\beta(0)}\\) is a vector of the survival elasticities evaluated at \\(\\log{E}=0\\), and \\(\\mathbf{l(0)}\\) is a vector of maximum survival.\nNext, expand TFR around the non-limited TFR:\n\\[\n\\widehat{TFR} = \\sum_x \\hat{m}_x \\approx TFR(0) + \\log \\hat{E}^{\\langle \\mathbf{\\gamma(0),m(0)} \\rangle}\n\\]\nStylized assumptions: see their appendix A and put in details…\nThe age pattern for survival elasticities, \\(\\alpha_x\\), is approximated as a constant value \\(\\alpha\\) and for fertility elasticities, \\(\\gamma_x\\), by a constant \\(\\gamma\\).\n\\[\n\\hat{e}_0 \\approx e_0(0) + \\frac{\\alpha (e^2_0 + s^2_0)}{2} \\log(\\hat{E})\n\\]\nwhere \\(s^2_0\\) is the variance in age at death.\nThis shows the very interesting result that the decline in life expectancy as scarcity increases (note that \\(\\log(\\hat{E}) &lt; 0\\) when the population is food-limited) is larger for both high-life-expectancy populations and for populations where the variance in age at death is large. C. T. Lee and Tuljapurkar (2008) note that this latter condition applies to populations with high infant and child mortality and relatively even adult mortality Edwards and Tuljapurkar (2005).\n\\[\n\\widehat{TFR} \\approx TFR(0) \\left( 1 + \\gamma \\log(\\hat{E}) \\right)\n\\]\nThis shows that the elasticity of TFR to a change in \\(\\hat{E}\\) is simply \\(\\gamma\\).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Emergence and Governing the Commons</span>"
    ]
  },
  {
    "objectID": "commons.html#commons-and-governance",
    "href": "commons.html#commons-and-governance",
    "title": "7  Emergence and Governing the Commons",
    "section": "7.3 Commons and Governance",
    "text": "7.3 Commons and Governance\n“Fifty years on, let’s stop the mindless invocation of Hardin” (Matto Mildenberger)\nIn his (1833) Two Lectures on the Checks to Population, William Forster Lloyd argued that on a “common”, costs are collective, while benefits are private. Pursuit of individual interest leads to over-exploitation. It is inevitable. These ideas circulated, particularly in economics (e.g., Scott Gordon, Mancur Olsen, Harold Demsetz). Then in 1968, a Stanford-trained ecologist wrote a highly-influential paper in the flagship journal Science. This paper contained not a single datum, nor was the argument especially original, as it was simply a re-telling of Forster Lloyd. Banner (2018) suggests the only thing that Hardin did was provide a catchy name for a phenomenon known for centuries.\nThe most obvious error that Hardin makes is that he assumes that access to the commons is completely open. As Kollock (1998) notes, this assumption is “neither necessary nor historically accurate”. Commons are frequently governed by very strict norms and customary laws.\nDasgupta (2001) also notes that Hardin gets his history (to the extent that the paper actually contains any) wrong, suggesting, “it is difficult to locate a passage of comparable length and fame that contains as many errors as the one above.”\nHardin was a xenophobe, nativist, and white nationalist. He was a major intellectual for the white-nationalist right. His notion of “passive genocide” is an idea that has transformed into the current notion of “Great Replacement.” In a 1991 essay, he wrote:\n\nthere are two forms [of genocide]. Active genocide is the sort one first thinks of — Hitler killing six million Jews. But there is another form — more subtle, less obvious, but potentially equally effective — that we may call passive genocide. The way this works was recently revealed in … remarks by Ali Akbar Hashemi Rafsanjani, the speaker of the Iranian parliament… Translated bluntly, ‘We Muslims are going to outbreed you.’ … If two cultures compete for the same bit of ‘turf’ (environment), and if one of the populations increases faster than the other, then year by year, the population that is reproducing faster will increasingly outnumber the slower one …This is passive genocide.\n\nNear the end of his life, he wrote in a 1999 essay:\n\nThe Ford Foundation (and other organizations financed by American money) have allotted many millions of dollars to nondemocratic Latino organizations that are determined to revise the political structure of the United States… We have no reason to suppose that suicidal political organizations will never succeed in creating a chaotic NorteAmericano Central. The human species may not self-destruct; but what we like to call ‘human civilization’ may.\n\nNote that the current Vice President of the United States has recently attacked the Ford Foundation in particular for its allegedly “Far Leftist” ideology as part of his pledge to “work to dismantle the institutions that promote violence and terrorism in our own country.” Hardin’s prejudices cast long shadows.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Emergence and Governing the Commons</span>"
    ]
  },
  {
    "objectID": "commons.html#ostrom",
    "href": "commons.html#ostrom",
    "title": "7  Emergence and Governing the Commons",
    "section": "7.4 Ostrom",
    "text": "7.4 Ostrom\nCommons are not free-for-alls, as demonstrated by the work of Lin Ostrom and her collaborators.\nOstrom’s Typology of Goods:\n\n\n\n\n\n\n\n\n\nSubtractable\nNon-Subtractable\n\n\n\n\nExcludable\nPrivate Goods\nClub Goods\n\n\nNon-Excludable\nCommon-Pool Resources\nPublic Goods\n\n\n\nCommon-Pool Resources: stocks of natural resources, grazing land, fisheries, forests, etc. Public Goods: Peace, security, knowledge, weather forecasts Private Goods: stuff you own Club Goods: theaters, daycares\nIn his important work on the economics of collective action, Olson (1965) made a number of generalizations about collective action. Olson’s conclusion about the viability of collective action, that has come to be known as the zero-contribution thesis, is that “unless the number of individuals in a group is quite small, or unless there is coercion or some other special device to make individuals act in their common interest, rational, self-interested individuals will not act to achieve their common or group interests.”\nOstrom (2000, 140) notes that the zero-contribution thesis is contradicted by empirical reality, writing “By now seven general findings have been replicated so frequently that these can be considered the core facts that theory needs to explain.” These include:\n\nSubjects contribute 40-60% of their endowments in one-shot/first-round games\nContributions decay after first round but remain nonzero\nBelievers in others’ cooperative intentions contribute more\nLearning the game better leads to more cooperation, not less\nFace-to-face communication increases cooperation\nPlayers pay to punish cheaters\nContext (like framing) matters\n\n\n7.4.1 Managing the Commons\nOstrom’s Design Principles of successful commons management are bottom-up, emerging from the people engaged in using the resources (Ostrom 2015).\nOstrom’s Design Principles:\n\nDefine clear group boundaries\nMatch rules governing use of common goods to local needs and conditions\nEnsure that those affected by the rules can participate in modifying the rules\nMake sure the rule-making rights of community members are respected by outside authorities\nDevelop a system, carried out by community members, for monitoring members’ behavior\nUse graduated sanctions for rule violators\nProvide accessible, low-cost means for dispute resolution\nBuild responsibility for governing the common resource in nested tiers from the lowest level up to the entire interconnected system\n\nA thing that we learn from subsistence populations is that open access does not necessarily lead to depression. Property rights generally thought of as key to avoiding tragedies of the commons. This includes Ostrom (2015). It’s her first design principle! However, pastoralists, artisanal fishermen, hunter-gatherers all require more territory than can be defended economically, so the idea of property rights does not make sense in many traditional subsistence economies.\nPastoralists often blamed for land degradation. However, they are pretty much never to blame. More the type of agricultural over-exploitation discussed by Lansing in Bali (e.g., Lansing 1991). Pastoralist land increasingly circumscribed. Migration from agricultural areas and cities. Extensive observations suggest that pastoralists often manage their common resources very effectively (Johnson 1993).\nMoritz et al. (2018) note that, in fact, many of these open-access subsistence systems remain resilient without access restrictions. They present a theoretical model that specifies when open access does not lead to resource over-exploitation.\nMortiz et al.’s model suggests the following features which allow open-access systems to not become depleted:\n\nBenefits of defense outweighed by costs\nIdeal Free Distribution (IFD)\nHigh resource renewal rate\nInformation freely shared\nNiche construction of more favorable resource regimes\nNonlinear feedback (i.e., coupling)\nDevelopment of shared norms\n\nThe Ideal Free Distribution (IDF) is essentially a formalization of the common-sense rule that organisms should settle a heterogeneous landscape in proportion to the resource availability.\n\n### Ideal Free Distribution\ng &lt;- seq(0,sqrt(1/5),length=200)\nh &lt;- sqrt(1-(5*g^2))\nhf &lt;- function(g,a=1) sqrt(a-(5*g^2))\n## derivative\nfp &lt;- function(g) -5*g/sqrt(1-5*g^2)\n\n## will give warnings; doesn't matter\nplot(g,hf(g), type=\"l\", lwd=2, axes=FALSE, frame=TRUE, \n     yaxs=\"i\", xaxs=\"i\", \n     ylim=c(0.1,1.1), xlim=c(0,0.5), \n     xlab=\"Number of Competitors\", \n     ylab=\"Rewards per Individual\")\nlines(g,hf(g,a=0.5), lwd=2)\n# used locator() to find tangents\nsegments(0,hf(0.1,a=1/2),0.3319867,hf(0.1,a=1/2), lty=2)\nsegments(0.3319867,0,0.3319867,0.6714605, lty=2)\nsegments(0.1,0,0.1,hf(0.1,a=1/2),lty=2)\n\n\n\n\n\n\n\n\nAnother important idea from Ostrom: Commons problems arise in part because of a failure to recognize larger systems in which they are embedded (Ostrom 2009).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Emergence and Governing the Commons</span>"
    ]
  },
  {
    "objectID": "commons.html#how-many-people-can-the-earth-support",
    "href": "commons.html#how-many-people-can-the-earth-support",
    "title": "7  Emergence and Governing the Commons",
    "section": "7.5 How Many People Can the Earth Support?",
    "text": "7.5 How Many People Can the Earth Support?\nWhere does the Carrying Capacity come from? Presumably, \\(K\\) ultimately arises from resource limitation. The most likely form of resource limitation, particularly for humans, is food. We see that people live at very different densities depending upon their subsistence economy. This is indirect evidence that food limitation at least plays a substantial role in determining human population size. Joel Cohen explored this idea extensively in his masterful (1995) book, How Many People Can the Earth Support? (J. E. Cohen 1996).\nOne of the key debates that Cohen describes in his book relates to the response of human populations to increased population density. Cohen concludes that the answer to the question that defines his book, How Many People Can the Earth Support?, depends on several things. Fundamentally, the answer depends upon individual and collective human decisions. There is no simple answer. Cohen suggests a dinner table metaphor to understand how we might increase the carrying capacity of Earth. Three things to consider for how to increase the total carrying capacity of Earth are:\n\nMake a bigger pie: Increase human productive capacities through technology and innovation.\nPut fewer forks on the table: Reduce numbers and expectations of people through such means as family planning and vegetarian diets.\nTeach better manners: Change the terms of people’s interactions through improved planning and government to enhance social justice.\n\nSome of these are rather more difficult to achieve than others.\n\n\n\n\nBanner, Stuart. 2018. “The Banality of the Commons: Efficiency Arguments Against Common Ownership Before Hardin.” Theoretical Inquiries in Law 19 (2): 395–407. https://doi.org/10.1515/til-2018-0021.\n\n\nCohen, J. E. 1996. How Many People Can the Earth Support? New York: Norton.\n\n\nCohen, M. N. 1989. Health and the Rise of Civilization. New Haven: Yale University Press.\n\n\nCohen, M. N., G. J. Armelagos, and C. S. Larsen. 1984. Paleopathology at the Origins of Agriculture. Orlando, FL: Academic Press.\n\n\nDasgupta, Partha S. 2001. Human Well-Being and the Natural Environment. Oxford: Oxford University Press. https://books.google.com/books?id=5Je4AAAAIAAJ.\n\n\nEdwards, R. D., and S. Tuljapurkar. 2005. “Inequality in Life Spans and a New Perspective on Mortality Convergence Across Industrialized Countries.” Population and Development Review 31 (4): 645–74. https://www.jstor.org/stable/3401520.\n\n\nHill, K., and A. M. Hurtado. 1996. Ache Life History. New York: Aldine de Gruyter.\n\n\nJohnson, Douglas L. 1993. “Nomadism and Desertification in Africa and the Middle East.” GeoJournal 31 (1): 51–66. https://doi.org/10.1007/BF00815903.\n\n\nKeyfitz, N. 1977. Introduction to the Mathematics of Populations. 2nd ed. Menlo Park: Addison-Wesley.\n\n\nKollock, Peter. 1998. “Social Dilemmas: The Anatomy of Cooperation.” Annual Review of Sociology 24 (1): 183–214. https://doi.org/10.1146/annurev.soc.24.1.183.\n\n\nLansing, John Stephen. 1991. Priests and Programmers : Technologies of Power in the Engineered Landscape of Bali. Princeton, NJ: Princeton University Press.\n\n\nLee, Charlotte T., and Shripad Tuljapurkar. 2008. “Population and Prehistory I: Food-Dependent Population Growth in Constant Environments.” Theoretical Population Biology 73 (4): 473–82. https://doi.org/10.1016/j.tpb.2008.03.001.\n\n\nLee, Ronald D. 1986. “Malthus and Boserup: A Dynamic Synthesis.” In The State of Population Theory, edited by D. Coleman and R. Schofield, 96–130. New York: Blackwell.\n\n\nMoritz, Mark, Roy Behnke, Christine M. Beitl, Rebecca Bliege Bird, Rafael Morais Chiaravalloti, Julia K. Clark, Stefani A. Crabtree, et al. 2018. “Emergent Sustainability in Open Property Regimes.” Proceedings of the National Academy of Sciences 115 (51): 12859–67. https://doi.org/10.1073/pnas.1812028115.\n\n\nNetting, R. M. 1993. Smallholders, Householders: Farm Families and the Ecology of Intensive, Sustainable Agriculture. Stanford: Stanford University Press.\n\n\nOlson, M. 1965. The Logic of Collective Action: Public Goods and the Theory of Groups. Cambridge: Harvard University Press.\n\n\nOstrom, Elinor. 2000. “Collective Action and the Evolution of Social Norms.” The Journal of Economic Perspectives 14 (3): 137–58. http://www.jstor.org/stable/2646923.\n\n\n———. 2009. “A General Framework for Analyzing Sustainability of Social-Ecological Systems.” Science 325 (5939): 419–22. https://doi.org/10.1126/science.1172133.\n\n\n———. 2015. Governing the Commons: The Evolution of Institutions for Collective Action. Canto Classics. Cambridge: Cambridge University Press. https://doi.org/10.1017/CBO9781316423936.\n\n\nPuleston, C. O, and S. Tuljapurkar. 2008. “Population and Prehistory II: Space-Limited Human Populations in Constant Environments.” Theoretical Population Biology 74 (2): 147–60. https://doi.org/10.1016/j.tpb.2008.05.007.\n\n\nPuleston, C., S. Tuljapurkar, and B. Winterhalder. 2014. “The Invisible Cliff: Abrupt Imposition of Malthusian Equilibrium in a Natural-Fertility, Agrarian Society.” PloS ONE 9 (1): 13. https://doi.org/10.1371/journal.pone.0087541.\n\n\nWood, J. W. 1998. “A Theory of Preindustrial Population Dynamics: Demography, Economy, and Well-Being in Malthusian Systems.” Current Anthropology 39 (1): 99–135. https://doi.org/10.1086/204700.\n\n\nWood, J. W., G. R. Milner, H. C. Harpending, and K. M. Weiss. 1992. “The Osteological Paradox: Problems of Inferring Prehistoric Health from Skeletal Samples.” Current Anthropology 33 (4): 343–70. http://www.jstor.org/stable/2743861.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Emergence and Governing the Commons</span>"
    ]
  },
  {
    "objectID": "dynamic.html",
    "href": "dynamic.html",
    "title": "8  Dynamic Optimization and Adaptive Management",
    "section": "",
    "text": "8.1 Dynamic Programming\nSometimes there isn’t a single best value to choose. Instead, the best choice depends on the state of the organism, the environment, the social group, etc. Dynamic optimization approaches such as dynamic programming provide very powerful tools for such cases. In principle, these methods are very simple to implement. In practice it can be easier to find solutions for dynamic programming models than for many complex but static problems. Dynamic programming simply takes a bit of computer programming and a willingness to deal with some notation.\nA full description of the method of stochastic dynamic programming is beyond the scope of this chapter, and the interested reader is referred to both Mangel and Clark (1988) and Clark and Mangel (2000), a pair of excellent books detailing dynamic programming with applications in behavioral ecology and natural resource management. Nonetheless, it is worth outlining the logic of dynamic programming.\nThe optimal decision in a dynamic programming problem is made by considering a dynamic state valiable. Such a variable might be individual energy stores in a foraging application or household wealth in an economic application. This state variable increases or decreases depending upon your decision and whether or not you are successful once you have made your decision. Whether you decide to pursue the high-risk/high-gain prey or the low-risk/low-gain prey will be a function of how hungry you are. Similarly, whether you liquidate your houshold herd or not will depend critically on whether your household is in imminent danger of extinction. Dynamic programming relies on defining a finite time horizon over which decisions are made. It turns out frequently to be quite easy to determine the optimal choice, given the state variable, in this last time step. For example, consider the case of risky foraging. Say that if at the end of the time horizon, \\(T\\) (e.g., a week or a month) you will starve to death if your energy stores are below a critical value \\(x(T)&lt;x_c\\). Your goal is simply to survive to \\(T\\). In this case, it is obvious that you go for the high-risk/high-reward choice if getting the high return will put you above \\(x_c\\) but the low return will not. There is no need to be concerned about risk at this point because you are desperate. Similarly, if you are at the end of the time span (i.e., \\(T-1\\)), comfortably above \\(x_c\\) and the risk associated with the high-risk/high-reward foraging target is mortality (e.g., in the case where foraging for the high-reward item is dangerous), then you obviously go for the low-risk choice because there is no added benefit to ending way above or just above \\(x_c\\) – the only thing that matters is whether you survive.\nOnce you have determined what the optimal decision is for \\(T-1\\), you then figure out what the best decision is at \\(T-2\\) and so on. By moving backward through time, you are always making the relatively easy decision of “the last” since your decision at time \\(T-2\\) can not be affected by your decision at time \\(T-1\\).\nDynamic programming has been applied to human ecology, though apparently perceptions about it being an advanced or difficult technique have kept the applications to human ecology less numerous than the utility of the technique would warrant. Mace (1993) used dynamic programming to study subsistence decisions among Gabbra pastoralists of Ethiopia. Mace used multiple objective functions: herd offtake, short-term household survival, and long-term household survival. The decision that she investigated was whether or not Gabbra herders should manipulate the breeding rate of their sheep. She found that each different objective function yielded a different prediction: (1) maximizing off-take predicted that breeding should never be slowed, (2) maximizing short-term household survival predicted that breeding should always be slowed, and (3) maximizing long-term household survival predicted that the herd-breeding rate should only be slowed by relatively wealthy households. Her ethnographic data supported pediction 3, supporting the hypothesis that Gabbra herders are maximizing long-term household survival. Mace argues that this is the outcome most clearly consistent with natural selection acting upon decision-making.\nGillis et al. (1995), as discussed in Clark and Mangel (2000), investigated a phenomenon known as “high-grading” in the Oregon sablefish fishery. High-grading is the practice of discarding less valuable fish when they are caught in anticipation of landing more valuable fish later. The discarded fish typically die when they are discarded. Fishing boats high-grade because they can not keep valuable fish if their hold is filled and if it is filled with lower-quality fish (i.e., fish fetching a lower price at market), then they potentially pay a substantial opportunity cost for keeping lower-grade fish. They found that high-grading should become more common in four situations: (1) toward the end of fishing trips, (2) when there is a greater overall availability of fish, (3) when there is a decrease in the trip quota, or (4) where there a decrease in the risk prematurely terminating a fishing trip. The model of Gillis et al. (1995) can be used to estimate bycatch mortality, an important fisheries metric.\nSometimes there isn’t a single best value to choose. Instead, the best choice depends on the state of the organism, the environment, the social group, etc. Dynamic optimization approaches such as stochastic dynamic programming (SDP) provide very powerful tools for such cases. In principle, these methods are very simple to implement. In practice it can be easier to find solutions for dynamic programming models than for many complex but static problems. Dynamic programming simply takes a bit of computer programming and a willingness to deal with some notation. A full description of the method of stochastic dynamic programming is beyond the scope of this chapter, and the interested reader is referred to both Mangel and Clark (1988) and Clark and Mangel’s (2000) excellent books detailing dynamic programming with applications in behavioral ecology and natural resource management. Nonetheless, it is worth outlining the logic of dynamic programming.\nFitness is a function of both the state variable(s) (which may be vector-valued) that changes with time, \\(x_t\\), and the control variable \\(a_t\\). The control variable is the action the actor takes at each time \\(t\\). The goal is to maximize the fitness function over some specified time horizon ranging from \\(t=0\\) to \\(t=T\\). Dynamic programming solves the problem,\n\\[ \\max_A \\mathsf{E} \\left( F(x_t, a_t) \\right). \\]\nThat is, choose the actions \\(a_t \\in A\\) that maximize the expected value of the fitness function over the time period \\([0, T]\\).\nThe optimal decision in a dynamic programming problem is made by considering a dynamic state variable. Such a variable might be individual energy stores in a foraging application or household wealth in an economic application. This state variable increases or decreases depending upon the actor’s decision and whether or not the actor is successful once its made a decision. Whether an actor decides to pursue the high-risk/high-gain prey or the low-risk/low-gain prey will be a function of how hungry the actor is. Similarly, whether the actor liquidates its household herd or not will depend critically on whether the household is in imminent danger of extinction. Dynamic programming relies on defining a finite time horizon over which decisions are made. It turns out frequently to be quite easy to determine the optimal choice, given the state variable, in this last time step. For example, consider the case of risky foraging. Say that if at the end of the time horizon, \\(T\\) (e.g., a week or a month) the actor will starve to death if its energy stores are below a critical value \\(x(T)&lt;x_c\\). The actor’s goal is simply to survive to \\(T\\). In this case, it is obvious that the actor will go for the high-risk/high-reward choice if getting the high return will put it above \\(x_c\\) but the low return will not. There is no need to be concerned about risk at this point because the actor is desperate. Similarly, if the actor is at the end of the time span (i.e., \\(T-1\\)), comfortably above \\(x_c\\) and the risk associated with the high-risk/high-reward foraging target is mortality (e.g., in the case where foraging for the high-reward item is dangerous), then the actor obviously goes for the low-risk choice because there is no added benefit to ending way above or just above \\(x_c\\) – the only thing that matters is whether it survives.\nOnce we have determined what the optimal decision is for \\(T-1\\), we then figure out what the best decision is at \\(T-2\\) and so on. By moving backward through time, we are always making the relatively easy decision of “the last” since your decision at time \\(T-2\\) can not be affected by your decision at time \\(T-1\\). This process is known as “backward induction” and it is a powerful tool also used in finding the evolutionary stable strategies in games.\nDynamic programming has been applied to human ecology, though apparently perceptions about it being an advanced or difficult technique have kept the applications to human ecology less numerous than the utility of the technique would warrant. Mace (1993) used dynamic programming to study subsistence decisions among Gabbra pastoralists of Ethiopia. Mace used mutliple objective functions: herd offtake, short-term household survival, and long-term household survival. The decision that she investigated was whether or not Gabbra herders should manipulate the breeding rate of their sheep. She found that each different objective function yielded a different prediction: (1) maximizing off-take predicted that breeding should never be slowed, (2) maximizing short-term household survival predicted that breeding should always be slowed, and (3) maximizing long-term household survival predicted that the herd-breeding rate should only be slowed by relatively wealthy households. Her ethnographic data supported prediction #3, supporting the hypothesis that Gabbra herders are maximizing long-term household survival. Mace argues that this is the outcome most clearly consistent with natural selection acting upon decision-making.\nGillis et al. (1995), as discussed in Clark and Mangel (2000), investigated a phenomenon known as “high-grading” in the Oregon sablefish fishery. High-grading is the practice of discarding less valuable fish when they are caught in anticipation of landing more valuable fish later. The discarded fish typically die when they are discarded. Fishing boats high-grade because they can not keep valuable fish if their hold is filled and if it is filled with lower-quality fish (i.e., fish fetching a lower price at market), then they potentially pay a substantial opportunity cost for keeping lower-grade fish. They found that high-grading should become more common in four situations: (1) toward the end of fishing trips, (2) when there is a greater overall availability of fish, (3) when there is a decrease in the trip quota, or (4) where there a decrease in the risk prematurely terminating a fishing trip. The model of Gillis et al. (1995) can be used to estimate by-catch mortality, an important fisheries metric.\nMilner-Gulland and colleagues (1996) model household decision-making among dry-land agropastoralists. They were specifically interested in three questions: (1) why do farmers in dry areas grow maize despite the fact that it performs poorly when water stressed? (2) what determines the fraction of household wealth represented by goats, cattle, or crops? (3) how does the ability to use cattle as draft animals affect the optimal proportions of livestock vs. crops?\nMilner-Gulland, Mace, and Scoones (1996) employ an important feature of the dynamic programming approach. Solving the dynamic programming approach allowed the researchers to find the optimal strategies for different wealth states of individual households. However, they were also able to specify suboptimal strategies and explore the consequences of these for household wealth by forward simulation. Furthermore, by simulating all possible paths for a household’s wealth from a given starting point, a household wealth probability distribution for destitution (i.e., zero household wealth) can be calculated.\nThe model allowed the authors to understand the seemingly paradoxical observation that poor farmers on very dry land will plant maize despite its typically poor performance in dry country rather than millet which does much better. In brief, the only hope for a farmer faced with destitution is to get very lucky and produce a bumper crop of maize. At that level of poverty, a millet crop will not raise the farmer from destitution, so he might as well attempt the maize crop. Similarly, wealthier households should switch to millet because of its lower year-to-year variance. This is an interesting example of Friedman & Savage’s (1948) model for changing risk preference with wealth discussed below.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Dynamic Optimization and Adaptive Management</span>"
    ]
  },
  {
    "objectID": "dynamic.html#dynamic-programming",
    "href": "dynamic.html#dynamic-programming",
    "title": "8  Dynamic Optimization and Adaptive Management",
    "section": "",
    "text": "8.1.1 Example: Clark & Mangel (2000) Patch-Choice Model\nThe R code for this model is provided by Soetaert and Herman (2009).\nFirst set the parameters\n\nxcrit &lt;- 0\nxmax &lt;- 30\nxrep &lt;- 4\nxclass &lt;- xcrit:xmax\nnmass &lt;- length(xclass)\ntmax &lt;- 20\ntimes &lt;- 1:(tmax-1)\n\nSome more:\n\nnpatch &lt;- 3\npsurv &lt;- c(0.99,0.95,0.98)\npfood &lt;- c(0.2,0.5,0)\ncost &lt;- c(1,1,1)\nfeedgain &lt;- c(2,4,0)\nrepr &lt;- c(0,0,4)\n\nf &lt;- matrix(nr=tmax, nc=nmass, 0)\nbestp &lt;- matrix(nr=tmax-1,nc=nmass-1,0)\nV &lt;- vector(len=npatch)\nfend &lt;- 60\n# saturation parameter\nkx &lt;- 0.25*xmax\n# terminal fitness -- type II functional response\nf[tmax,] &lt;- fend*(xclass-xcrit)/(xclass-xcrit+kx)\n\nDefine the fitness function that will be used in the iteration:\n\nfitness &lt;- function(x,t){\n  xx &lt;- pmin(x,xmax)\n  xx &lt;- pmax(xx,xcrit)\n  fitness &lt;- f[t,xx-xcrit+1]\n}\n\nThis runs the main loop. Iterate over time and over size classes.\n\nfor(t in rev(times))                         #backwards iteration\n{\n  for(x in xclass[-1])                       #each class except xcrit\n    {\n      dfit &lt;- pmax(0,pmin(x-xrep,repr))      #reproduction\n      expectgain &lt;- psurv*(pfood*fitness(x-cost+feedgain-dfit,t+1) + (1-pfood)*fitness(x-cost-dfit, t+1))\n      V &lt;- dfit + expectgain\n      V[expectgain == 0] &lt;- 0                 #dead\n      f[t,x-xcrit+1] &lt;- max(V)                #optimal fitness\n      bestp[t,x-xcrit] &lt;- which.max(V)        #best patch\n\n    }  # next biomass class x\n\n} # next time t\n\nPlot the output using an image and overlay contour lines\n\nimage(x=times,y=xclass[-1],z=bestp,ylab=\"weight\",xlab=\"time\",zlim=c(0,3),\n        main=\"optimal patch\",col=c(\"black\",\"blue4\",\"turquoise\",\"skyblue\"))\n  box()\nlegend(\"topleft\",fill=c(\"black\",\"blue4\",\"turquoise\",\"skyblue\"), legend=c(\"dead\",\"1\",\"2\",\"3\"))\ncontour(x=1:tmax, y=xclass, z=f,add=TRUE)\nlegend(\"topright\",legend=\"fitness\",lty=1)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Dynamic Optimization and Adaptive Management</span>"
    ]
  },
  {
    "objectID": "dynamic.html#notes-on-human-life-history-decisions",
    "href": "dynamic.html#notes-on-human-life-history-decisions",
    "title": "8  Dynamic Optimization and Adaptive Management",
    "section": "8.2 Notes on Human Life-History Decisions",
    "text": "8.2 Notes on Human Life-History Decisions\nDefine the six requirements of an SDP model (from Marescot et al. 2013):\n\nDefine optimization objective\nDefine states that determine the system\nDefine decision variable\nBuild transition model\nDefine utility function\nDetermine optimal solution\n\n\n8.2.1 Objective\nMaximize lifetime fitness. For first run, simply use number of recruited offspring. Eventually, use the Mangel/Clark approach using maximization of reproductive value, which is equivalent to maximizing \\(r\\), and therefore incorporating timing. This is very likely to be crucial to the outcomes.\n\n\n8.2.2 States\nBegin with seven states \\(\\mathbf{X_t} = (n_0, n_1, n_2, n_3, n_4, n_r, x)\\), where \\(n_i, i \\in 0:4\\) is the number of children age \\(i\\), \\(n_r\\) is the number of children age \\(&gt;5\\) (i.e., potential recruits), and \\(x\\) is the energetic state of the individual.\nMight want to extend the state-space to count all offspring age less than, say, 15. Not clear if this would be worth the computational costs though since kids over five have a more-or-less constant mortality rate until AFR.\n\n\n8.2.3 Decision Variable\nThe decision variable \\(A_t\\), at least for the simplest model, is really just whether or not to have a child.\n\n\n8.2.4 Transition Model\nHaving a baby has a big cost. Having an unweaned kid has a bigger cost (?), having a weaned kid has a lower cost. This may be why expanding the state space might make sense. Older kids cost a lot less and may even subsidize younger kids a bit.\nBecause this is a finite-time model that we will solve using backward induction, we need to define a terminal fitness function. If a woman survives to the end of her reproductive period, her terminal fitness function is just the sum of the product of the number of offspring she has in all different age classes (\\(n_i\\)) and the age-specific recruitment probabilities of these offspring (\\(\\sigma_i\\)).\n\\[ F(\\bar{x},T) = \\sum_i n_i \\sigma_i(\\bar{x}) \\]\nI have made the values of \\(\\sigma_i\\) be dependent on the mother’s energetic state. This increases realism and ensures that the model doesn’t default to maximizing terminal reproductive effort (i.e., mothers engage in a suicidal last bout of reproduction).\n\n\n8.2.5 Define Utility Function\nThe problem becomes:\n\\[ F(\\bar{x},t) = \\mathrm{max}\\{V_0(\\bar{x},t), V_1(\\bar{x},t)\\} \\]\nwhere the 0 and 1 subscripts denote the decision to delay or give birth in a the year \\(t\\) respectively.\nUnpacking \\(V_0\\), we get:\n\\[ V_0(\\bar{x},t) = s(t) \\{p_f(\\bar{x},t) \\mathsf{E}[F(\\bar{x}',t+1)] + (1-p_f(\\bar{x},t))  \\mathsf{E}[F(\\bar{x}'',t+1)] \\} + (1-s(t)) \\sum \\sigma_i n_i \\]\nwhere \\(s(t)\\) is the probability that the woman survives from \\(t\\) to \\(t+1\\), \\(p_f(\\bar{x},t)\\) is the probability that the woman, with state \\(\\bar{x}\\) forages successfully in that period, \\(\\mathsf{E}\\) is the expectation operator, \\(\\bar{x}'\\) is the value of the woman’s state if she forages successfully that year and \\(\\bar{x}''\\) is the value of the state if she is unsuccessful, and \\(F(\\bar{x},t+1)\\) is fitness given the state \\(\\bar{x}\\) at time \\(t+1\\).\nThis means that the formula for \\(V_0\\bar{x},t)\\) is the sum of two things: (1) the expected fitness if the woman survives the interval, and (2) the expected fitness if she does not. In the former case this is the sum of the expected fitness if she is successful in foraging, \\(p_f(\\bar{x},t) \\mathsf{E}[F(\\bar{x}',t+1)]\\) and if she is not successful, \\((1-p_f(\\bar{x},t))  \\mathsf{E}[F(\\bar{x}'',t+1)]\\). In the latter case, it is just the survival-weighted sum of her previous reproduction,\n\\[\\sum \\sigma_i n_i \\].\nA comparable formula applies for \\(V_1\\).\n\n\n8.2.6 Determine Optimal Solution\nBackwards induction of the finite time-horizon model.\n\n\n8.2.7 The Biology\nThe model is broadly similar to the model that Marty Anderies used to investigate optimal fertility among the !Kung (Anderies 1996). Anderies used an explicit dynamic model of backload constraint to determine the success of foraging. I think this is a bit too restricted. This is where we need to think hard. How does the state (i.e., the number and age-composition of children, and energy status) affect overall foraging success? Are there other potential key variables of state that are going to determine foraging success?",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Dynamic Optimization and Adaptive Management</span>"
    ]
  },
  {
    "objectID": "dynamic.html#adaptive-management",
    "href": "dynamic.html#adaptive-management",
    "title": "8  Dynamic Optimization and Adaptive Management",
    "section": "8.3 Adaptive Management",
    "text": "8.3 Adaptive Management\nGreatly expand this. (Holling 1978; Walters 1986)\nAdaptive management follows a cycle of planning, doing, evaluating and adjusting.\nSteps in Adaptive Management:\n\nSpecify a management objective (e.g., minimize final size of epidemic)\nIdentify possible management actions\nConstruct alternative models for the different management actions\nEvaluate the success of the chosen management action for achieving objective\nUpdate management decisions\nContinue measurement, evaluation, modeling alternatives\n\n\n\n\n\nAnderies, John M. 1996. “An Adaptive Model for Predicting !Kung Reproductive Performance: A Stochastic Dynamic Programming Approach.” Ethology and Sociobiology 17 (4): 221–45. https://doi.org/10.1016/0162-3095(96)00037-4.\n\n\nClark, C. W., and M. Mangel. 2000. Dynamic State Variable Models in Ecology. New York: Oxford University Press.\n\n\nHolling, C. S. 1978. Adaptive Environmental Assessment and Management. New York: Wiley. https://books.google.com/books?id=1InvPAAACAAJ.\n\n\nMace, Ruth. 1993. “Nomadic Pastoralists Adopt Subsistence Strategies That Maximise Long-Term Household Survival.” Behavioral Ecology and Sociobiology 33 (5): 329–34. https://doi.org/10.1007/BF00172931.\n\n\nMangel, M., and C. W. Clark. 1988. Dynamic Modeling in Behavioral Ecology. Monographs in Behavior and Ecology. Princeton: Princeton University Press.\n\n\nMilner-Gulland, E. J., Ruth Mace, and Ian Scoones. 1996. “A Model of Household Decisions in Dryland Agropastoral Systems.” Agricultural Systems 51 (4): 407–30. https://doi.org/10.1016/0308-521X(95)00057-C.\n\n\nSoetaert, Karline, and Peter M. J. Herman. 2009. “Dynamic Programming.” In A Practical Guide to Ecological Modelling, edited by Karline Soetaert and Peter M. J. Herman, 295–307. Amsterdam: Springer Netherlands. https://doi.org/10.1007/978-1-4020-8624-3_10.\n\n\nWalters, C. J. 1986. Adaptive Management of Renewable Resources. New York: Macmillan. https://books.google.com/books?id=rkEqPQAACAAJ.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Dynamic Optimization and Adaptive Management</span>"
    ]
  },
  {
    "objectID": "efficiency.html",
    "href": "efficiency.html",
    "title": "9  Efficiency Is the Enemy",
    "section": "",
    "text": "9.1 Optimality Models\nI come not to praise optimization but to bury it.\nWe live in a time of nonstationary change. When we optimize, we are adapting to the past.\nOptimality models are important.\nWhen we look at a textbook treatment on mathematical optimization (e.g., Boyd and Vandenberghe (2004)), what you will see is typically something like this.\n\\[\n\\begin{array}{ll}\n{\\operatorname{minimize}} & f_0(x) \\\\\n\\text { subject to } & f_i(x) \\leq b_i, \\quad i=1, \\ldots, m\n\\end{array}\n\\tag{9.1}\\]\nwhere \\(f_0()\\) is the objective function, \\(x\\) is the optimization variable, and the \\(f_i()\\) are the \\(m\\) constraint functions.\nYou can search your optimization text all you want, but you’re not likely to find any discussion of how to translate your real-world problem into the form of equation Equation 9.1. There is nothing about how to determine the choice variable, the objective function, the constraints, the possible set of actions, etc. This is where the specific scientific questions—and the subject knowledge of the research—comes in. So what do we need to translate a scientific question into an optimization problem?\nThere are different definitions of the structure/requirements for optimization models. I like the definition provided by Smith (1992), who provides a bit more structure than, say, Parker and Maynard Smith (1990).\nSmith’s Structure of an optimization model requires that we specify four things:\nMany would-be optimizers fail to identify any of these criteria.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Efficiency Is the Enemy</span>"
    ]
  },
  {
    "objectID": "efficiency.html#optimality-models",
    "href": "efficiency.html#optimality-models",
    "title": "9  Efficiency Is the Enemy",
    "section": "",
    "text": "Actor: Define the unit of analysis\nObjective Function: What is it that people seek to optimize?\nStrategy Set: What is the space of possible action?\nConstraints: Define what is actually achievable rather than the best of all possible worlds",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Efficiency Is the Enemy</span>"
    ]
  },
  {
    "objectID": "efficiency.html#the-trouble-with-optimality",
    "href": "efficiency.html#the-trouble-with-optimality",
    "title": "9  Efficiency Is the Enemy",
    "section": "9.2 The Trouble with Optimality",
    "text": "9.2 The Trouble with Optimality\nSmall worlds.\nUncertainty makes cost-benefit analysis impossible\nHeavy-tailed probability distributions have infinite moment-generating functions\nUnknown unknowns.\n“The hegemony of optimisation as the goal of decision-making is made possible by ignoring radical uncertainty.” (Kay and King 2020)\n“That makes it odd that economics should have put so much emphasis on optimising” (loc 5767)\nKeynes: the spirit of enterprise dies when mathematical expectation takes over (cited in Kay and King (2020)).\n“Thus if the animal spirits are dimmed and the spontaneous optimism falters, leaving us to depend on nothing but a mathematical expectation, enterprise will fade and die; —though fears of loss may have a basis no more reasonable than hopes of profit had before.” (Keynes 1936)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Efficiency Is the Enemy</span>"
    ]
  },
  {
    "objectID": "efficiency.html#the-trouble-with-optimization",
    "href": "efficiency.html#the-trouble-with-optimization",
    "title": "9  Efficiency Is the Enemy",
    "section": "9.3 The Trouble with Optimization",
    "text": "9.3 The Trouble with Optimization\nBro, what’s is your objective function? Better yet, what is your objective? Are you optimizing the thing you really care about or something you can measure easily? Is efficiency really all it’s cracked up to be? Do trade-offs actually trade off? Or are they actually constraints (i.e., non-fungible). Trade-offs only make sense if you’ve accounted for all the sinks.\nWhen your optimization problem is ill-posed, you will get a garbage answer.\nBrian Arthur: “Where a problem is ill-defined, optimizing behavior is also ill-defined; and so ‘acting less than optimally’ is not defined.” (Arthur 2021: 6)\n\n9.3.1 Optimization Culture\n(Clearly need to greatly expand this section.)\nSilicon Valley Tech Bros are really into “optimization.” Their practices raise serious questions about whether they actually understand what it means to optimize.\nRelevance of work of Elizabeth Popp Berman (2022), Thinking Like an Economist, in which she shows that the discipline of economics transitioned from a focus equity to a focus on efficiency (Berman 2022).\nWajcman: Technological change is frequently couched in terms of time-saving, but just as frequently leads to more work! American workers work longer hours than ever, despite (or maybe because of) the innovations of the internet, remote work, etc.\nKeynes (1936) “Practical men, who believe themselves quite exempt from any intellectual influence, are usually the slaves of some defunct economist.”\n\n\n9.3.2 “Efficiency” Über Alles\nPerhaps the most famous example of this is Facebook founder and Meta CEO Mark Zuckerberg, who famously wore the same t-shirt every day. Why did Mark Zuckerberg wear the exact same t-shirt every day (until he had to start testifying before Congress)? He was quoted in The Independent as saying, “I really want to clear my life to make it so that I have to make as few decisions as possible about anything except how to best serve this community…I feel like I’m not doing my job if I spend any of my energy on things that are silly or frivolous about my life.”\nIn a post on the blog LessWrong, OpenAI CEO Sam Altman wrote on artificial general intelligence (AGI), “We want AGI to empower humanity to maximally flourish in the universe. We don’t expect the future to be an unqualified utopia, but we want to maximize the good and minimize the bad, and for AGI to be an amplifier of humanity.”\nEmpower humanity to maximally flourish in the universe, eh? What’s the objective function?\nWhat is “an amplifier of humanity”? Which part, exactly, are we amplifying?\n\n\n9.3.3 Biohacking Tech Bros\nIn 2006, The New York Times profiled tech figure Mike Linksvayer, who consumed less than 1000 kcal/day to promote longevity, based on a belief that caloric restriction would lead to slowed aging. The accompanying photo shows the man looking dead-eyed and skeletal as he poses with his daily salad.\nRob Rhinehart, inventor of Soylent, a nutritional supplement (?) that “frees” coders from the need to get up from their desks to feed themselves—truly the embodiment of Silicon Valley optimization culture—noted that flush toilets use enormous quantities of water. He decided that he needed a way to make it unnecessary. He wrote “Feces are almost entirely deceased gut bacteria and water. I massacred my gut bacteria the day before by consuming a DIY Soylent version with no fiber and taking 500mg of Rifaximin, an antibiotic with poor bioavailability, meaning it stays in your gut and kills bacteria. Soylent’s microbiome consultant advised that this is a terrible idea so I do not recommend it. However, it worked. Throughout the challenge I did not defecate.”\n\n\n9.3.4 Ego Depletion\nEgo depletion became a super-popular idea among a certain class of Americans.\nHowever, it seems like it is yet another non-replicable fad, possibly the flagship for this phenomenon!\nCarol Dweck and her colleagues (Job et al. 2013) showed that the physiologically-measurable ego depletion an individual experiences is a function of their beliefs about ego depletion!\nIs the capacity for decision-making a pie or is it a muscle? This appears to be particularly the case with ethical decision-making. The more you do it, the better you get at it (Friese et al. 2019).\nTerm coined by John Tierney\nClassic low-power/high-catchiness bit of pop psychology\nSeems to result from p-hacking.\nContrast to perspective of virtue ethics. Aristotle suggested that morality was like a muscle that needs to be exercised (apparently).\nIs ego depletion actually just transient cognitive fatigue? (Hurley ???? – homie should really put a date on his preprint!)\nHagger et al. (2016): “Meta-analysis of the studies revealed that the size of the ego-depletion effect was small with 95% confidence intervals (CIs) that encompassed zero” In contrast, Dang et al. (2021) do find a small but statistically significant ego-depletion effect in the Stroop effect.\nKoppel et al. (2019): “None of the studies revealed a significant effect of ego depletion on risk taking. Our findings cast further doubts about the ability of ego-depletion manipulations to affect actual behavior in experimental settings.”\n\n\n9.3.5 Priming\nPriming! So much hyperbole over ultimately weak science.\n\n\n9.3.6 Implicit Bias\nImplicit bias, an easy out for institutions. Why worry about instituting structural change when you can implement implicit-bias training for cheap?!\n\n\n9.3.7 Psychological Distance\nNo Evidence for Psychological Distance\nVan Lange and Huckelba (2021) suggest “To combat climate change, individuals, communities, and governments must work together to reduce the psychological distance of climate change and designate the future of the planet as the prime concern.”\nBut is that even true? Evidence suggest no.\n“Opinion polls show that most people actually perceive climate change as occurring now and close by. Seeing climate change as more distant does not necessarily result in less climate action, and reducing PD does not reliably increase climate action. Policymakers may develop ineffective climate action campaigns because of incorrect assumptions about PD.” (Valkengoed, Steg, and Perlaviciute 2023)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Efficiency Is the Enemy</span>"
    ]
  },
  {
    "objectID": "efficiency.html#the-ubiquity-of-confirmation-bias-in-optimization-culture",
    "href": "efficiency.html#the-ubiquity-of-confirmation-bias-in-optimization-culture",
    "title": "9  Efficiency Is the Enemy",
    "section": "9.4 The Ubiquity of Confirmation Bias in Optimization Culture",
    "text": "9.4 The Ubiquity of Confirmation Bias in Optimization Culture\nA commonality of both the biohacking and the social-psychology instantiations of optimization culture is the extreme credulousness of would-be optimizers toward very weak science.\nWhat these examples are illustrating is really just elaborate confirmation bias.\nAnother element of the culture is a rather vague application of Bayesian logic. If you hear someone talk about their “Bayesian Priors,” you are probably safe in assuming that they’re talking out their ass. The irony, of course, is that the same guys who promote ubiquitous optimization and claim to use Bayesian updating of their beliefs have incredibly informative priors that are largely insensitive to the actual information available.\nIf you have a reasonable prior for some phenomenon, weak evidence should not move it much.\nThis is related to the discussion of RAPPing in Chapter 1.\nThis, of course, raises the reasonable question: do people really have priors for these types of phenomena? Or is this just so much more bullshit?\n\n9.4.1 The Costs of Optimality\nBeing “optimal” sucks. Suppose your objective is to become maximally shredded. A person is shredded if they are first jacked, meaning have substantial muscle mass achieved through extensive resistance exercise, and then they reduce their body fat to the point that they reduce subcutaneous fat. This gives their body a highly-defined and vascular look that is sought out by bodybuilders.\nIt’s broadly understood that women have to do terrible things for the health/welfare to maintain socially-determined ideals. Turns out it’s pretty horrible to achieve (let alone maintain) what seems like an ostensibly healthier male masculine form. Listen, for example, to actors who have to get shredded for a role like a superhero. Literally, all these guys say something like “First, I called my friend Dwayne Johnson.”\nThey all talk about chicken, broccoli, and rice too. This is the classic body-builder meal. Doesn’t look so bad, but would you want to eat that seven times a day for weeks on end?",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Efficiency Is the Enemy</span>"
    ]
  },
  {
    "objectID": "efficiency.html#regression-to-the-mean",
    "href": "efficiency.html#regression-to-the-mean",
    "title": "9  Efficiency Is the Enemy",
    "section": "9.5 Regression to the Mean",
    "text": "9.5 Regression to the Mean\nIs this where this belongs?",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Efficiency Is the Enemy</span>"
    ]
  },
  {
    "objectID": "efficiency.html#objectives-not-objective-functions",
    "href": "efficiency.html#objectives-not-objective-functions",
    "title": "9  Efficiency Is the Enemy",
    "section": "9.6 Objectives, Not Objective Functions",
    "text": "9.6 Objectives, Not Objective Functions\nOptimization (strictly) requires an objective function, in addition to a choice set and constraints. From a technical standpoint, objective functions require completeness and strict transitivity (Debreu). Often what we want is not actually an objective function but simply, an objective. This objective should be well-defined and measurable. We should not default to things we don’t care about but can measure. Brings us back to Adaptive Management\n\n\n\n\nArthur, W. Brian. 2021. “Foundations of Complexity Economics.” Nature Reviews Physics 3 (2): 136–45. https://doi.org/10.1038/s42254-020-00273-3.\n\n\nBerman, E. P. 2022. Thinking Like an Economist: How Efficiency Replaced Equality in U.S. Public Policy. Princeton: Princeton University Press. https://books.google.com/books?id=KS49EAAAQBAJ.\n\n\nBoyd, Stephen, and Lieven Vandenberghe. 2004. Convex Optimization. Cambridge: Cambridge University Press. https://doi.org/10.1017/CBO9780511804441.\n\n\nDang, Junhua, Paul Barker, Anna Baumert, Margriet Bentvelzen, Elliot Berkman, Nita Buchholz, Jacek Buczny, et al. 2021. “A Multilab Replication of the Ego Depletion Effect.” Social Psychological and Personality Science 12 (1): 14–24. https://doi.org/10.1177/1948550619887702.\n\n\nFriese, Malte, David D. Loschelder, Karolin Gieseler, Julius Frankenbach, and Michael Inzlicht. 2019. “Is Ego Depletion Real? An Analysis of Arguments.” Personality and Social Psychology Review 23 (2): 107–31. https://doi.org/10.1177/1088868318762183.\n\n\nHagger, M. S., N. L. D. Chatzisarantis, H. Alberts, C. O. Anggono, C. Batailler, A. R. Birt, R. Brand, et al. 2016. “A Multilab Preregistered Replication of the Ego-Depletion Effect.” Perspectives on Psychological Science 11 (4): 546–73. https://doi.org/10.1177/1745691616652873.\n\n\nJob, Veronika, Gregory M. Walton, Katharina Bernecker, and Carol S. Dweck. 2013. “Beliefs about Willpower Determine the Impact of Glucose on Self-Control.” Proceedings of the National Academy of Sciences 110 (37): 14837–42. https://doi.org/10.1073/pnas.1313475110.\n\n\nKay, J. A., and M. A. King. 2020. Radical Uncertainty: Decision-Making Beyond the Numbers. W. W. Norton, Incorporated. https://books.google.com/books?id=1S1AxQEACAAJ.\n\n\nKeynes, J. M. 1936. The General Theory of Employment, Interest, and Money. London: Macmillon.\n\n\nKoppel, Lina, David Andersson, Daniel Västfjäll, and Gustav Tinghög. 2019. “No Effect of Ego Depletion on Risk Taking.” Scientific Reports 9 (1): 9724. https://doi.org/10.1038/s41598-019-46103-0.\n\n\nParker, Geoffrey A., and John Maynard Smith. 1990. “Optimality Theory in Evolutionary Biology.” Nature 348: 27–33. https://doi.org/10.1038/348027a0.\n\n\nSmith, Eric Alden. 1992. “Human Behavioral Ecology: I.” Evolutionary Anthropology 1 (1): 20–25. https://doi.org/10.1002/evan.1360010107.\n\n\nValkengoed, Anne M. van, Linda Steg, and Goda Perlaviciute. 2023. “The Psychological Distance of Climate Change Is Overestimated.” One Earth 6 (4): 362–91. https://doi.org/10.1016/j.oneear.2023.03.006.\n\n\nVan Lange, Paul A. M., and Anna L. Huckelba. 2021. “Psychological Distance: How to Make Climate Change Less Abstract and Closer to the Self.” Current Opinion in Psychology 42: 49–53. https://doi.org/10.1016/j.copsyc.2021.03.011.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Efficiency Is the Enemy</span>"
    ]
  },
  {
    "objectID": "robust.html",
    "href": "robust.html",
    "title": "10  The Structure of Successful Problem-Solving",
    "section": "",
    "text": "10.1 Subsistence Risk Management\nAs noted by Glynn Isaac in his classic work, the hearth, with its attendant central-place foraging is a perfect way of risk-pooling.\nWe tend to take central-place foraging for granted, but behavioral ecologists like Alistair Houston have noted the profound implications CPF has on optimal strategies.\nHBEs have noted that sharing the principle mechanism for managing risk in hunter-gatherers and other subsistence populations. Work by scholars such as Magdalena Hurtado, Elizabeth Cashdan, Kim Hill, Bruce Winterhalder, Hilly Kaplan, Polly Wiessner. Some development economists too. Scott (1977): “Safety First”; Lipton (1968): “Survival Algorithms”\nSharing reduces risk. When we calculate the variance of a portfolio of items (e.g., the contributions of multiple sharing partners), the variance of the constituent contributions is scaled by the product of pairwise weights. Since these weights will always be less than one, this has the effect of reducing the overall variance (as long as the covariance between these contributions is not too high).\nSo here, two individuals have their own means and standard deviations of their subsistence returns, but when they share, their joint mean is the weighted average of their respective production rates and the variance is typically smaller than either of their individual variances.\nIndividual foraging returns are random variables. The distribution of returns for individual \\(i\\) has mean \\(\\mu_i\\) and variance \\(\\sigma^2_i\\). In sharing with another individual \\(j\\), \\(i\\) contributes a fraction \\(0 \\leq w_i \\leq 1\\).\nPooled mean\n\\[ \\mu_{(i+j)} = w_i \\mu_i + (1-w_i) \\mu_j \\] Pooled variance\n\\[ s^2_{(i+j)} = w^2_i \\sigma^2_i + (1-w_i)^2 \\sigma^2_j + 2 w_i (1-w_i)\\, \\mathrm{Cov}(i,j) \\] ### Independence with Risk-Pooling\nIndividuals or small groups go out and forage. There are different levels of independence to these decisions. There is commonly a sexual division of labor, with women and men targeting resources of different average trophic level or expected risk/return. Furthermore, within each sex, individuals or small groups typically go out independently. A central place — something that is taken largely for granted among human foragers (Kelly 2013) — facilitates returning and broad-based sharing. This is the risk-pooling.\nSharing and exchange are the lifeblood of forager societies. As noted by Kaplan, Hill, and Hurtado (1990), food-sharing is the primary mechanism for risk management among foragers.\nThe classic portfolio formulation shows that the expected return on a portfolio is a horizontal parabola. For a given standard deviation (known as “volatility” in the finance literature) the parabola describes the maximum and minimum portfolio returns. Anything in between these extremes is also allowable. Obviously, we only care about the higher returns, so the upper branch of the parabola is the focus. This is known as the efficient frontier.\nThere are three assets plotted here (\\(r_1\\), \\(r_2\\), \\(r_3\\)) that define the efficient frontier. There are a number of portfolios we can calculate off of these. The minimum variance portfolio is the safest possible combination of \\(r_1\\), \\(r_2\\), and \\(r_3\\). Its expected return is quite low, but it has the lowest possible volatility associated with it.\nIf there is a certain asset (i.e., one with zero volatility), there is a special solution to the portfolio problem, known as the tangent portfolio because it is tangent to the efficient frontier. This portfolio provides the highest possible expected return for \\(r_1\\), \\(r_2\\), and \\(r_3\\) together with the certain asset.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Structure of Successful Problem-Solving</span>"
    ]
  },
  {
    "objectID": "robust.html#subsistence-risk-management",
    "href": "robust.html#subsistence-risk-management",
    "title": "10  The Structure of Successful Problem-Solving",
    "section": "",
    "text": "Portfolio efficient frontier\n\n\n\n\n\n10.1.1 Sharing Networks\nWhen people share food, they create networks — an aggregate of social relations.\nWhen we see a sharing network, does it actually manifest the structure a risk-minimizing network would predict? We can use sociometric techniques from social network analysis to answer this question.\nNetworks as risk-management. Dyadic exchange is a terrible way to manage risk. Traps, lack of diversification, etc.\nShort cyclic exchanges can be gamed\nGeneralized exchange: “Under generalized exchange, where gifts are univocal and givers are always givers, exploitation can take place only if actors explicitly reject the guiding norm of reciprocity. In this case, individuals or subgroups contemplating the exploitation of givers find little room for subtle action and thus face sanction from the entire group whose debt they have failed to repay.” (P. Bearman 1997)\nThere are good theoretical reasons to think that generalized exchange is the way to manage risk through food sharing. The key to generalized exchange actually functioning is the existence of long cycles, which, once established, make the system impossible to game strategically.\nGeneralized exchange exists in the ethnographic record (Kula ring, hxaro exchange) (Wiessner 1982; Cashdan 1985)\nThe basic building blocks of networks are triads. They are the simplest higher-order structure (e.g., subject to dyadic dependence).\nThe mechanism identified by Bearman et al. (2004) — and really an abundance of cyclical structures in general — will produce long cycles. This has been the general thinking among network theorists: generalized exchange requires and abundance of 030C triads and a social mechanism that generates these such as avoiding partner choices that result in short cycles.\nHowever, while the resulting networks certainly have long cycles, they would be terrible for risk management! We don’t see the connectance that Jennifer Dunne and colleagues note is so essential. There isn’t the functional redundancy that leads to stability in mutualistic ecological networks. Furthermore, these networks are brittle. Paths between individuals are easily disrupted if even a single person fails to behave as expected.\nWhat really matters for generalized exchange to work is the presence of long paths between key actors. Another way to ensure the existence of these is to have what is known as a giant component to the graph.\nSexual networks have very long chains (and occasional, improbably-large cycles) because of the simple rule that you don’t have sex with your partners’ partners’ partners (in a purely heterosexual network) or your partners’ partners more generally. Termed “chains of affection” by P. S. Bearman, Moody, and Stovel (2004).\nThe thing is, when a short cycle forms among agents who are part of a longer cycle, it breaks that long cycle, whereas transitive relations among the members of a long cycle do not. In short, we conclude that subsistence risk-management networks should take a core-periphery form. The only problem with this is that there are no real off-the-shelf tests for this.\nThere are a number of other desirable properties of transitivity, related to redundancy, giant-component formation, etc. We use Borgatti & Everett’s coreness measure to evaluate the core structure of food-sharing networks. Basically, measure the distribution of k-cores in the graph (where a k-core is defined as a subcomponent of graph \\(\\mathcal{G}\\) where all vertices have degree of at least \\(k\\)).\n\nrequire(igraph)\n## giant component\ngg &lt;- sample_gnp(n=200,p=1/200)\ngg1 &lt;- sample_gnp(n=200,p=1/100)\n\nplot(gg,vertex.size=5,vertex.color=\"cyan\", vertex.label=NA)\n\n\n\n\n\n\n\nplot(gg1,vertex.size=5,vertex.color=\"cyan\", vertex.label=NA)\n\n\n\n\n\n\n\n\nThese are homogenous Bernoulli graphs. The formation or large connected components can be helped along by the presence of certain structures/mechanisms. Two such mechanisms include degree heterogeneity and especially transitivity.\nThe structures that emerge from this transitive assembly of network ties are generally much more robust, with plenty of redundancy\nGiant component formation. For a random graph, when \\(p &gt; (1 + \\epsilon)/n\\) (for any \\(\\epsilon &gt; 0\\)), there is a high probability of the formation of a giant component.\nIn work with Elspeth Ready, following a quite extensive review of the concept of risk-management in networks, we concluded that the best form of risk-management for subsistence networks — from the several available — involves the construction of a core and the resulting periphery that comes attached to that core.\nWhat is core-periphery structure?\n\nConcentric layers of decreasing connectivity\nIt’s an idea that is surprisingly underdeveloped, even 22 years after Borgatti & Everett suggested in was a surprisingly-underdeveloped idea!\nCore interacts intensively; periphery can come and go\nThe substance of the periphery may matter a lot. For example, peripheral members of a sharing/exchange network may be people with strong ties to other communities and may be extremely important for communities’ security during extensive spatially/temporally autocorrelated crises\nCore-periphery structure leads to localization (heterogeneity of the L/R eigenvectors), which makes it more stable to perturbations",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Structure of Successful Problem-Solving</span>"
    ]
  },
  {
    "objectID": "robust.html#trade-off-between-optimality-and-robustness",
    "href": "robust.html#trade-off-between-optimality-and-robustness",
    "title": "10  The Structure of Successful Problem-Solving",
    "section": "10.2 Trade-Off Between Optimality and Robustness",
    "text": "10.2 Trade-Off Between Optimality and Robustness\nSchmid et al. (2022) recently made the important observation that optimality and robustness trade-off in a formal sense.\nFrom Barfield et al. (2011), the speed of evolution of a quantitative trait in a stage-structured population is:\n\\[\n\\Delta \\bar{z} = \\mathbf{G} \\sum_{i,j}\\frac{\\partial \\bar{\\lambda}}{\\partial \\bar{a}_{ij}} \\nabla_{\\bar{z}_{j}} \\bar{a}_{ij}\n\\tag{10.1}\\]\nwhere \\(\\nabla_{\\bar{z}_j}=(\\partial /\\left.\\partial \\bar{z}_1, \\partial / \\partial \\bar{z}_2, \\ldots, \\partial / \\partial \\bar{z}_m\\right)\\) is the gradient operator with respect to trait means at stage \\(j\\).\nWhat this shows is that the rate of evolution depends linearly on the sensitivities of \\(\\lambda\\), which the authors define as the inverse of the population’s demographic robustness.\nThat is a trait with higher sensitivity is less robust.\nFrom Tuljapurkar (1990):\n\\[\na = \\log(\\lambda) - \\frac{1}{2 \\lambda^2} \\left( \\frac{\\partial \\lambda}{\\partial \\bar{a}_{ij}} \\right)^2 \\sigma^2_{ij}\n\\tag{10.2}\\]\n“As a consequence, the demographic robustness of a species is inversely proportional to \\(\\partial{\\bar{\\lambda}}/ \\partial \\bar{a}_{ij}\\), with a higher sensitivity indicating a lower demographic robustness.”\nSo: 1. The rate of evolution is proportional to \\(\\partial{\\bar{\\lambda}}/ \\partial \\bar{a}_{ij}\\), but 2. Demographic robustness is inversely related to \\(\\partial{\\bar{\\lambda}}/ \\partial \\bar{a}_{ij}\\)\nHence, a trade-off.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Structure of Successful Problem-Solving</span>"
    ]
  },
  {
    "objectID": "robust.html#wicked-problems",
    "href": "robust.html#wicked-problems",
    "title": "10  The Structure of Successful Problem-Solving",
    "section": "10.3 Wicked Problems",
    "text": "10.3 Wicked Problems\nIn a stationary environment, where the mean and variance stay the same despite short-term variability, optimizing your decision-making based on your prior experience with the environment is a sound policy. However, in nonstationary environments, doing so can be a disaster. Nonstationary environments create what the psychologist Robin Hogarth called a wicked learning environment. In such environments, lessons that we learn from the past do not help us perform better. The economists John Kay & Mervin King note that when the learning environment is wicked “the application of the mathematics of probability is questionable and the results ambiguous.” In other words, in uncertain, wicked learning environments, maximization of something like expected utility, the primary tool of decision theory, economics, and planning won’t do us much good.\nNeed to approach learning/expertise/optimization/efficiency differently when learning environments are wicked.\nThe collected evolutionary lessons for adaptation suggest that we should promoting diversity in our potentially adaptive solutions. Under uncertainty — such as nonstationarity — the name of the game is robustness, not optimality. We should increase our tolerance for non-optimal solutions to problems if they contribute to the diversity of approaches. We should pursue policies that promote diversity, that generate hybridity, that add innovative peripheries to cohesive cores, and that increase autonomy for hotbeds of innovation.\nPopular approaches to societal problem-solving like effective altruism — where charities are ranked according to some criterion of effectiveness and donors are encouraged to contribute only to those ranked highest in the resulting league table — at best are likely to miss transformative adaptive solutions and at worst will inhibit their incubation and emergence.\nWhile we can learn a lot about adaptation and sustainability from looking at adaptations of the past and from economic and engineering studies of efficiency or optimality, this isn’t where the transformative ideas that we need to achieve sustainability are going to come from.\nExplore/exploit strategies.\n\n10.3.1 AI and Adaptation\nThis is clearly a way that people are going to lazily suggest we will adapt\nLLMs will always regress to the mean. Emily Bender talk\nAIs are likely to pursue narrow optimality criteria. Unclear how they will perform on either rugged fitness surfaces or on flat fitness surfaces.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Structure of Successful Problem-Solving</span>"
    ]
  },
  {
    "objectID": "robust.html#normal-accidents-theory",
    "href": "robust.html#normal-accidents-theory",
    "title": "10  The Structure of Successful Problem-Solving",
    "section": "10.4 Normal Accidents Theory",
    "text": "10.4 Normal Accidents Theory\nPerrow (1984) defines a “normal” accident as one that is inevitable in a high-complexity system. Three system features make a system susceptible to normal accidents:\n\nwhen the system is highly complex\nwhen the system is tightly coupled\nwhen there is possibility for catastrophic\n\nRedundancy is a fundamental strategy for minimizing catastrophic failures.\nSagan (2004) argues that redundancy in human systems can often backfire. There are three ways that it can do this:\n\nby making the system more complex\nby leading to overcompensation on the part of the human components of the system\nby leading to “social shirking”\n\nThis last problem is reminiscent of Bowles (2016) and the notion of moral crowding-out in social contracts.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Structure of Successful Problem-Solving</span>"
    ]
  },
  {
    "objectID": "robust.html#examples-of-efficiency-leading-to-brittleness",
    "href": "robust.html#examples-of-efficiency-leading-to-brittleness",
    "title": "10  The Structure of Successful Problem-Solving",
    "section": "10.5 Examples of Efficiency Leading to Brittleness",
    "text": "10.5 Examples of Efficiency Leading to Brittleness\nJust-In-Time Logistics (JIT) leads to tight coupling.\nSouthwest Airlines Supply-chain problems with the pandemic\n\n\n\n\nBearman, P. 1997. “Generalized Exchange.” American Journal of Sociology 102 (5): 1383–1415. https://doi.org/10.1086/231087.\n\n\nBearman, P. S., J. Moody, and K. Stovel. 2004. “Chains of Affection: The Structure of Adolescent Romantic and Sexual Networks.” American Journal of Sociology 110 (1): 44–91. https://doi.org/10.1086/386272.\n\n\nBowles, S. 2016. The Moral Economy: Why Good Incentives Are No Substitute for Good Citizens. Castle Lectures Series. New Haven: Yale University Press. https://books.google.com/books?id=Q7IODAAAQBAJ.\n\n\nCashdan, Elizabeth A. 1985. “Coping with Risk: Reciprocity Among the Basarwa of Northern Botswana.” Man 20 (3): 454–74. https://doi.org/10.2307/2802441.\n\n\nKaplan, H., K. Hill, and A. M. Hurtado. 1990. “Risk, Foraging, and Food Sharing Among the Ache.” In Risk and Uncertainty in Tribal and Peasant Societies, edited by E. Cashadan, 107–43. Coulder, CO: Westview Press.\n\n\nKelly, R. L. 2013. The Lifeways of Hunter-Gatherers: The Foraging Spectrum. Cambridge University Press. https://books.google.com/books?id=CDAWBQAAQBAJ.\n\n\nLipton, Michael. 1968. “Theory of Optimising Peasant.” Journal of Development Studies 4 (3): 327–51. https://doi.org/10.1080/00220386808421262.\n\n\nPerrow, C. 1984. Normal Accidents: Living with High Risk Technologies. Princeton: Princeton University Press. https://books.google.com/books?id=g66J6Vzq6EYC.\n\n\nSagan, Scott D. 2004. “The Problem of Redundancy Problem: Why More Nuclear Security Forces May Produce Less Nuclear Security.” Risk Analysis 24 (4): 935–46. https://doi.org/10.1111/j.0272-4332.2004.00495.x.\n\n\nSchmid, Max, Maria Paniw, Maarten Postuma, Arpat Ozgul, and Frédéric Guillaume. 2022. “A Trade-Off Between Robustness to Environmental Fluctuations and Speed of Evolution.” The American Naturalist 200 (1): E16–35. https://doi.org/10.1086/719654.\n\n\nScott, James C. 1977. The Moral Economy of the Peasant: Rebellion and Subsistence in Southeast Asia. New Haven: Yale University Press.\n\n\nTuljapurkar, S. 1990. Population Dynamics in Variable Environments. Vol. 85. Lecture Notes in Biomathematics. Berlin: Springer-Veralg.\n\n\nWiessner, P. 1982. “Risk, Reciprocity, and Social Influences on !Kung San Economics.” In Politics and History in Band Societies, edited by Eleanore Leacock and Richard B. Lee. Cambridge: Cambridge University Press.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>The Structure of Successful Problem-Solving</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Acemoglu, Daron. 2009. Introduction to Modern Economic Growth.\nPrinceton: Princeton University Press.\n\n\nAinslie, G. 1975. “Specious Reward: Behavioral Theory of\nImpulsiveness and Impulse Control.” Psychological\nBulletin 82 (4): 463–96. https://doi.org/10.1037/h0076860.\n\n\nAlland, Alexander. 1975. “Adaptation.” Annual Review of\nAnthropology 4 (1): 59–73. https://doi.org/10.1146/annurev.an.04.100175.000423.\n\n\nAlvard, Michael S. 2003. “The Adaptive Nature of Culture.”\nEvolutionary Anthropology 12 (3): 136–49. https://doi.org/10.1002/evan.10109.\n\n\nAnderies, John M. 1996. “An Adaptive Model for Predicting\n!Kung Reproductive Performance: A Stochastic Dynamic\nProgramming Approach.” Ethology and Sociobiology 17 (4):\n221–45. https://doi.org/10.1016/0162-3095(96)00037-4.\n\n\nAriely, D. 2008. Predictably Irrational: The Hidden Forces That\nShape Our Decisions. New York: HarperCollins.\n\n\nArrow, K. J. 1965. Aspects of the Theory of Risk-Bearing.\nHelsinki: Yrjö Hahnsson Foundation.\n\n\nArthur, W. Brian. 2021. “Foundations of Complexity\nEconomics.” Nature Reviews Physics 3 (2): 136–45. https://doi.org/10.1038/s42254-020-00273-3.\n\n\nBanner, Stuart. 2018. “The Banality of the Commons: Efficiency\nArguments Against Common Ownership Before Hardin.”\nTheoretical Inquiries in Law 19 (2): 395–407. https://doi.org/10.1515/til-2018-0021.\n\n\nBearman, P. 1997. “Generalized Exchange.” American\nJournal of Sociology 102 (5): 1383–1415. https://doi.org/10.1086/231087.\n\n\nBearman, P. S., J. Moody, and K. Stovel. 2004. “Chains of\nAffection: The Structure of Adolescent Romantic and Sexual\nNetworks.” American Journal of Sociology 110 (1): 44–91.\nhttps://doi.org/10.1086/386272.\n\n\nBennett, J. W. 1976. “Anticipation, Adaptation, and Concept of\nCulture in Anthropology.” Science 192 (4242): 847–53. https://doi.org/10.1126/science.192.4242.847.\n\n\nBerman, E. P. 2022. Thinking Like an Economist: How Efficiency\nReplaced Equality in U.S. Public Policy. Princeton:\nPrinceton University Press. https://books.google.com/books?id=KS49EAAAQBAJ.\n\n\nBird, R. B., D. W. Bird, E. A. Smith, and G. C. Kushnick. 2002.\n“Risk and Reciprocity in Meriam Food Sharing.”\nEvolution and Human Behavior 23 (4): 297–321. https://doi.org/10.1016/S1090-5138(02)00098-3.\n\n\nBird, R. B., and E. A. Smith. 2005. “Signaling Theory, Strategic\nInteraction, and Symbolic Capital.” Current Anthropology\n46 (2): 221–48. https://doi.org/10.1086/427115.\n\n\nBird, R. B., E. A. Smith, and D. W. Bird. 2001. “The Hunting\nHandicap: Costly Signaling in Human Foraging Strategies.”\nBehavioral Ecology and Sociobiology 50 (1): 9–19. https://doi.org/10.1007/s002650100338.\n\n\nBird, Rebecca Bliege. 1999. “Cooperation and Conflict: The\nBehavioral Ecology of the Sexual Division of Labor.”\nEvolutionary Anthropology 8 (2): 65–75. https://doi.org/10.1002/(SICI)1520-6505(1999)8:2&lt;65::AID-EVAN5&gt;3.0.CO;2-3.\n\n\nBowden, Rory, Tammie S. MacFie, Simon Myers, Garrett Hellenthal, Eric\nNerrienet, Ronald E. Bontrop, Colin Freeman, Peter Donnelly, and\nNicholas I. Mundy. 2012. “Genomic Tools for Evolution and\nConservation in the Chimpanzee: Pan Troglodytes\nEllioti Is a Genetically Distinct Population.”\nPLOS Genetics 8 (3): e1002504. https://doi.org/10.1371/journal.pgen.1002504.\n\n\nBowles, S. 2016. The Moral Economy: Why Good Incentives Are No\nSubstitute for Good Citizens. Castle Lectures Series. New Haven:\nYale University Press. https://books.google.com/books?id=Q7IODAAAQBAJ.\n\n\nBradley, Valerie C., Shiro Kuriwaki, Michael Isakov, Dino Sejdinovic,\nXiao-Li Meng, and Seth Flaxman. 2021. “Unrepresentative Big\nSurveys Significantly Overestimated US Vaccine\nUptake.” Nature 600 (7890): 695–700. https://doi.org/10.1038/s41586-021-04198-4.\n\n\nBrown, R. A., and G. J. Armelagos. 2001. “Apportionment of Racial\nDiversity: A Review.” Evolutionary Anthropology 10:\n34–40. https://doi.org/10.1002/1520-6505(2001)10:1&lt;34::AID-EVAN1011&gt;3.0.CO;2-P.\n\n\nCashdan, Elizabeth A. 1985. “Coping with Risk: Reciprocity Among\nthe Basarwa of Northern Botswana.”\nMan 20 (3): 454–74. https://doi.org/10.2307/2802441.\n\n\nCaswell, H. 2001. Matrix Population Models: Construction, Analysis\nand Interpretation. 2nd ed. Sunderland, MA: Sinauer.\n\n\nCaswell, Hal. 1978. “A General Formula for the Sensitivity of\nPopulation Growth Rate to Changes in Life History Parameters.”\nTheoretical Population Biology 14 (2): 215–30. https://doi.org/10.1016/0040-5809(78)90025-4.\n\n\nClark, C. W., and M. Mangel. 2000. Dynamic State Variable Models in\nEcology. New York: Oxford University Press.\n\n\nCoale, A. 1974. “The History of Human Population.”\nScientific American 231 (40-51).\n\n\nCohen, J. E. 1996. How Many People Can the Earth Support? New\nYork: Norton.\n\n\nCohen, M. N. 1989. Health and the Rise of Civilization. New\nHaven: Yale University Press.\n\n\nCohen, M. N., G. J. Armelagos, and C. S. Larsen. 1984.\nPaleopathology at the Origins of Agriculture. Orlando, FL:\nAcademic Press.\n\n\nCole, L. C. 1954. “The Population Consequences of Life History\nPhenomena.” Quarterly Review of Biology 29 (2): 103–37.\nhttp://www.jstor.org/stable/2817654.\n\n\nCosmides, Leda, and John Tooby. 1996. “Are Humans Good Intuitive\nStatisticians After All? Rethinking Some Conclusions from the Literature\non Judgment Under Uncertainty.” Cognition 58 (1): 1–73.\nhttps://doi.org/10.1016/0010-0277(95)00664-8.\n\n\nCrabtree, Stefani A., Douglas W. Bird, and Rebecca Bliege Bird. 2019.\n“Subsistence Transitions and the Simplification of Ecological\nNetworks in the Western Desert of\nAustralia.” Human Ecology 47 (2): 165–77. https://doi.org/10.1007/s10745-019-0053-z.\n\n\nCrook, John H., and Stamati J. Crook. 1988. “Tibetan Polyandry:\nProblems of Adaptation and Fitness.” In Human Reproductive\nBehavior, edited by L. Betzig, M. Borgerhoff Mulder, and P. W.\nTurke, 97–114. Cambridge: Cambridge University Press.\n\n\nDaly, Martin, and Margo I. Wilson. 1999. “Human Evolutionary\nPsychology and Animal Behaviour.” Animal Behaviour 57\n(3): 509–19. https://doi.org/10.1006/anbe.1998.1027.\n\n\nDang, Junhua, Paul Barker, Anna Baumert, Margriet Bentvelzen, Elliot\nBerkman, Nita Buchholz, Jacek Buczny, et al. 2021. “A Multilab\nReplication of the Ego Depletion Effect.” Social\nPsychological and Personality Science 12 (1): 14–24. https://doi.org/10.1177/1948550619887702.\n\n\nDasgupta, P. 2008. “Discounting Climate Change.”\nJournal of Risk and Uncertainty 37 (2-3): 141–69. https://doi.org/10.1007/s11166-008-9049-6.\n\n\nDasgupta, Partha S. 2001. Human Well-Being and the Natural\nEnvironment. Oxford: Oxford University Press. https://books.google.com/books?id=5Je4AAAAIAAJ.\n\n\nDasgupta, P., and E. Maskin. 2005. “Uncertainty and Hyperbolic\nDiscounting.” American Economic Review 95 (4): 1290–99.\nhttps://doi.org/10.1257/0002828054825637.\n\n\ndeMenocal, Peter, Joseph Ortiz, Tom Guilderson, Jess Adkins, Michael\nSarnthein, Linda Baker, and Martha Yarusinsky. 2000. “Abrupt Onset\nand Termination of the African Humid Period: Rapid Climate\nResponses to Gradual Insolation Forcing.” Quaternary Science\nReviews 19 (1): 347–61. https://doi.org/10.1016/S0277-3791(99)00081-5.\n\n\nDriscoll, C., and S. Stich. 2008. “Vayda Blues: Explanation in\nDarwinian Ecological Anthropology.” In Against the Grain: The\nVayda Tradition in Human Ecology and Ecological Anthropology,\nedited by B. Walters, B. McCay, P. West, and S. Lees, 175–91. Lanham,\nMD: AltaMira Press.\n\n\nDunne, Jennifer A., Herbert Maschner, Matthew W. Betts, Nancy Huntly,\nRoly Russell, Richard J. Williams, and Spencer A. Wood. 2016. “The\nRoles and Impacts of Human Hunter-Gatherers in North\nPacific Marine Food Webs.” Scientific Reports 6\n(1): 21179. https://doi.org/10.1038/srep21179.\n\n\nEdwards, R. D., and S. Tuljapurkar. 2005. “Inequality in Life\nSpans and a New Perspective on Mortality Convergence Across\nIndustrialized Countries.” Population and Development\nReview 31 (4): 645–74. https://www.jstor.org/stable/3401520.\n\n\nEisenberg, Eric M. 1984. “Ambiguity as Strategy in Organizational\nCommunication.” Communication Monographs 51 (3): 227–42.\nhttps://doi.org/10.1080/03637758409390197.\n\n\nEndler, J. A. 1986. Natural Selection in the Wild. Princeton:\nPrinceton University Press. https://books.google.com/books?id=MYk1XbelDssC.\n\n\nEnquist, Magnus, Kimmo Eriksson, and Stefano Ghirlanda. 2007.\n“Critical Social Learning: A Solution to Rogers’s Paradox of\nNonadaptive Culture.” American Anthropologist 109 (4):\n727–34. http://www.jstor.org/stable/27563823.\n\n\nEvans, Matthew R., Volker Grimm, Karin Johst, Tarja Knuuttila, Rogier de\nLanghe, Catherine M. Lessells, Martina Merz, et al. 2013. “Do\nSimple Models Lead to Generality in Ecology?” Trends in\nEcology & Evolution 28 (10): 578–83. https://doi.org/10.1016/j.tree.2013.05.022.\n\n\nFoley, Robert. 1995. “The Adaptive Legacy of Human Evolution: A\nSearch for the Environment of Evolutionary Adaptedness.”\nEvolutionary Anthropology 4 (6): 194–203. https://doi.org/10.1002/evan.1360040603.\n\n\nFrankenhuis, Willem, Karthik Panchanathan, and Paul E Smaldino. 2022.\n“Strategic Ambiguity in the Social Sciences.” MetaArXiv. https://doi.org/10.31222/osf.io/kep5b.\n\n\nFriedman, M., and L. J. Savage. 1948. “The\nUtility Analysis of Choices Involving Risk.” The\nJournal of Political Economy 56 (4): 279–304. https://doi.org/10.1086/256692.\n\n\nFriese, Malte, David D. Loschelder, Karolin Gieseler, Julius\nFrankenbach, and Michael Inzlicht. 2019. “Is Ego Depletion Real?\nAn Analysis of Arguments.” Personality and Social Psychology\nReview 23 (2): 107–31. https://doi.org/10.1177/1088868318762183.\n\n\nFutuyma, D. J. 2013. Evolution. 3rd ed. Sunderland, MA: Sinauer\nAssociates. https://books.google.com/books?id=YkrRlwEACAAJ.\n\n\nGagneux, Pascal, Christopher Wills, Ulrike Gerloff, Diethard Tautz,\nPhillip A. Morin, Christophe Boesch, Barbara Fruth, Gottfried Hohmann,\nOliver A. Ryder, and David S. Woodruff. 1999. “Mitochondrial\nSequences Show Diverse Evolutionary Histories of African\nHominoids.” Proceedings of the National Academy of\nSciences 96 (9): 5077–82. https://doi.org/10.1073/pnas.96.9.5077.\n\n\nGeertz, Clifford. 1973. The Interpretation of Cultures. New\nYork: Basic Books.\n\n\nGeweke, John. 2001. “A Note on Some Limitations of CRRA\nUtility.” Economics Letters 71 (3): 341–45. https://doi.org/10.1016/S0165-1765(01)00391-3.\n\n\nGibson, M. A., and D. W. Lawson. 2014. Applied Evolutionary\nAnthropology: Darwinian Approaches to Contemporary World Issues.\nSpringer New York. https://books.google.com/books?id=xAS9BAAAQBAJ.\n\n\nGigerenzer, Gerd. 1991. “How to Make Cognitive Illusions\nDisappear: Beyond ‘Heuristics and Biases’.”\nEuropean Review of Social Psychology 2 (1): 83–115. https://doi.org/10.1080/14792779143000033.\n\n\nGintis, H. 2007. “A Framework for the Unification of the\nBehavioral Sciences.” Behavioral and Brain Sciences 30\n(1): 1–61. https://doi.org/10.1017/S0140525X07000581.\n\n\nGollier, Christian. 2013. Pricing the Planet’s Future: The Economics\nof Discounting in an Uncertain World. Princeton: Princeton\nUniversity Press.\n\n\nGoodman, M. 1963. “Man’s Place in the Phylogeny of the Primates as\nReflected in Serum Proteins.” In Classification and Human\nEvolu­tion, edited by S. L. Washburn, 204–34. Chicago: Aldine.\n\n\nGould, S. J., and R. C. Lewontin. 1979. “Spandrels of San Marco and the Panglossian Paradigm: A Critique\nof the Adaptationist Program.” Proceedings of the Royal\nSociety Series B-Biological Sciences 205 (1161): 581–98. https://doi.org/10.1098/rspb.1979.0086.\n\n\nGunawardena, Jeremy. 2014. “Models in Biology: ‘Accurate\nDescriptions of Our Pathetic Thinking’.” BMC\nBiology 12 (1): 29. https://doi.org/10.1186/1741-7007-12-29.\n\n\nGuttal, Vishwesha, and Ciriyam Jayaprakash. 2008. “Changing\nSkewness: An Early Warning Signal of Regime Shifts in\nEcosystems.” Ecology Letters 11 (5): 450–60. https://doi.org/10.1111/j.1461-0248.2008.01160.x.\n\n\nHadfield, J. D., A. Nutall, D. Osorio, and I. P. F. Owens. 2007.\n“Testing the Phenotypic Gambit: Phenotypic, Genetic and\nEnvironmental Correlations of Colour.” Journal of\nEvolutionary Biology 20 (2): 549–57. https://doi.org/10.1111/j.1420-9101.2006.01262.x.\n\n\nHagger, M. S., N. L. D. Chatzisarantis, H. Alberts, C. O. Anggono, C.\nBatailler, A. R. Birt, R. Brand, et al. 2016. “A Multilab\nPreregistered Replication of the Ego-Depletion Effect.”\nPerspectives on Psychological Science 11 (4): 546–73. https://doi.org/10.1177/1745691616652873.\n\n\nHalevy, Yoram. 2008. “Strotz Meets Allais: Diminishing Impatience\nand the Certainty Effect.” American Economic Review 98\n(3): 1145–62. https://doi.org/10.1257/aer.98.3.1145.\n\n\nHastings, Alan, and Thomas Powell. 1991. “Chaos in a Three-Species\nFood Chain.” Ecology 72 (3): 896–903. https://doi.org/10.2307/1940591.\n\n\nHawkes, Kristen. 1991. “Showing Off: Tests of an Hypothesis about\nMen’s Foraging Goals.” Ethology and Sociobiology 12 (1):\n29–54. https://doi.org/10.1016/0162-3095(91)90011-E.\n\n\nHawkes, Kristen, Kim Hill, and James F. O’connell. 1982. “Why\nHunters Gather: Optimal Foraging and the Aché of Eastern\nParaguay.” American Ethnologist 9 (2):\n379–98. https://doi.org/10.1525/ae.1982.9.2.02a00100.\n\n\nHealy, Kieran. 2017. “Fuck Nuance.” Sociological\nTheory 35 (2): 118–27. https://doi.org/10.1177/0735275117709046.\n\n\nHenrich, J., and R. Boyd. 1998. “The Evolution of Conformist\nTransmission and the Emergence of Between-Group Differences.”\nEvolution and Human Behavior 19 (4): 215–41. https://doi.org/10.1016/S1090-5138(98)00018-X.\n\n\nHenrich, Joseph, Steven J. Heine, and Ara Norenzayan. 2010. “The\nWeirdest People in the World?” Behavioral and Brain\nSciences 33 (2-3): 61–135. https://doi.org/10.1017/s0140525x0999152x.\n\n\nHenrich, Joseph, and Richard McElreath. 2003. “The Evolution of\nCultural Evolution.” Evolutionary Anthropology 12 (3):\n123–35. https://doi.org/10.1002/evan.10110.\n\n\nHilborn, R., and M. Mangel. 1997. The Ecological Detective:\nConfronting Models with Data. Princeton: Princeton University\nPress.\n\n\nHill, K., and A. M. Hurtado. 1996. Ache Life History. New York:\nAldine de Gruyter.\n\n\nHolling, C. S. 1964. “The Analysis of Complex Population\nProcesses.” The Canadian Entomologist 96 (1-2): 335–47.\nhttps://doi.org/10.4039/Ent96335-1.\n\n\n———. 1966. “The Strategy of Building Models of Complex Ecological\nSystems.” In Systems Analysis in Ecology, edited by\nKenneth E. F. Watt, 195–214. Academic Press. https://doi.org/10.1016/B978-1-4832-3283-6.50014-5.\n\n\n———. 1978. Adaptive Environmental Assessment and Management.\nNew York: Wiley. https://books.google.com/books?id=1InvPAAACAAJ.\n\n\nIrons, W. 1990. “Let’s Make Our Perspective Broader Rather Than\nNarrower: A Comment on Turke Which Humans Behave\nAdaptively, and Why Does It Matter and on the so-Called\nDA-DP Debate.” Ethology and Sociobiology 11\n(4-5): 361–74. https://doi.org/10.1016/0162-3095(90)90016-Y.\n\n\nJob, Veronika, Gregory M. Walton, Katharina Bernecker, and Carol S.\nDweck. 2013. “Beliefs about Willpower Determine the Impact of\nGlucose on Self-Control.” Proceedings of the National Academy\nof Sciences 110 (37): 14837–42. https://doi.org/10.1073/pnas.1313475110.\n\n\nJohnson, Douglas L. 1993. “Nomadism and Desertification in Africa\nand the Middle East.” GeoJournal 31 (1): 51–66. https://doi.org/10.1007/BF00815903.\n\n\nJones, J. H. 2009. “The Force of Selection on the Human Life\nCycle.” Evolution and Human Behavior 30 (5): 305–14. https://doi.org/10.1016/j.evolhumbehav.2009.01.005.\n\n\nJones, J. H., and R. Bliege Bird. 2014. “The Marginal Valuation of\nFertility.” Evolution and Human Behavior 35 (1): 65–71.\nhttps://doi.org/10.1016/j.evolhumbehav.2013.10.002.\n\n\nJones, James Holland, Rebecca Bliege Bird, and Douglas W. Bird. 2013.\n“To Kill a Kangaroo: Understanding the Decision to Pursue\nHigh-Risk/High-Gain Resources.” Proceedings of the Royal\nSociety B: Biological Sciences 280 (1767): 20131210. https://doi.org/10.1098/rspb.2013.1210.\n\n\nJones, James Holland, Elspeth Ready, and Anne C. Pisor. 2020.\n“Want Climate-Change Adaptation? Evolutionary Theory Can\nHelp.” American Journal of Human Biology 33 (4): e23539.\nhttps://doi.org/10.1002/ajhb.23539.\n\n\nKahneman, Daniel, and Amos Tversky. 1973. “On the Psychology of\nPrediction.” Psychological Review 80 (4): 237–51. https://doi.org/10.1037/h0034747.\n\n\nKaplan, H., and K. Hill. 1992. “The Evolutionary Ecology of Food\nAcquisition.” In Evolutionary Ecology and Human\nBehavior, edited by E. A. Smith and B. Winterhalder, 167–201.\nHawthorne, NY: Aldine de Gruyter.\n\n\nKaplan, H., K. Hill, and A. M. Hurtado. 1990. “Risk, Foraging, and\nFood Sharing Among the Ache.” In Risk and\nUncertainty in Tribal and Peasant Societies, edited by E. Cashadan,\n107–43. Coulder, CO: Westview Press.\n\n\nKaplan, H., K. Hill, J. Lancaster, and A. M. Hurtado. 2000. “A\nTheory of Human Life History Evolution: Diet, Intelligence, and\nLongevity.” Evolutionary Anthropology 9 (4): 156–85. https://doi.org/10.1002/1520-6505(2000)9:4&lt;156::AID-EVAN5&gt;3.0.CO;2-7.\n\n\nKay, J. A., and M. A. King. 2020. Radical Uncertainty:\nDecision-Making Beyond the Numbers. W. W. Norton, Incorporated. https://books.google.com/books?id=1S1AxQEACAAJ.\n\n\nKelly, R. L. 2013. The Lifeways of Hunter-Gatherers: The Foraging\nSpectrum. Cambridge University Press. https://books.google.com/books?id=CDAWBQAAQBAJ.\n\n\nKeyfitz, N. 1977. Introduction to the Mathematics of\nPopulations. 2nd ed. Menlo Park: Addison-Wesley.\n\n\nKeynes, J. M. 1936. The General Theory of Employment, Interest, and\nMoney. London: Macmillon.\n\n\nKollock, Peter. 1998. “Social Dilemmas: The Anatomy of\nCooperation.” Annual Review of Sociology 24 (1):\n183–214. https://doi.org/10.1146/annurev.soc.24.1.183.\n\n\nKoopmans, Tjalling C. 1960. “Stationary Ordinal Utility and\nImpatience.” Econometrica 28 (2): 287–309. https://doi.org/10.2307/1907722.\n\n\nKoppel, Lina, David Andersson, Daniel Västfjäll, and Gustav Tinghög.\n2019. “No Effect of Ego Depletion on Risk Taking.”\nScientific Reports 9 (1): 9724. https://doi.org/10.1038/s41598-019-46103-0.\n\n\nKuznar, L. 2002. “On Risk-Prone Peasants: Cultural Transmission or\nSigmoid Utility Maximization?” Current Anthropology 43\n(5): 787–89. https://doi.org/10.1086/344370.\n\n\nKuznar, L. A., and W. G. Frederick. 2003. “Environmental\nConstraints and Sigmoid Utility: Implications for Value, Risk\nSensitivity, and Social Status.” Ecological Economics 46\n(2): 293–306. https://doi.org/10.1016/S0921-8009(03)00167-8.\n\n\nLaibson, David. 1997. “Golden Eggs and Hyperbolic\nDiscounting.” The Quarterly Journal of Economics 112\n(2): 443–78. https://doi.org/10.1162/003355397555253.\n\n\nLaland, Kevin N., and Gillian R. Brown. 2002. Sense and Nonsense:\nEvolutionary Perspectives on Human Behaviour. New York: Oxford\nUniversity Press.\n\n\nLande, Russell. 1979. “Quantitative Genetic Analysis of\nMultivariate Evolution, Applied to Brain:body Size Allometry.”\nEvolution 33 (1): 402–16. https://doi.org/10.1111/j.1558-5646.1979.tb04694.x.\n\n\nLansing, John Stephen. 1991. Priests and Programmers : Technologies\nof Power in the Engineered Landscape of Bali.\nPrinceton, NJ: Princeton University Press.\n\n\nLasker, Gabriel W. 1969. “Human Biological Adaptability.”\nScience 166 (3912): 1480–86. https://doi.org/10.1126/science.166.3912.1480.\n\n\nLee, Charlotte T., and Shripad Tuljapurkar. 2008. “Population and\nPrehistory I: Food-Dependent Population Growth in Constant\nEnvironments.” Theoretical Population Biology 73 (4):\n473–82. https://doi.org/10.1016/j.tpb.2008.03.001.\n\n\nLee, Ronald D. 1986. “Malthus and\nBoserup: A Dynamic Synthesis.” In The State of\nPopulation Theory, edited by D. Coleman and R. Schofield, 96–130.\nNew York: Blackwell.\n\n\nLehman, John T. 1986. “The Goal of Understanding in\nLimnology.” Limnology and Oceanography 31 (5): 1160–66.\nhttps://doi.org/10.4319/lo.1986.31.5.1160.\n\n\nLeslie, P., and B. Winterhalder. 2002. “Demographic Consequences\nof Unpredictability in Fertility Outcomes.” American Journal\nof Human Biology 14 (2): 168–83. https://doi.org/10.1002/ajhb.10044.\n\n\nLevins, Richard. 1966. “The Strategy of Model Building in\nPopulation Biology.” American Scientist 54 (4): 421–31.\nhttp://www.jstor.org/stable/27836590.\n\n\nLewis, Anna C. F., Santiago J. Molina, Paul S. Appelbaum, Bege Dauda,\nAnna Di Rienzo, Agustin Fuentes, Stephanie M. Fullerton, et al. 2022.\n“Getting Genetic Ancestry Right for Science and Society.”\nScience 376 (6590): 250–52. https://doi.org/10.1126/science.abm7530.\n\n\nLewontin, R. C. 1972. “The Apportionment of Human\nDiversity.” In Evolutionary Biology: Volume 6, edited by\nTheodosius Dobzhansky, Max K. Hecht, and William C. Steere, 381–98. New\nYork, NY: Springer US. https://doi.org/10.1007/978-1-4684-9063-3_14.\n\n\n———. 1978. “Adaptation.” Scientific American 239\n(9): 212–30. https://doi.org/10.1038/scientificamerican0978-212.\n\n\nLipton, Michael. 1968. “Theory of Optimising Peasant.”\nJournal of Development Studies 4 (3): 327–51. https://doi.org/10.1080/00220386808421262.\n\n\nLoewenstein, George, and Drazen Prelec. 1992. “Anomalies in\nIntertemporal Choice: Evidence and an Interpretation.” The\nQuarterly Journal of Economics 107 (2): 573–97. https://doi.org/10.2307/2118482.\n\n\nLovejoy, C. Owen. 1981. “The Origin of Man.”\nScience 211 (4480): 341–50. https://doi.org/10.1126/science.211.4480.341.\n\n\nMacArthur, Robert H., and Eric R. Pianka. 1966. “On Optimal Use of\na Patchy Environment.” The American Naturalist 100\n(916): 603–9. http://www.jstor.org/stable/2459298.\n\n\nMace, Ruth. 1993. “Nomadic Pastoralists Adopt Subsistence\nStrategies That Maximise Long-Term Household Survival.”\nBehavioral Ecology and Sociobiology 33 (5): 329–34. https://doi.org/10.1007/BF00172931.\n\n\nMangel, M., and C. W. Clark. 1988. Dynamic Modeling in Behavioral\nEcology. Monographs in Behavior and Ecology. Princeton: Princeton\nUniversity Press.\n\n\nMay, R. M. 1973. Stability and Complexity in Model Ecosystems.\nPrinceton: Princeton University Press.\n\n\n———. 1976. “Simple Mathematical-Models with Very Complicated\nDynamics.” Nature 261 (5560): 459–67. https://doi.org/10.1038/261459a0.\n\n\n———. 1977. “Thresholds and Breakpoints in Ecosystems with a\nMultiplicity of Stable States.” Nature 269 (5628):\n471–77. https://doi.org/10.1038/269471a0.\n\n\nMay, R. M., and N. Arinaminpathy. 2010. “Systemic Risk: The\nDynamics of Model Banking Systems.” Journal of The Royal\nSociety Interface 7 (46): 823–38. https://doi.org/10.1098/rsif.2009.0359.\n\n\nMay, R. M., S. A. Levin, and G. Sugihara. 2008. “Complex Systems:\nEcology for Bankers.” Nature 451 (7181): 893–95. https://doi.org/10.1038/451893a.\n\n\nMaynard Smith, John. 1978. “Optimization Theory in\nEvolution.” Annual Review of Ecology and Systematics 9\n(1): 31–56. https://doi.org/10.1146/annurev.es.09.110178.000335.\n\n\nMayr, E. 1982. The Growth of Biological Thought. Cambridge:\nBelknap.\n\n\nMcCann, K., A. Hastings, and G. R. Huxel. 1998. “Weak Trophic\nInteractions and the Balance of Nature.” Nature 395:\n794–98. https://doi.org/10.1038/27427.\n\n\nMcElreath, Richard, Mark Lubell, Peter J. Richerson, Timothy M. Waring,\nWilliam Baum, Edward Edsten, Charles Efferson, and Brian Paciotti. 2005.\n“Applying Evolutionary Models to the Laboratory Study of Social\nLearning.” Evolution and Human Behavior 26 (6): 483–508.\nhttps://doi.org/10.1016/j.evolhumbehav.2005.04.003.\n\n\nMeng, Xiao-Li. 2018. “Statistical Paradises and Paradoxes in Big\nData (I): Law of Large Populations, Big Data Paradox, and\nthe 2016 US Presidential Election.” Annals of\nApplied Statistics 12 (2): 685–726. https://doi.org/10.1214/18-AOAS1161SF.\n\n\nMilner-Gulland, E. J., Ruth Mace, and Ian Scoones. 1996. “A Model\nof Household Decisions in Dryland Agropastoral Systems.”\nAgricultural Systems 51 (4): 407–30. https://doi.org/10.1016/0308-521X(95)00057-C.\n\n\nMoritz, Mark, Roy Behnke, Christine M. Beitl, Rebecca Bliege Bird,\nRafael Morais Chiaravalloti, Julia K. Clark, Stefani A. Crabtree, et al.\n2018. “Emergent Sustainability in Open Property Regimes.”\nProceedings of the National Academy of Sciences 115 (51):\n12859–67. https://doi.org/10.1073/pnas.1812028115.\n\n\nMullainathan, S., and E. Shafir. 2013. Scarcity: Why Having Too\nLittle Means so Much. New York: Henry Holt; Company. https://books.google.com/books?id=NTnjsTHrfj8C.\n\n\nMuthukrishna, Michael, and Joseph Henrich. 2019. “A Problem in\nTheory.” Nature Human Behaviour 3 (3): 221–29. https://doi.org/10.1038/s41562-018-0522-1.\n\n\nNair, Jayakrishnan, Adam Wierman, and Bert Zwart. 2022. The\nFundamentals of Heavy Tails: Properties, Emergence, and Estimation.\nCambridge Series in Statistical and Probabilistic Mathematics.\nCambridge: Cambridge University Press.\n\n\nNetting, R. M. 1993. Smallholders, Householders: Farm Families and\nthe Ecology of Intensive, Sustainable Agriculture. Stanford:\nStanford University Press.\n\n\nNeumann, John von, and Oskar Morgenstern. 1947. Theory of Games and Economic Behavior. 2nd\nEd. Princeton, NJ: Princeton University Press.\n\n\nNoy-Meir, Imanuel. 1975. “Stability of Grazing Systems: An\nApplication of Predator-Prey Graphs.” Journal of Ecology\n63 (2): 459–81. https://doi.org/10.2307/2258730.\n\n\nO’Donoghue, Ted, and Matthew Rabin. 1999. “Doing It Now or\nLater.” The American Economic Review 89 (1): 103–24. https://doi.org/10.1257/aer.89.1.103.\n\n\nOlson, M. 1965. The Logic of Collective Action: Public Goods and the\nTheory of Groups. Cambridge: Harvard University Press.\n\n\nOrzack, Steven Hecht, and Elliott Sober. 1994. “Optimality Models\nand the Test of Adaptationism.” The American Naturalist\n143 (3): 361–80. http://www.jstor.org/stable/2462735.\n\n\nOster, G. F., and E. O. Wilson. 1978. Caste and Ecology in the\nSocial Insects. Princeton: Princeton University Press.\n\n\nOstrom, Elinor. 2000. “Collective Action and the Evolution of\nSocial Norms.” The Journal of Economic Perspectives 14\n(3): 137–58. http://www.jstor.org/stable/2646923.\n\n\n———. 2009. “A General Framework for Analyzing Sustainability of\nSocial-Ecological Systems.” Science 325 (5939): 419–22.\nhttps://doi.org/10.1126/science.1172133.\n\n\n———. 2015. Governing the Commons: The Evolution of Institutions for\nCollective Action. Canto Classics. Cambridge: Cambridge University\nPress. https://doi.org/10.1017/CBO9781316423936.\n\n\nParker, Geoffrey A., and John Maynard Smith. 1990. “Optimality\nTheory in Evolutionary Biology.” Nature 348: 27–33. https://doi.org/10.1038/348027a0.\n\n\nPerrow, C. 1984. Normal Accidents: Living with High Risk\nTechnologies. Princeton: Princeton University Press. https://books.google.com/books?id=g66J6Vzq6EYC.\n\n\nPimm, S. L., and J. H. Lawton. 1978. “On Feeding on More Than One\nTrophic Level.” Nature 275: 542–44. https://doi.org/10.1038/275542a0.\n\n\nPuleston, C. O, and S. Tuljapurkar. 2008. “Population and\nPrehistory II: Space-Limited Human Populations in Constant\nEnvironments.” Theoretical Population Biology 74 (2):\n147–60. https://doi.org/10.1016/j.tpb.2008.05.007.\n\n\nPuleston, C., S. Tuljapurkar, and B. Winterhalder. 2014. “The\nInvisible Cliff: Abrupt Imposition of Malthusian Equilibrium in a\nNatural-Fertility, Agrarian Society.” PloS ONE 9 (1):\n13. https://doi.org/10.1371/journal.pone.0087541.\n\n\nRappaport, Roy A. 1971. “Ritual, Sanctity, and\nCybernetics.” American Anthropologist 73 (1): 59–76. https://doi.org/10.2307/671812.\n\n\nRaymond, Michel, Dominique Pontier, Anne-bééatrice Dufour, and Anders\nPape Møller. 1996. “Frequency-Dependent Maintenance of Left\nHandedness in Humans.” Proceedings of the Royal Society of\nLondon. Series B: Biological Sciences 263 (1377): 1627–33. https://doi.org/10.1098/rspb.1996.0238.\n\n\nReal, LA. 1991. “Animal Choice Behavior and the Evolution of\nCognitive Architecture.” Science 253 (5023): 980–86. https://doi.org/10.1126/science.1887231.\n\n\nRendell, Luke, Laurel Fogarty, and Kevin N. Laland. 2010. “Rogers’\nParadox Recast and Resolved: Population Structure and the Evolution of\nSocial Learning Strategies.” Evolution 64 (2): 534–48.\nhttps://doi.org/10.1111/j.1558-5646.2009.00817.x.\n\n\nRichardson, Thomas, and R. Tucker Gilman. 2019. “Left-Handedness\nIs Associated with Greater Fighting Success in Humans.”\nScientific Reports 9 (1): 15402. https://doi.org/10.1038/s41598-019-51975-3.\n\n\nRogers, A. R. 1988. “Does Biology Constrain Culture?”\nAmerican Anthropologist 90 (4): 819–31. https://doi.org/10.1525/aa.1988.90.4.02a00030.\n\n\n———. 1994. “Evolution of Time Preference by Natural\nSelection.” American Economic Review 84 (3): 460–81. http://www.jstor.org/stable/2118062.\n\n\nRoseman, Charles C. 2021. “Lewontin Did Not Commit Lewontin’s Fallacy, His Critics Do: Why Racial\nTaxonomy Is Not Useful for the Scientific Study of Human\nVariation.” BioEssays 43 (12): 2100204. https://doi.org/10.1002/bies.202100204.\n\n\nRosenberg, Alexander, and Frederic Bouchard. 2015.\n“Fitness.” In The Stanford Encyclopedia of\nPhilosophy, edited by Edward N. Zalta. Metaphysics Research Lab,\nStanford University. https://plato.stanford.edu/entries/fitness/.\n\n\nRoughgarden, J., R. M. May, and S. A. Levin. 1989. Perspectives in\nEcological Theory. Princeton: Princeton University Press.\n\n\nRuvolo, M. 1997. “Genetic Diversity in Hominoid Primates.”\nAnnual Review of Anthropology 26: 515–40. http://www.jstor.org/stable/2952533.\n\n\nSagan, Scott D. 2004. “The Problem of Redundancy Problem: Why More\nNuclear Security Forces May Produce Less Nuclear Security.”\nRisk Analysis 24 (4): 935–46. https://doi.org/10.1111/j.0272-4332.2004.00495.x.\n\n\nSalamon, Sonya. 1985. “Ethnic Communities and the Structure of\nAgriculture.” Rural Sociology 50 (3): 323.\n\n\nSamuelson, Paul A. 1937. “A Note on Measurement of\nUtility.” The Review of Economic Studies 4 (2): 155–61.\nhttps://doi.org/10.2307/2967612.\n\n\nScheffer, Marten, Jordi Bascompte, William A. Brock, Victor Brovkin,\nStephen R. Carpenter, Vasilis Dakos, Hermann Held, Egbert H. van Nes,\nMax Rietkerk, and George Sugihara. 2009. “Early-Warning Signals\nfor Critical Transitions.” Nature 461 (7260): 53–59. https://doi.org/10.1038/nature08227.\n\n\nScheffer, M., and S. R. Carpenter. 2003. “Catastrophic Regime\nShifts in Ecosystems: Linking Theory to Observation.” Trends\nin Ecology & Evolution 18 (12): 648–56. https://doi.org/10.1016/j.tree.2003.09.002.\n\n\nSchelling, T. C. 1960. Strategy of Conflict. Cambridge: Harvard\nUniversity Press.\n\n\n———. 1978. Micromotives and Macrobehavior. New York: Norton.\n\n\nSchmid, Max, Maria Paniw, Maarten Postuma, Arpat Ozgul, and Frédéric\nGuillaume. 2022. “A Trade-Off Between Robustness to Environmental\nFluctuations and Speed of Evolution.” The American\nNaturalist 200 (1): E16–35. https://doi.org/10.1086/719654.\n\n\nScott, James C. 1977. The Moral Economy of the\nPeasant: Rebellion and Subsistence in Southeast Asia. New\nHaven: Yale University Press.\n\n\nSilva, Sara Graça da, and Jamshid J. Tehrani. 2016. “Comparative\nPhylogenetic Analyses Uncover the Ancient Roots of Indo-European\nFolktales.” Royal Society Open Science 3 (1): 150645. https://doi.org/10.1098/rsos.150645.\n\n\nSlade, Norman A., Richard Gomulkiewicz, and Helen M. Alexander. 1998.\n“Alternatives to Robinson and\nRedford’s Method of Assessing Overharvest from Incomplete\nDemographic Data.” Conservation Biology 12 (1): 148–55.\nhttps://doi.org/10.1111/j.1523-1739.1998.96273.x.\n\n\nSmaldino, P. E. 2017. “Models Are Stupid, and We Need More of\nThem.” In Computational Social Psychology, edited by R.\nR. Vallacher, A . Nowak, and S. J. Read, 311–31. New York: Routledge.\n\n\nSmaldino, Paul E., and Richard McElreath. 2016. “The Natural\nSelection of Bad Science.” Royal Society Open Science 3\n(9): 160384. https://doi.org/10.1098/rsos.160384.\n\n\nSmith, E. A., and B. Winterhalder. 1992. “Natural Selection and\nDecision Making: Some Fundamental Principles.” Book Section. In\nEvolutionary Ecology and Human Behavior, edited by E. A. Smith\nand B. Winterhalder, 25–60. New York: Aldine de Gruyter.\n\n\nSmith, Eric Alden. 1992. “Human Behavioral Ecology:\nI.” Evolutionary Anthropology 1 (1): 20–25.\nhttps://doi.org/10.1002/evan.1360010107.\n\n\nSmith, Eric A., Monique Borgerhoff Mulder, and Kim Hill. 2001.\n“Controversies in the Evolutionary Social Sciences: A Guide for\nthe Perplexed.” Trends in Ecology & Evolution 16\n(3): 128–35. https://doi.org/10.1016/S0169-5347(00)02077-2.\n\n\nSoetaert, Karline, and Peter M. J. Herman. 2009. “Dynamic\nProgramming.” In A Practical Guide to Ecological\nModelling, edited by Karline Soetaert and Peter M. J. Herman,\n295–307. Amsterdam: Springer Netherlands. https://doi.org/10.1007/978-1-4020-8624-3_10.\n\n\nSozou, P. D. 1998. “On Hyperbolic Discounting and Uncertain Hazard\nRates.” Proceedings of the Royal Society of London. Series B:\nBiological Sciences 265 (1409): 2015–20. https://doi.org/10.1098/rspb.1998.0534.\n\n\nSozou, P. D., and R. M. Seymour. 2003. “Augmented Discounting:\nInteraction Between Ageing and Time-Preference Behaviour.”\nProceedings of the Royal Society of London Series B-Biological\nSciences 270 (1519): 1047–53. https://doi.org/10.1098/rspb.2003.2344.\n\n\nStephens, David W., and John R. Krebs. 1986. Foraging Theory.\nPrinceton: Princeton University Press.\n\n\nSucci, Sauro, and Peter V. Coveney. 2019. “Big Data: The End of\nthe Scientific Method?” Philosophical Transactions of the\nRoyal Society A: Mathematical, Physical and Engineering Sciences\n377 (2142): 20180145. https://doi.org/10.1098/rsta.2018.0145.\n\n\nSymons, D. 1989. “A Critique of Darwinian\nAnthropology.” Ethology and Sociobiology 10 (1-3):\n131–44. https://doi.org/10.1016/0162-3095(89)90016-2.\n\n\nTainter, Joseph A. 1988. The Collapse of Complex Societies.\nCambridge: Cambridge University Press. https://books.google.com/books?id=YdW5wSPJXIoC.\n\n\nTodd, P. M., and G. Gigerenzer. 2012. Ecological Rationality:\nIntelligence in the World. Oxford: Oxford University Press. https://books.google.com/books?id=lO4EdShcg7AC.\n\n\nTomasello, Michael. 1999. The Cultural Origins of Human\nCognition. Cambridge, MA: Harvard University Press.\n\n\nTooby, J., and L. Cosmides. 1990. “The Past Explains the Present:\nEmotional Adaptations and the Structure of Ancestral\nEnvironments.” Ethology and Sociobiology 11 (4-5):\n375–424. https://doi.org/10.1016/0162-3095(90)90017-Z.\n\n\nTooby, John, and Leda Cosmides. 1990. “On the Universality of\nHuman Nature and the Uniqueness of the Individual: The Role of Genetics\nand Adaptation.” Journal of Personality 58 (1): 17–67.\nhttps://doi.org/10.1111/j.1467-6494.1990.tb00907.x.\n\n\nTuljapurkar, S. 1990. Population Dynamics in Variable\nEnvironments. Vol. 85. Lecture Notes in Biomathematics. Berlin:\nSpringer-Veralg.\n\n\nTurke, P. W. 1990. “Which Humans Behave Adaptively, and Why Does\nIt Matter?” Ethology and Sociobiology 11 (4-5): 305–39.\nhttps://doi.org/10.1016/0162-3095(90)90013-V.\n\n\nValkengoed, Anne M. van, Linda Steg, and Goda Perlaviciute. 2023.\n“The Psychological Distance of Climate Change Is\nOverestimated.” One Earth 6 (4): 362–91. https://doi.org/10.1016/j.oneear.2023.03.006.\n\n\nVan Lange, Paul A. M., and Anna L. Huckelba. 2021. “Psychological\nDistance: How to Make Climate Change Less Abstract and Closer to the\nSelf.” Current Opinion in Psychology 42: 49–53. https://doi.org/10.1016/j.copsyc.2021.03.011.\n\n\nVarian, Hal R. 1992. Microeconomic Analysis. 3rd\ned. New York: Norton.\n\n\nVayda, A. P., and B. J. McCay. 1975. “New Directions in Ecology\nand Ecological Anthropology.” Annual Review of\nAnthropology 4: 293–306. https://doi.org/10.1146/annurev.an.04.100175.001453.\n\n\nVayda, Andrew P. 1995a. “Failures of Explanation in\nDarwinian Ecological Anthropology: Part\nI.” Philosophy of the Social Sciences 25\n(2): 219–49. https://doi.org/10.1177/004839319502500205.\n\n\n———. 1995b. “Failures of Explanation in Darwinian\nEcological Anthropology: Part II.” Philosophy of\nthe Social Sciences 25 (3): 360–75. https://doi.org/10.1177/004839319502500305.\n\n\nVayda, Andrew P., and Bradley B. Walters. 1999. “Against Political\nEcology.” Human Ecology 27 (1): 167–79. https://doi.org/10.1023/A:1018713502547.\n\n\nWalters, C. J. 1986. Adaptive Management of Renewable\nResources. New York: Macmillan. https://books.google.com/books?id=rkEqPQAACAAJ.\n\n\nWeitzman, M. L. 2009. “On Modeling and Interpreting the Economics\nof Catastrophic Climate Change.” The Review of Economics and\nStatistics XCI (1): 1–19. https://doi.org/10.1162/rest.91.1.1\n.\n\n\nWeitzman, Martin L. 1998. “Why the Far-Distant Future Should Be\nDiscounted at Its Lowest Possible Rate.” Journal of\nEnvironmental Economics and Management 36 (3): 201–8. https://doi.org/10.1006/jeem.1998.1052.\n\n\nWestern, B. 2001. “Bayesian Thinking about Macrosociology.”\nAmerican Journal of Sociology 107 (2): 353–78. https://doi.org/10.1086/323639.\n\n\nWiessner, P. 1982. “Risk, Reciprocity, and Social Influences on\n!Kung San Economics.” In Politics and History in\nBand Societies, edited by Eleanore Leacock and Richard B. Lee.\nCambridge: Cambridge University Press.\n\n\nWimsatt, William C. 1987. “False Models as Means to Truer\nTheories.” In Neutral Models in Biology, edited by M. H.\nNitecki and A. Hoffman, 23–55. New York: Oxford University Press.\n\n\nWinterhalder, B., and E. A. Smith. 2000. “Analyzing Adaptive\nStrategies: Human Behavioral Ecology at Twenty-Five.”\nEvolutionary Anthropology 9 (2): 51–72. https://doi.org/10.1002/(SICI)1520-6505(2000)9:2&lt;51::AID-EVAN1&gt;3.0.CO;2-7.\n\n\nWood, J. W. 1998. “A Theory of Preindustrial Population Dynamics:\nDemography, Economy, and Well-Being in Malthusian\nSystems.” Current Anthropology 39 (1): 99–135. https://doi.org/10.1086/204700.\n\n\nWood, J. W., G. R. Milner, H. C. Harpending, and K. M. Weiss. 1992.\n“The Osteological Paradox: Problems of Inferring Prehistoric\nHealth from Skeletal Samples.” Current Anthropology 33\n(4): 343–70. http://www.jstor.org/stable/2743861.\n\n\nYodzis, P. 1981. “The Stability of Real Ecosystems.”\nNature 289 (5799): 674–76. https://doi.org/10.1038/289674a0.",
    "crumbs": [
      "References"
    ]
  }
]